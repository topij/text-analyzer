# src/config/models.yaml

version: "1.0.0"
default_provider: "openai"
default_model: "gpt-4o-mini"

providers:
  openai:
    models:
      gpt-4o-mini:
        description: "Default model for most analysis tasks"
        max_tokens: 1000
        temperature: 0.0
        top_p: 1.0
        frequency_penalty: 0.0
        presence_penalty: 0.0
      gpt-4:
        description: "More capable model for complex analysis"
        max_tokens: 2000
        temperature: 0.0
        top_p: 1.0
        
  anthropic:
    models:
      claude-3-sonnet-20240229:
        description: "Alternative model for analysis tasks"
        max_tokens: 1000
        temperature: 0.0
        top_p: 1.0

model_capabilities:
  gpt-4o-mini:
    supports_function_calling: true
    supports_json_mode: true
    max_context: 8192
  gpt-4:
    supports_function_calling: true
    supports_json_mode: true
    max_context: 8192
  claude-3-sonnet-20240229:
    supports_function_calling: false
    supports_json_mode: true
    max_context: 200000

default_parameters:
  temperature: 0.0
  max_tokens: 1000
  top_p: 1.0
  frequency_penalty: 0.0
  presence_penalty: 0.0