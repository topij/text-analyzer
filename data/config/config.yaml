# Project settings
project_name: "semantic-text-analyzer"
version: "0.4.5"
environment: "production"

# Logging configuration
logging:
  level: "DEBUG"
  format: "%(asctime)s - %(name)s - %(levelname)s - %(message)s"
  date_format: "%Y-%m-%d %H:%M:%S"
  file_path: "app.log" # "data/logs/app.log"
  disable_existing_loggers: true

# Basic settings
csv_delimiter: ";"
encoding: "utf-8"
quoting: 0  # csv.QUOTE_MINIMAL
include_timestamp: true
# logging_level: "INFO"
# disable_logging: false

## FileUtils settings
# Directory structure
directory_structure:
  docs: []
  data:
    - raw
    - interim
    - processed
    - config
    - testing
  reports:
    - figures
    - outputs
  models: []
  src: []
  scripts: []
  notebooks: []
  
# Azure Storage settings (optional)
azure:
  enabled: false  # Set to true to enable Azure storage
  container_mapping:
    raw: "raw-data"
    processed: "processed-data"
    interim: "interim-data"
    parameters: "parameters"
    configurations: "configurations"
  retry_settings:
    max_retries: 3
    retry_delay: 1
  connection_string: ""  # Set via environment variable

##
# Language-specific settings
languages:
  fi:
    min_word_length: 3
    excluded_patterns: 
      - "^\\d+$"
      - "^[^a-zA-ZäöåÄÖÅ0-9]+$"
    voikko:
      paths:
        win32:
          lib_path: "C:/scripts/Voikko/libvoikko-1.dll"
          dict_path: "C:/scripts/Voikko"
        linux:
          lib_path: "/usr/lib/x86_64-linux-gnu/libvoikko.so.1"
          dict_path: "/usr/lib/voikko"
    preserve_compounds: true

# Core analyzer settings
analyzer:
  default_language: "en"
  content_column: "content"

# Model settings
models:
  default_provider: "openai"
  default_model: "gpt-4o-mini"
  parameters:
    temperature: 0.0
    max_tokens: 1000
    top_p: 1.0
    frequency_penalty: 0.0
    presence_penalty: 0.0
  
  providers:
    openai:
      available_models:
        gpt-4:
          description: "Most capable model, best for complex tasks"
          max_tokens: 8192
          supports_functions: true
        gpt-4-turbo:
          description: "Faster GPT-4 variant"
          max_tokens: 4096
          supports_functions: true
        gpt-4o-mini:
          description: "Fast and cost-effective for simpler tasks"
          max_tokens: 4096
          supports_functions: true
      api_type: "open_ai"
      api_version: null
      
    azure:
      available_models:
        #gpt-4:
        #  description: "Azure OpenAI GPT-4"
        #  deployment_name: "gpt-4"
        #  max_tokens: 8192
        #  supports_functions: true
        gpt-4o-mini:
          description: "Azure OpenAI GPT-4o-mini deployment"
          deployment_name: "gpt-4o-mini"
          max_tokens: 4096
          supports_functions: true
      api_type: "openai"
      api_version: "2024-08-01-preview"
      
    anthropic:
      available_models:
        claude-3-opus:
          description: "Most capable Claude model"
          max_tokens: 200000
          supports_functions: false
        claude-3-sonnet:
          description: "Balanced performance and speed"
          max_tokens: 200000
          supports_functions: false
        claude-3-haiku:
          description: "Fastest Claude model"
          max_tokens: 200000
          supports_functions: false
      api_type: "anthropic"
      api_version: null

# Analysis configurations
analysis:
  keywords:
    max_keywords: 10
    min_keyword_length: 3
    include_compounds: true
    min_confidence: 0.3
    use_statistical: true
    compound_word_bonus: 0.2
    weights:
      statistical: 0.4
      llm: 0.6

  themes:
    max_themes: 3
    min_confidence: 0.5
    include_hierarchy: true
    require_evidence: true
    min_theme_length: 10

  categories:
    max_categories: 3
    min_confidence: 0.3
    require_evidence: true
    allow_overlap: true
    hierarchical: true

# Feature flags
features:
  use_caching: true
  use_async: true
  use_batching: true
  enable_finnish_support: true
  enable_compound_detection: true
  enable_spell_check: false

# Processing settings
processing:
  batch_size: 100
  max_retries: 3
  retry_delay: 1.0
  timeout: 30.0
  max_workers: 4
  chunk_size: 1000

# Cache settings
caching:
  enabled: true
  ttl: 3600  # 1 hour
  max_size: 1000
  backend: "memory"
  compression: true

# Development settings
# development:
#   debug_mode: true
#   profile_performance: false
#   log_llm_calls: true
#   mock_llm_responses: false
#   save_intermediates: false