{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required modules\n",
    "import sys\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "from typing import List, Dict, Any\n",
    "import logging\n",
    "import asyncio\n",
    "import logging\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# Add project root to Python path if needed\n",
    "project_root = str(Path().resolve().parent)\n",
    "if project_root not in sys.path:\n",
    "    sys.path.append(project_root)\n",
    "\n",
    "# Import necessary components\n",
    "from src.nb_helpers.environment import setup_notebook_env, verify_environment\n",
    "from src.semantic_analyzer import SemanticAnalyzer\n",
    "from src.core.config import AnalyzerConfig\n",
    "from src.core.language_processing import create_text_processor\n",
    "from src.core.llm.factory import create_llm\n",
    "from src.utils.output_formatter import (\n",
    "    ExcelFormatter, DetailedFormatter, OutputDetail, ExcelOutputConfig, BaseColumnFormat\n",
    ")\n",
    "from FileUtils import FileUtils, OutputFileType\n",
    "\n",
    "logger = logging.getLogger(__name__)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-12-11 12:04:14,909 - FileUtils.core.file_utils - INFO - Project root: c:\\Users\\tja\\OneDrive - Rastor-instituutti ry\\Tiedostot\\Rastor-instituutti\\kehittäminen\\analytiikka\\repos\\semantic-text-analyzer\n",
      "2024-12-11 12:04:14,917 - FileUtils.core.file_utils - INFO - FileUtils initialized with local storage\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-12-11 12:04:14,961 - FileUtils.core.file_utils - INFO - Project root: c:\\Users\\tja\\OneDrive - Rastor-instituutti ry\\Tiedostot\\Rastor-instituutti\\kehittäminen\\analytiikka\\repos\\semantic-text-analyzer\n",
      "2024-12-11 12:04:14,970 - FileUtils.core.file_utils - INFO - FileUtils initialized with local storage\n",
      "Environment Check Results:\n",
      "==================================================\n",
      "\n",
      "Basic Setup:\n",
      "-----------\n",
      "✓ Project root in path\n",
      "✓ FileUtils initialized\n",
      "✓ .env file loaded\n",
      "\n",
      "Environment Variables:\n",
      "---------------------\n",
      "✓ OPENAI_API_KEY set\n",
      "✓ ANTHROPIC_API_KEY set\n",
      "\n",
      "Project Structure:\n",
      "-----------------\n",
      "✓ Raw data exists\n",
      "✓ Processed data exists\n",
      "✓ Configuration exists\n",
      "✓ Main config.yaml exists\n",
      "\n",
      "==================================================\n",
      "Environment Status: Ready ✓\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Set up environment and verify\n",
    "setup_notebook_env(log_level=\"DEBUG\")\n",
    "verify_environment()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-12-11 12:04:15,056 - FileUtils.core.file_utils - INFO - Project root: c:\\Users\\tja\\OneDrive - Rastor-instituutti ry\\Tiedostot\\Rastor-instituutti\\kehittäminen\\analytiikka\\repos\\semantic-text-analyzer\n",
      "2024-12-11 12:04:15,063 - FileUtils.core.file_utils - INFO - FileUtils initialized with local storage\n",
      "2024-12-11 12:04:15,098 - FileUtils.core.file_utils - INFO - Project root: c:\\Users\\tja\\OneDrive - Rastor-instituutti ry\\Tiedostot\\Rastor-instituutti\\kehittäminen\\analytiikka\\repos\\semantic-text-analyzer\n",
      "2024-12-11 12:04:15,105 - FileUtils.core.file_utils - INFO - FileUtils initialized with local storage\n",
      "2024-12-11 12:04:23,139 - FileUtils.core.file_utils - INFO - Project root: c:\\Users\\tja\\OneDrive - Rastor-instituutti ry\\Tiedostot\\Rastor-instituutti\\kehittäminen\\analytiikka\\repos\\semantic-text-analyzer\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO: Project root: c:\\Users\\tja\\OneDrive - Rastor-instituutti ry\\Tiedostot\\Rastor-instituutti\\kehittäminen\\analytiikka\\repos\\semantic-text-analyzer\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-12-11 12:04:23,148 - FileUtils.core.file_utils - INFO - FileUtils initialized with local storage\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO: FileUtils initialized with local storage\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-12-11 12:04:23,216 - FileUtils.core.file_utils - INFO - Project root: c:\\Users\\tja\\OneDrive - Rastor-instituutti ry\\Tiedostot\\Rastor-instituutti\\kehittäminen\\analytiikka\\repos\\semantic-text-analyzer\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO: Project root: c:\\Users\\tja\\OneDrive - Rastor-instituutti ry\\Tiedostot\\Rastor-instituutti\\kehittäminen\\analytiikka\\repos\\semantic-text-analyzer\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-12-11 12:04:23,225 - FileUtils.core.file_utils - INFO - FileUtils initialized with local storage\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO: FileUtils initialized with local storage\n",
      "INFO: Loaded 747 stopwords from c:\\Users\\tja\\OneDrive - Rastor-instituutti ry\\Tiedostot\\Rastor-instituutti\\kehittäminen\\analytiikka\\repos\\semantic-text-analyzer\\data\\configurations\\stop_words\\fi.txt\n",
      "DEBUG: Initialized with config: {}\n",
      "DEBUG: Trying library paths: ['C:\\\\scripts\\\\Voikko\\\\libvoikko-1.dll', 'C:\\\\Program Files\\\\Voikko\\\\libvoikko-1.dll', 'C:\\\\Voikko\\\\libvoikko-1.dll']\n",
      "DEBUG: Trying dictionary paths: ['C:\\\\scripts\\\\Voikko', 'C:\\\\Program Files\\\\Voikko', 'C:\\\\Voikko']\n",
      "DEBUG: Added C:\\scripts\\Voikko to DLL search path\n",
      "INFO: Successfully initialized Voikko with path: C:\\scripts\\Voikko\n"
     ]
    }
   ],
   "source": [
    "# Initialize FileUtils\n",
    "file_utils = FileUtils()\n",
    "\n",
    "# Create analyzer config with OpenAI as default\n",
    "config = AnalyzerConfig()\n",
    "config.config[\"models\"][\"default_provider\"] = \"openai\"\n",
    "config.config[\"models\"][\"default_model\"] = \"gpt-4o-mini\"\n",
    "\n",
    "# Create LLM instance\n",
    "llm = create_llm(provider=\"openai\", config=config)\n",
    "\n",
    "# Initialize language processors\n",
    "en_processor = create_text_processor(language=\"en\")\n",
    "fi_processor = create_text_processor(language=\"fi\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-12-11 12:04:23,385 - FileUtils.core.file_utils - INFO - Project root: c:\\Users\\tja\\OneDrive - Rastor-instituutti ry\\Tiedostot\\Rastor-instituutti\\kehittäminen\\analytiikka\\repos\\semantic-text-analyzer\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO: Project root: c:\\Users\\tja\\OneDrive - Rastor-instituutti ry\\Tiedostot\\Rastor-instituutti\\kehittäminen\\analytiikka\\repos\\semantic-text-analyzer\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-12-11 12:04:23,393 - FileUtils.core.file_utils - INFO - FileUtils initialized with local storage\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO: FileUtils initialized with local storage\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-12-11 12:04:24,184 - FileUtils.core.file_utils - INFO - Project root: c:\\Users\\tja\\OneDrive - Rastor-instituutti ry\\Tiedostot\\Rastor-instituutti\\kehittäminen\\analytiikka\\repos\\semantic-text-analyzer\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO: Project root: c:\\Users\\tja\\OneDrive - Rastor-instituutti ry\\Tiedostot\\Rastor-instituutti\\kehittäminen\\analytiikka\\repos\\semantic-text-analyzer\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-12-11 12:04:24,193 - FileUtils.core.file_utils - INFO - FileUtils initialized with local storage\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO: FileUtils initialized with local storage\n",
      "INFO: Semantic analyzer initialization complete\n"
     ]
    }
   ],
   "source": [
    "# Create analyzer with proper initialization\n",
    "analyzer = SemanticAnalyzer(\n",
    "    llm=llm,\n",
    "    file_utils=file_utils,\n",
    "    parameter_file=\"parameters_en.xlsx\"  # Default to English parameters\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test data for demonstrations\n",
    "test_texts = {\n",
    "    \"en\": {\n",
    "        \"technical\": \"\"\"Machine learning models are trained using large datasets to recognize patterns. \n",
    "                    The neural network architecture includes multiple layers for feature extraction. \n",
    "                    Data preprocessing and feature engineering are crucial steps.\"\"\",\n",
    "        \n",
    "        \"business\": \"\"\"Q3 financial results show 15% revenue growth and improved profit margins. \n",
    "                    Customer acquisition costs decreased while retention rates increased. \n",
    "                    Market expansion strategy focuses on emerging technology sectors.\"\"\",\n",
    "        \n",
    "        \"mixed\": \"\"\"Our AI platform leverages machine learning to optimize customer engagement.\n",
    "                 The system analyzes user behavior patterns to improve conversion rates.\n",
    "                 Q2 results showed 25% improvement in customer retention metrics.\"\"\"\n",
    "    },\n",
    "    \"fi\": {\n",
    "        \"technical\": \"\"\"Koneoppimismalleja koulutetaan suurilla datajoukolla tunnistamaan kaavoja. \n",
    "                    Neuroverkon arkkitehtuuri sisältää useita kerroksia piirteiden erottamiseen. \n",
    "                    Datan esikäsittely ja piirteiden suunnittelu ovat keskeisiä vaiheita.\"\"\",\n",
    "        \n",
    "        \"business\": \"\"\"Q3 taloudelliset tulokset osoittavat 15% liikevaihdon kasvun ja parantuneet katteet. \n",
    "                    Asiakashankinnan kustannukset laskivat ja asiakaspysyvyys parani. \n",
    "                    Markkinalaajennusstrategia keskittyy nouseviin teknologiasektoreihin.\"\"\"\n",
    "    }\n",
    "}\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize formatters with different detail levels\n",
    "summary_formatter = ExcelFormatter(\n",
    "    file_utils=file_utils,\n",
    "    config=ExcelOutputConfig(detail_level=OutputDetail.SUMMARY)\n",
    ")\n",
    "\n",
    "detailed_formatter = DetailedFormatter(\n",
    "    file_utils=file_utils,\n",
    "    config=ExcelOutputConfig(detail_level=OutputDetail.DETAILED)\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Single Text Analysis with Different Detail Levels\n",
    "async def demonstrate_single_analysis(text: str, language: str = \"en\"):\n",
    "    \"\"\"Demonstrate analysis of single text with different detail levels.\"\"\"\n",
    "    print(f\"Analyzing {language.upper()} text:\")\n",
    "    print(\"-\" * 50)\n",
    "    print(text)\n",
    "    print(\"\\n\")\n",
    "\n",
    "    try:\n",
    "        # Update analyzer's language and configuration\n",
    "        analyzer.set_language(language)\n",
    "        \n",
    "        # Perform analysis\n",
    "        result = await analyzer.analyze(\n",
    "            text,\n",
    "            analysis_types=[\"keywords\", \"themes\", \"categories\"],\n",
    "            language=language  # Pass language explicitly\n",
    "        )\n",
    "\n",
    "        print(\"\\nAnalysis Results:\")\n",
    "        print(\"-\" * 50)\n",
    "        print(result)\n",
    "\n",
    "        # Show summary format\n",
    "        print(\"\\nSummary Output:\")\n",
    "        print(\"-\" * 50)\n",
    "        summary = summary_formatter.format_output(\n",
    "            results={\n",
    "                \"keywords\": result.keywords,\n",
    "                \"themes\": result.themes,\n",
    "                \"categories\": result.categories\n",
    "            },\n",
    "            analysis_types=[\"keywords\", \"themes\", \"categories\"]\n",
    "        )\n",
    "\n",
    "        logger.debug(f\"Summary formatter results: {summary}\")\n",
    "        \n",
    "        for analysis_type, output in summary.items():\n",
    "            print(f\"\\n{analysis_type.title()}:\")\n",
    "            if output:\n",
    "                items = output.split(\"; \")\n",
    "                for item in items:\n",
    "                    print(f\"  • {item}\")\n",
    "            else:\n",
    "                print(\"  No results\")\n",
    "\n",
    "        # Show detailed format\n",
    "        print(\"\\nDetailed Output:\")\n",
    "        print(\"-\" * 50)\n",
    "        detailed = detailed_formatter.format_detailed_output(\n",
    "            results={\n",
    "                \"keywords\": result.keywords,\n",
    "                \"themes\": result.themes,\n",
    "                \"categories\": result.categories\n",
    "            },\n",
    "            analysis_types=[\"keywords\", \"themes\", \"categories\"]\n",
    "        )\n",
    "        \n",
    "        for analysis_type, output in detailed.items():\n",
    "            print(f\"\\n{analysis_type.title()}:\")\n",
    "            print(\"Summary:\")\n",
    "            if output[\"summary\"]:\n",
    "                items = output[\"summary\"].split(\"; \")\n",
    "                for item in items:\n",
    "                    print(f\"  • {item}\")\n",
    "            \n",
    "            print(\"\\nDetails:\")\n",
    "            if isinstance(output[\"details\"], str):\n",
    "                # Handle string format\n",
    "                items = output[\"details\"].split(\"; \")\n",
    "                for item in items:\n",
    "                    print(f\"  • {item}\")\n",
    "            elif isinstance(output[\"details\"], dict):\n",
    "                # Handle dictionary format\n",
    "                for key, value in output[\"details\"].items():\n",
    "                    print(f\"  • {key}:\")\n",
    "                    if isinstance(value, list):\n",
    "                        for item in value:\n",
    "                            print(f\"    - {item}\")\n",
    "                    else:\n",
    "                        print(f\"    {value}\")\n",
    "\n",
    "            print(\"\\nMetadata:\")\n",
    "            for key, value in output[\"metadata\"].items():\n",
    "                print(f\"  • {key}: {value}\")\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Analysis failed: {e}\")\n",
    "        print(f\"Error: {str(e)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "async def demonstrate_excel_processing_details():\n",
    "    \"\"\"Demonstrate processing of Excel file.\"\"\"\n",
    "    input_filename = \"test_content_short.xlsx\"  # Without extension\n",
    "    output_filename = \"analysis_results\"  # Without extension\n",
    "    text_column = \"keskustelu\"\n",
    "    language_column = \"language\"  # Optional column for language detection\n",
    "\n",
    "    print(f\"Processing Excel file: {input_filename}\")\n",
    "    print(\"-\" * 50)\n",
    "\n",
    "    try:\n",
    "        # Load input file using FileUtils\n",
    "        input_df = file_utils.load_single_file(\n",
    "            file_path=input_filename,\n",
    "            input_type=\"raw\"\n",
    "        )\n",
    "\n",
    "        if text_column not in input_df.columns:\n",
    "            print(f\"Error: Column '{text_column}' not found in input file\")\n",
    "            return\n",
    "\n",
    "        # Process each row with appropriate language handling\n",
    "        results = []\n",
    "        for idx, row in input_df.iterrows():\n",
    "            try:\n",
    "                # Determine language\n",
    "                language = row[language_column] if language_column in input_df.columns else \"en\"\n",
    "                \n",
    "                # Update analyzer's language\n",
    "                analyzer.set_language(language)\n",
    "\n",
    "                # Analyze text\n",
    "                result = await analyzer.analyze(\n",
    "                    row[text_column],\n",
    "                    analysis_types=[\"keywords\", \"themes\", \"categories\"],\n",
    "                    language=language\n",
    "                )\n",
    "\n",
    "                # Format results using the formatters\n",
    "                formatted_result = {\n",
    "                    \"keywords\": summary_formatter.format_output(\n",
    "                        {\"keywords\": result.keywords},\n",
    "                        [\"keywords\"]\n",
    "                    ).get(\"keywords\", \"\"),\n",
    "                    \n",
    "                    \"themes\": summary_formatter.format_output(\n",
    "                        {\"themes\": result.themes},\n",
    "                        [\"themes\"]\n",
    "                    ).get(\"themes\", \"\"),\n",
    "                    \n",
    "                    \"categories\": summary_formatter.format_output(\n",
    "                        {\"categories\": result.categories},\n",
    "                        [\"categories\"]\n",
    "                    ).get(\"categories\", \"\"),\n",
    "                    \n",
    "                    \"language\": language\n",
    "                }\n",
    "                \n",
    "                results.append(formatted_result)\n",
    "                print(f\"Processed row {idx + 1}/{len(input_df)} ({language})\")\n",
    "\n",
    "            except Exception as e:\n",
    "                logger.error(f\"Error processing row {idx + 1}: {e}\")\n",
    "                results.append({\n",
    "                    \"keywords\": f\"Error: {str(e)}\",\n",
    "                    \"themes\": f\"Error: {str(e)}\",\n",
    "                    \"categories\": f\"Error: {str(e)}\",\n",
    "                    \"language\": language\n",
    "                })\n",
    "\n",
    "        # Create results DataFrame\n",
    "        results_df = input_df.copy()\n",
    "        for key in [\"keywords\", \"themes\", \"categories\"]:\n",
    "            results_df[key] = [r.get(key, \"\") for r in results]\n",
    "\n",
    "        # Save using FileUtils\n",
    "        saved_files, _ = file_utils.save_data_to_storage(\n",
    "            data={\"analysis_results\": results_df},\n",
    "            output_type=\"processed\",\n",
    "            file_name=output_filename,\n",
    "            output_filetype=OutputFileType.XLSX,\n",
    "            include_timestamp=True\n",
    "        )\n",
    "\n",
    "        print(\"\\nProcessing complete!\")\n",
    "        output_path = next(iter(saved_files.values()))\n",
    "        print(f\"Results saved to: {output_path}\")\n",
    "        \n",
    "        print(\"\\nFirst few rows of results:\")\n",
    "        pd.set_option('display.max_columns', None)\n",
    "        pd.set_option('display.max_colwidth', 50)\n",
    "        print(results_df.head())\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing Excel file: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "async def demonstrate_excel_processing():\n",
    "    \"\"\"Demonstrate processing of Excel file with simplified output.\"\"\"\n",
    "    file_name = \"test_content_fi.xlsx\"\n",
    "    output_filename = \"analysis_results\"\n",
    "    text_column = \"content\"\n",
    "    language_column = \"language\"\n",
    "\n",
    "    # Create simplified formatter configuration\n",
    "    simple_config = ExcelOutputConfig(\n",
    "        detail_level=OutputDetail.MINIMAL,  # Use minimal detail level\n",
    "        keywords_format=BaseColumnFormat(\n",
    "            column_name=\"keywords\",\n",
    "            format_template=\"{keyword}\",  # Just show keyword without score/domain\n",
    "            included_fields=[\"keyword\"],\n",
    "            max_items=5  # Limit number of keywords\n",
    "        ),\n",
    "        themes_format=BaseColumnFormat(\n",
    "            column_name=\"themes\",\n",
    "            format_template=\"{name}\",  # Just show theme name\n",
    "            included_fields=[\"name\"],\n",
    "            max_items=3  # Limit number of themes\n",
    "        ),\n",
    "        categories_format=BaseColumnFormat(\n",
    "            column_name=\"categories\",\n",
    "            format_template=\"{name}\",  # Just show category name\n",
    "            included_fields=[\"name\"],\n",
    "            max_items=2  # Limit number of categories\n",
    "        )\n",
    "    )\n",
    "\n",
    "    # Create formatter with simplified config\n",
    "    simple_formatter = ExcelFormatter(\n",
    "        file_utils=file_utils,\n",
    "        config=simple_config\n",
    "    )\n",
    "\n",
    "    try:\n",
    "        # Load and process input file\n",
    "        input_df = file_utils.load_single_file(\n",
    "            file_path=file_name,\n",
    "            input_type=\"raw\"\n",
    "        )\n",
    "\n",
    "        if text_column not in input_df.columns:\n",
    "            print(f\"Error: Column '{text_column}' not found in input file\")\n",
    "            return\n",
    "\n",
    "        results = []\n",
    "        for idx, row in input_df.iterrows():\n",
    "            try:\n",
    "                language = row[language_column] if language_column in input_df.columns else \"en\"\n",
    "                analyzer.set_language(language)\n",
    "\n",
    "                result = await analyzer.analyze(\n",
    "                    row[text_column],\n",
    "                    analysis_types=[\"keywords\", \"themes\", \"categories\"],\n",
    "                    language=language\n",
    "                )\n",
    "\n",
    "                # Format with simplified formatter\n",
    "                formatted_result = {\n",
    "                    \"keywords\": simple_formatter.format_output(\n",
    "                        {\"keywords\": result.keywords},\n",
    "                        [\"keywords\"]\n",
    "                    ).get(\"keywords\", \"\"),\n",
    "                    \n",
    "                    \"themes\": simple_formatter.format_output(\n",
    "                        {\"themes\": result.themes},\n",
    "                        [\"themes\"]\n",
    "                    ).get(\"themes\", \"\"),\n",
    "                    \n",
    "                    \"categories\": simple_formatter.format_output(\n",
    "                        {\"categories\": result.categories},\n",
    "                        [\"categories\"]\n",
    "                    ).get(\"categories\", \"\"),\n",
    "                    \n",
    "                    \"language\": language\n",
    "                }\n",
    "                results.append(formatted_result)\n",
    "\n",
    "            except Exception as e:\n",
    "                logger.error(f\"Error processing row {idx + 1}: {e}\")\n",
    "                results.append({\n",
    "                    \"keywords\": f\"Error: {str(e)}\",\n",
    "                    \"themes\": f\"Error: {str(e)}\",\n",
    "                    \"categories\": f\"Error: {str(e)}\",\n",
    "                    \"language\": language\n",
    "                })\n",
    "\n",
    "        # Create and save results\n",
    "        results_df = input_df.copy()\n",
    "        for key in [\"keywords\", \"themes\", \"categories\"]:\n",
    "            results_df[key] = [r.get(key, \"\") for r in results]\n",
    "\n",
    "        # Configure pandas display options\n",
    "        pd.set_option('display.max_columns', None)\n",
    "        pd.set_option('display.max_colwidth', 30)  # Shorter column width\n",
    "        pd.set_option('display.expand_frame_repr', False)\n",
    "\n",
    "        # Save results\n",
    "        saved_files, _ = file_utils.save_data_to_storage(\n",
    "            data={\"analysis_results\": results_df},\n",
    "            output_type=\"processed\",\n",
    "            file_name=output_filename,\n",
    "            output_filetype=OutputFileType.XLSX,\n",
    "            include_timestamp=True\n",
    "        )\n",
    "\n",
    "        print(\"\\nProcessing complete!\")\n",
    "        print(f\"Results saved to: {next(iter(saved_files.values()))}\")\n",
    "        print(\"\\nFirst few rows of results:\")\n",
    "        print(results_df.head())\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing Excel file: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "async def demonstrate_custom_format():\n",
    "    \"\"\"Demonstrate custom formatting options with language support.\"\"\"\n",
    "    # Create custom config with language-aware templates\n",
    "    custom_config = ExcelOutputConfig(\n",
    "        detail_level=OutputDetail.SUMMARY,\n",
    "        keywords_format=BaseColumnFormat(\n",
    "            column_name=\"key_terms\",\n",
    "            format_template=\"{keywords} ({domain}) [{language}]\",\n",
    "            included_fields=[\"keyword\", \"domain\", \"language\"],\n",
    "            confidence_threshold=0.5,\n",
    "            max_items=3\n",
    "        ),\n",
    "        themes_format=BaseColumnFormat(\n",
    "            column_name=\"main_themes\",\n",
    "            format_template=\"{name} ({confidence}) [{language}]\",\n",
    "            included_fields=[\"name\", \"confidence\", \"language\"],\n",
    "            confidence_threshold=0.6,\n",
    "            max_items=2\n",
    "        )\n",
    "    )\n",
    "\n",
    "    custom_formatter = ExcelFormatter(\n",
    "        file_utils=file_utils,\n",
    "        config=custom_config\n",
    "    )\n",
    "\n",
    "    # Test both languages\n",
    "    for lang, texts in test_texts.items():\n",
    "        print(f\"\\nAnalyzing {lang.upper()} text with custom format:\")\n",
    "        print(\"-\" * 50)\n",
    "        \n",
    "        # Set appropriate language processor\n",
    "        analyzer.language_processor = (\n",
    "            fi_processor if lang == \"fi\" else en_processor\n",
    "        )\n",
    "\n",
    "        # Analyze each type of text\n",
    "        for text_type, text in texts.items():\n",
    "            print(f\"\\nText type: {text_type}\")\n",
    "            \n",
    "            try:\n",
    "                result = await analyzer.analyze(\n",
    "                    text,\n",
    "                    analysis_types=[\"keywords\", \"themes\"]\n",
    "                )\n",
    "\n",
    "                custom_output = custom_formatter.format_output(\n",
    "                    results=result,\n",
    "                    analysis_types=[\"keywords\", \"themes\"]\n",
    "                )\n",
    "                \n",
    "                for analysis_type, output in custom_output.items():\n",
    "                    print(f\"\\n{analysis_type.title()}:\")\n",
    "                    print(output)\n",
    "\n",
    "            except Exception as e:\n",
    "                print(f\"Error analyzing {lang} {text_type} text: {e}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "async def run_demos():\n",
    "    \"\"\"Run all demonstrations with proper error handling.\"\"\"\n",
    "    try:\n",
    "        # 1. English text analysis\n",
    "        print(\"=== English Text Analysis Demo ===\\n\")\n",
    "        await demonstrate_single_analysis(test_texts[\"en\"][\"mixed\"], language=\"en\")\n",
    "\n",
    "        # 2. Finnish text analysis\n",
    "        print(\"\\n=== Finnish Text Analysis Demo ===\\n\")\n",
    "        await demonstrate_single_analysis(test_texts[\"fi\"][\"technical\"], language=\"fi\")\n",
    "\n",
    "        # 3. Excel processing\n",
    "        print(\"\\n=== Excel Processing Demo ===\\n\")\n",
    "        await demonstrate_excel_processing()\n",
    "\n",
    "        # 4. Custom format demo\n",
    "        print(\"\\n=== Custom Format Demo ===\\n\")\n",
    "        await demonstrate_custom_format()\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error running demonstrations: {e}\")\n",
    "        raise\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Run all demonstrations with proper error handling.\"\"\"\n",
    "# 1. English text analysis\n",
    "print(\"=== English Text Analysis Demo ===\\n\")\n",
    "await demonstrate_single_analysis(test_texts[\"en\"][\"mixed\"], language=\"en\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Finnish text analysis\n",
    "print(\"\\n=== Finnish Text Analysis Demo ===\\n\")\n",
    "await demonstrate_single_analysis(test_texts[\"fi\"][\"technical\"], language=\"fi\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Excel Processing Demo ===\n",
      "\n",
      "2024-12-11 12:04:30,353 - FileUtils.core.file_utils - INFO - Project root: c:\\Users\\tja\\OneDrive - Rastor-instituutti ry\\Tiedostot\\Rastor-instituutti\\kehittäminen\\analytiikka\\repos\\semantic-text-analyzer\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO: Project root: c:\\Users\\tja\\OneDrive - Rastor-instituutti ry\\Tiedostot\\Rastor-instituutti\\kehittäminen\\analytiikka\\repos\\semantic-text-analyzer\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-12-11 12:04:30,366 - FileUtils.core.file_utils - INFO - FileUtils initialized with local storage\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO: FileUtils initialized with local storage\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-12-11 12:04:30,466 - FileUtils.core.file_utils - INFO - Project root: c:\\Users\\tja\\OneDrive - Rastor-instituutti ry\\Tiedostot\\Rastor-instituutti\\kehittäminen\\analytiikka\\repos\\semantic-text-analyzer\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO: Project root: c:\\Users\\tja\\OneDrive - Rastor-instituutti ry\\Tiedostot\\Rastor-instituutti\\kehittäminen\\analytiikka\\repos\\semantic-text-analyzer\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-12-11 12:04:30,476 - FileUtils.core.file_utils - INFO - FileUtils initialized with local storage\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO: FileUtils initialized with local storage\n",
      "INFO: Loaded 747 stopwords from c:\\Users\\tja\\OneDrive - Rastor-instituutti ry\\Tiedostot\\Rastor-instituutti\\kehittäminen\\analytiikka\\repos\\semantic-text-analyzer\\data\\configurations\\stop_words\\fi.txt\n",
      "DEBUG: Initialized with config: {'default_language': 'en', 'content_column': 'content', 'analysis': {'keywords': {'max_keywords': 5, 'min_keyword_length': 3, 'include_compounds': True}, 'themes': {'max_themes': 3, 'min_confidence': 0.5, 'include_hierarchy': True}, 'categories': {'max_categories': 3, 'min_confidence': 0.3, 'require_evidence': True}}, 'models': {'default_provider': 'openai', 'default_model': 'gpt-4o-mini', 'parameters': {'temperature': 0.0, 'max_tokens': 1000, 'top_p': 1.0, 'frequency_penalty': 0.0, 'presence_penalty': 0.0}, 'providers': {'azure': {'api_version': '2024-02-15-preview', 'api_type': 'azure'}, 'openai': {'api_type': 'open_ai'}, 'anthropic': {'api_type': 'anthropic'}}}, 'features': {'use_caching': True, 'use_async': True, 'use_batching': True, 'enable_finnish_support': True}, 'language': 'fi'}\n",
      "DEBUG: Trying library paths: ['C:\\\\scripts\\\\Voikko\\\\libvoikko-1.dll', 'C:\\\\Program Files\\\\Voikko\\\\libvoikko-1.dll', 'C:\\\\Voikko\\\\libvoikko-1.dll']\n",
      "DEBUG: Trying dictionary paths: ['C:\\\\scripts\\\\Voikko', 'C:\\\\Program Files\\\\Voikko', 'C:\\\\Voikko']\n",
      "DEBUG: Added C:\\scripts\\Voikko to DLL search path\n",
      "INFO: Successfully initialized Voikko with path: C:\\scripts\\Voikko\n",
      "INFO: Language switched to fi\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-12-11 12:04:30,559 - FileUtils.core.file_utils - INFO - Project root: c:\\Users\\tja\\OneDrive - Rastor-instituutti ry\\Tiedostot\\Rastor-instituutti\\kehittäminen\\analytiikka\\repos\\semantic-text-analyzer\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO: Project root: c:\\Users\\tja\\OneDrive - Rastor-instituutti ry\\Tiedostot\\Rastor-instituutti\\kehittäminen\\analytiikka\\repos\\semantic-text-analyzer\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-12-11 12:04:30,570 - FileUtils.core.file_utils - INFO - FileUtils initialized with local storage\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO: FileUtils initialized with local storage\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-12-11 12:04:30,643 - FileUtils.core.file_utils - INFO - Project root: c:\\Users\\tja\\OneDrive - Rastor-instituutti ry\\Tiedostot\\Rastor-instituutti\\kehittäminen\\analytiikka\\repos\\semantic-text-analyzer\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO: Project root: c:\\Users\\tja\\OneDrive - Rastor-instituutti ry\\Tiedostot\\Rastor-instituutti\\kehittäminen\\analytiikka\\repos\\semantic-text-analyzer\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-12-11 12:04:30,651 - FileUtils.core.file_utils - INFO - FileUtils initialized with local storage\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO: FileUtils initialized with local storage\n",
      "INFO: Loaded 747 stopwords from c:\\Users\\tja\\OneDrive - Rastor-instituutti ry\\Tiedostot\\Rastor-instituutti\\kehittäminen\\analytiikka\\repos\\semantic-text-analyzer\\data\\configurations\\stop_words\\fi.txt\n",
      "DEBUG: Initialized with config: {'default_language': 'en', 'content_column': 'content', 'analysis': {'keywords': {'max_keywords': 5, 'min_keyword_length': 3, 'include_compounds': True}, 'themes': {'max_themes': 3, 'min_confidence': 0.5, 'include_hierarchy': True}, 'categories': {'max_categories': 3, 'min_confidence': 0.3, 'require_evidence': True}}, 'models': {'default_provider': 'openai', 'default_model': 'gpt-4o-mini', 'parameters': {'temperature': 0.0, 'max_tokens': 1000, 'top_p': 1.0, 'frequency_penalty': 0.0, 'presence_penalty': 0.0}, 'providers': {'azure': {'api_version': '2024-02-15-preview', 'api_type': 'azure'}, 'openai': {'api_type': 'open_ai'}, 'anthropic': {'api_type': 'anthropic'}}}, 'features': {'use_caching': True, 'use_async': True, 'use_batching': True, 'enable_finnish_support': True}, 'language': 'fi'}\n",
      "DEBUG: Trying library paths: ['C:\\\\scripts\\\\Voikko\\\\libvoikko-1.dll', 'C:\\\\Program Files\\\\Voikko\\\\libvoikko-1.dll', 'C:\\\\Voikko\\\\libvoikko-1.dll']\n",
      "DEBUG: Trying dictionary paths: ['C:\\\\scripts\\\\Voikko', 'C:\\\\Program Files\\\\Voikko', 'C:\\\\Voikko']\n",
      "DEBUG: Added C:\\scripts\\Voikko to DLL search path\n",
      "INFO: Successfully initialized Voikko with path: C:\\scripts\\Voikko\n",
      "INFO: Language switched to fi\n",
      "INFO: HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing response: {'categories': [{'category': 'Machine Learning', 'confidence': 0.95, 'explanation': 'The text discusses the training of machine learning models using large datasets to identify patterns, which is a core concept in the field of machine learning.', 'evidence': [{'text': 'Koneoppimismalleja koulutetaan suurilla datajoukolla tunnistamaan kaavoja.', 'relevance': 0.9, 'matched_keywords': ['koneoppimismalli', 'datajoukko', 'kaava'], 'context': 'The sentence explicitly mentions training machine learning models with large datasets to recognize patterns.'}, {'text': 'Neuroverkon arkkitehtuuri sisältää useita kerroksia piirteiden erottamiseen.', 'relevance': 0.9, 'matched_keywords': ['neuroverkon', 'arkkitehtuuri', 'kerros', 'piirre'], 'context': 'This part of the text refers to the architecture of neural networks, which is a specific type of machine learning model.'}], 'themes': ['artificial intelligence', 'data analysis']}], 'relationships': {'Machine Learning': ['Artificial Intelligence', 'Data Science']}}\n",
      "\n",
      "Processing category: {'category': 'Machine Learning', 'confidence': 0.95, 'explanation': 'The text discusses the training of machine learning models using large datasets to identify patterns, which is a core concept in the field of machine learning.', 'evidence': [{'text': 'Koneoppimismalleja koulutetaan suurilla datajoukolla tunnistamaan kaavoja.', 'relevance': 0.9, 'matched_keywords': ['koneoppimismalli', 'datajoukko', 'kaava'], 'context': 'The sentence explicitly mentions training machine learning models with large datasets to recognize patterns.'}, {'text': 'Neuroverkon arkkitehtuuri sisältää useita kerroksia piirteiden erottamiseen.', 'relevance': 0.9, 'matched_keywords': ['neuroverkon', 'arkkitehtuuri', 'kerros', 'piirre'], 'context': 'This part of the text refers to the architecture of neural networks, which is a specific type of machine learning model.'}], 'themes': ['artificial intelligence', 'data analysis']}\n",
      "Created category: name='Machine Learning' confidence=0.95 description='The text discusses the training of machine learning models using large datasets to identify patterns, which is a core concept in the field of machine learning.' evidence=[Evidence(text='Koneoppimismalleja koulutetaan suurilla datajoukolla tunnistamaan kaavoja.', relevance=0.9), Evidence(text='Neuroverkon arkkitehtuuri sisältää useita kerroksia piirteiden erottamiseen.', relevance=0.9)] themes=['artificial intelligence', 'data analysis']\n",
      "\n",
      "Final categories: [CategoryMatch(name='Machine Learning', confidence=0.95, description='The text discusses the training of machine learning models using large datasets to identify patterns, which is a core concept in the field of machine learning.', evidence=[Evidence(text='Koneoppimismalleja koulutetaan suurilla datajoukolla tunnistamaan kaavoja.', relevance=0.9), Evidence(text='Neuroverkon arkkitehtuuri sisältää useita kerroksia piirteiden erottamiseen.', relevance=0.9)], themes=['artificial intelligence', 'data analysis'])]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO: HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO: HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Raw LLM response: {'themes': [{'name': 'Koneoppimismallit', 'description': 'Koneoppimismallit ovat algoritmeja, jotka oppivat suurista datajoukoista tunnistamaan kaavoja ja tekemään ennusteita.', 'confidence': 0.95, 'keywords': ['koneoppimismalli', 'datajoukko', 'oppia'], 'domain': 'technical', 'parent_theme': None}, {'name': 'Neuroverkon arkkitehtuuri', 'description': 'Neuroverkon arkkitehtuuri koostuu useista kerroksista, jotka mahdollistavat piirteiden erottamisen ja syvällisen oppimisen.', 'confidence': 0.9, 'keywords': ['neuroverkko', 'arkkitehtuuri', 'kerros'], 'domain': 'technical', 'parent_theme': 'Koneoppimismallit'}, {'name': 'Data ja sen merkitys', 'description': 'Suurten datajoukkojen käyttö on keskeistä koneoppimismallien tehokkuuden ja tarkkuuden kannalta.', 'confidence': 0.85, 'keywords': ['data', 'datajoukko', 'tunnistaminen'], 'domain': 'business', 'parent_theme': None}], 'evidence': {'Koneoppimismallit': [{'text': 'Koneoppimismalleja koulutetaan suurilla datajoukolla tunnistamaan kaavoja.', 'relevance': 0.9, 'keywords': ['koneoppimismalli', 'datajoukko']}], 'Neuroverkon arkkitehtuuri': [{'text': 'Neuroverkon arkkitehtuuri sisältää useita kerroksia piirteiden erottamiseen.', 'relevance': 0.9, 'keywords': ['neuroverkko', 'kerros']}], 'Data ja sen merkitys': [{'text': 'Koneoppimismalleja koulutetaan suurilla datajoukolla.', 'relevance': 0.85, 'keywords': ['data', 'datajoukko']}]}, 'relationships': {'Koneoppimismallit': ['Neuroverkon arkkitehtuuri', 'Data ja sen merkitys'], 'Neuroverkon arkkitehtuuri': ['Koneoppimismallit'], 'Data ja sen merkitys': ['Koneoppimismallit']}}\n",
      "\n",
      "Processed LLM response: {'themes': [{'name': 'Koneoppimismallit', 'description': 'Koneoppimismallit ovat algoritmeja, jotka oppivat suurista datajoukoista tunnistamaan kaavoja ja tekemään ennusteita.', 'confidence': 0.95, 'keywords': ['koneoppimismalli', 'datajoukko', 'oppia'], 'domain': 'technical', 'parent_theme': None}, {'name': 'Neuroverkon arkkitehtuuri', 'description': 'Neuroverkon arkkitehtuuri koostuu useista kerroksista, jotka mahdollistavat piirteiden erottamisen ja syvällisen oppimisen.', 'confidence': 0.9, 'keywords': ['neuroverkko', 'arkkitehtuuri', 'kerros'], 'domain': 'technical', 'parent_theme': 'Koneoppimismallit'}, {'name': 'Data ja sen merkitys', 'description': 'Suurten datajoukkojen käyttö on keskeistä koneoppimismallien tehokkuuden ja tarkkuuden kannalta.', 'confidence': 0.85, 'keywords': ['data', 'datajoukko', 'tunnistaminen'], 'domain': 'business', 'parent_theme': None}], 'evidence': {'Koneoppimismallit': [{'text': 'Koneoppimismalleja koulutetaan suurilla datajoukolla tunnistamaan kaavoja.', 'relevance': 0.9, 'keywords': ['koneoppimismalli', 'datajoukko']}], 'Neuroverkon arkkitehtuuri': [{'text': 'Neuroverkon arkkitehtuuri sisältää useita kerroksia piirteiden erottamiseen.', 'relevance': 0.9, 'keywords': ['neuroverkko', 'kerros']}], 'Data ja sen merkitys': [{'text': 'Koneoppimismalleja koulutetaan suurilla datajoukolla.', 'relevance': 0.85, 'keywords': ['data', 'datajoukko']}]}, 'relationships': {'Koneoppimismallit': ['Neuroverkon arkkitehtuuri', 'Data ja sen merkitys'], 'Neuroverkon arkkitehtuuri': ['Koneoppimismallit'], 'Data ja sen merkitys': ['Koneoppimismallit']}}\n",
      "2024-12-11 12:04:39,897 - FileUtils.core.file_utils - INFO - Project root: c:\\Users\\tja\\OneDrive - Rastor-instituutti ry\\Tiedostot\\Rastor-instituutti\\kehittäminen\\analytiikka\\repos\\semantic-text-analyzer\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO: Project root: c:\\Users\\tja\\OneDrive - Rastor-instituutti ry\\Tiedostot\\Rastor-instituutti\\kehittäminen\\analytiikka\\repos\\semantic-text-analyzer\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-12-11 12:04:39,924 - FileUtils.core.file_utils - INFO - FileUtils initialized with local storage\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO: FileUtils initialized with local storage\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-12-11 12:04:40,011 - FileUtils.core.file_utils - INFO - Project root: c:\\Users\\tja\\OneDrive - Rastor-instituutti ry\\Tiedostot\\Rastor-instituutti\\kehittäminen\\analytiikka\\repos\\semantic-text-analyzer\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO: Project root: c:\\Users\\tja\\OneDrive - Rastor-instituutti ry\\Tiedostot\\Rastor-instituutti\\kehittäminen\\analytiikka\\repos\\semantic-text-analyzer\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-12-11 12:04:40,023 - FileUtils.core.file_utils - INFO - FileUtils initialized with local storage\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO: FileUtils initialized with local storage\n",
      "INFO: Loaded 747 stopwords from c:\\Users\\tja\\OneDrive - Rastor-instituutti ry\\Tiedostot\\Rastor-instituutti\\kehittäminen\\analytiikka\\repos\\semantic-text-analyzer\\data\\configurations\\stop_words\\fi.txt\n",
      "DEBUG: Initialized with config: {'default_language': 'en', 'content_column': 'content', 'analysis': {'keywords': {'max_keywords': 5, 'min_keyword_length': 3, 'include_compounds': True}, 'themes': {'max_themes': 3, 'min_confidence': 0.5, 'include_hierarchy': True}, 'categories': {'max_categories': 3, 'min_confidence': 0.3, 'require_evidence': True}}, 'models': {'default_provider': 'openai', 'default_model': 'gpt-4o-mini', 'parameters': {'temperature': 0.0, 'max_tokens': 1000, 'top_p': 1.0, 'frequency_penalty': 0.0, 'presence_penalty': 0.0}, 'providers': {'azure': {'api_version': '2024-02-15-preview', 'api_type': 'azure'}, 'openai': {'api_type': 'open_ai'}, 'anthropic': {'api_type': 'anthropic'}}}, 'features': {'use_caching': True, 'use_async': True, 'use_batching': True, 'enable_finnish_support': True}, 'language': 'fi'}\n",
      "DEBUG: Trying library paths: ['C:\\\\scripts\\\\Voikko\\\\libvoikko-1.dll', 'C:\\\\Program Files\\\\Voikko\\\\libvoikko-1.dll', 'C:\\\\Voikko\\\\libvoikko-1.dll']\n",
      "DEBUG: Trying dictionary paths: ['C:\\\\scripts\\\\Voikko', 'C:\\\\Program Files\\\\Voikko', 'C:\\\\Voikko']\n",
      "DEBUG: Added C:\\scripts\\Voikko to DLL search path\n",
      "INFO: Successfully initialized Voikko with path: C:\\scripts\\Voikko\n",
      "INFO: Language switched to fi\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-12-11 12:04:40,092 - FileUtils.core.file_utils - INFO - Project root: c:\\Users\\tja\\OneDrive - Rastor-instituutti ry\\Tiedostot\\Rastor-instituutti\\kehittäminen\\analytiikka\\repos\\semantic-text-analyzer\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO: Project root: c:\\Users\\tja\\OneDrive - Rastor-instituutti ry\\Tiedostot\\Rastor-instituutti\\kehittäminen\\analytiikka\\repos\\semantic-text-analyzer\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-12-11 12:04:40,102 - FileUtils.core.file_utils - INFO - FileUtils initialized with local storage\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO: FileUtils initialized with local storage\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-12-11 12:04:40,254 - FileUtils.core.file_utils - INFO - Project root: c:\\Users\\tja\\OneDrive - Rastor-instituutti ry\\Tiedostot\\Rastor-instituutti\\kehittäminen\\analytiikka\\repos\\semantic-text-analyzer\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO: Project root: c:\\Users\\tja\\OneDrive - Rastor-instituutti ry\\Tiedostot\\Rastor-instituutti\\kehittäminen\\analytiikka\\repos\\semantic-text-analyzer\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-12-11 12:04:40,268 - FileUtils.core.file_utils - INFO - FileUtils initialized with local storage\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO: FileUtils initialized with local storage\n",
      "INFO: Loaded 747 stopwords from c:\\Users\\tja\\OneDrive - Rastor-instituutti ry\\Tiedostot\\Rastor-instituutti\\kehittäminen\\analytiikka\\repos\\semantic-text-analyzer\\data\\configurations\\stop_words\\fi.txt\n",
      "DEBUG: Initialized with config: {'default_language': 'en', 'content_column': 'content', 'analysis': {'keywords': {'max_keywords': 5, 'min_keyword_length': 3, 'include_compounds': True}, 'themes': {'max_themes': 3, 'min_confidence': 0.5, 'include_hierarchy': True}, 'categories': {'max_categories': 3, 'min_confidence': 0.3, 'require_evidence': True}}, 'models': {'default_provider': 'openai', 'default_model': 'gpt-4o-mini', 'parameters': {'temperature': 0.0, 'max_tokens': 1000, 'top_p': 1.0, 'frequency_penalty': 0.0, 'presence_penalty': 0.0}, 'providers': {'azure': {'api_version': '2024-02-15-preview', 'api_type': 'azure'}, 'openai': {'api_type': 'open_ai'}, 'anthropic': {'api_type': 'anthropic'}}}, 'features': {'use_caching': True, 'use_async': True, 'use_batching': True, 'enable_finnish_support': True}, 'language': 'fi'}\n",
      "DEBUG: Trying library paths: ['C:\\\\scripts\\\\Voikko\\\\libvoikko-1.dll', 'C:\\\\Program Files\\\\Voikko\\\\libvoikko-1.dll', 'C:\\\\Voikko\\\\libvoikko-1.dll']\n",
      "DEBUG: Trying dictionary paths: ['C:\\\\scripts\\\\Voikko', 'C:\\\\Program Files\\\\Voikko', 'C:\\\\Voikko']\n",
      "DEBUG: Added C:\\scripts\\Voikko to DLL search path\n",
      "INFO: Successfully initialized Voikko with path: C:\\scripts\\Voikko\n",
      "INFO: Language switched to fi\n",
      "INFO: HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing response: {'categories': [{'category': 'Cloud Services', 'confidence': 0.85, 'explanation': 'The text discusses cloud services and their scalable infrastructure, which directly relates to the category of Cloud Services.', 'evidence': [{'text': 'Pilvipalvelut tarjoavat skaalautuvan infrastruktuurin käyttöönottoon.', 'relevance': 0.9, 'matched_keywords': ['pilvipalvelu', 'infrastruktuuri'], 'context': 'The sentence emphasizes the scalability of cloud services.'}], 'themes': ['scalability', 'infrastructure']}, {'category': 'Microservices Architecture', 'confidence': 0.8, 'explanation': 'The mention of microservices architecture indicates a focus on modular system design, which is a key aspect of this category.', 'evidence': [{'text': 'Mikropalveluarkkitehtuuri mahdollistaa modulaarisen järjestelmäsuunnittelun.', 'relevance': 0.9, 'matched_keywords': ['mikropalvelu', 'modulaarinen'], 'context': 'This sentence highlights the modular design capabilities of microservices architecture.'}], 'themes': ['modularity', 'system design']}], 'relationships': {'Cloud Services': ['Infrastructure', 'IT Services'], 'Microservices Architecture': ['Software Development', 'System Design']}}\n",
      "\n",
      "Processing category: {'category': 'Cloud Services', 'confidence': 0.85, 'explanation': 'The text discusses cloud services and their scalable infrastructure, which directly relates to the category of Cloud Services.', 'evidence': [{'text': 'Pilvipalvelut tarjoavat skaalautuvan infrastruktuurin käyttöönottoon.', 'relevance': 0.9, 'matched_keywords': ['pilvipalvelu', 'infrastruktuuri'], 'context': 'The sentence emphasizes the scalability of cloud services.'}], 'themes': ['scalability', 'infrastructure']}\n",
      "Created category: name='Cloud Services' confidence=0.85 description='The text discusses cloud services and their scalable infrastructure, which directly relates to the category of Cloud Services.' evidence=[Evidence(text='Pilvipalvelut tarjoavat skaalautuvan infrastruktuurin käyttöönottoon.', relevance=0.9)] themes=['scalability', 'infrastructure']\n",
      "\n",
      "Processing category: {'category': 'Microservices Architecture', 'confidence': 0.8, 'explanation': 'The mention of microservices architecture indicates a focus on modular system design, which is a key aspect of this category.', 'evidence': [{'text': 'Mikropalveluarkkitehtuuri mahdollistaa modulaarisen järjestelmäsuunnittelun.', 'relevance': 0.9, 'matched_keywords': ['mikropalvelu', 'modulaarinen'], 'context': 'This sentence highlights the modular design capabilities of microservices architecture.'}], 'themes': ['modularity', 'system design']}\n",
      "Created category: name='Microservices Architecture' confidence=0.8 description='The mention of microservices architecture indicates a focus on modular system design, which is a key aspect of this category.' evidence=[Evidence(text='Mikropalveluarkkitehtuuri mahdollistaa modulaarisen järjestelmäsuunnittelun.', relevance=0.9)] themes=['modularity', 'system design']\n",
      "\n",
      "Final categories: [CategoryMatch(name='Cloud Services', confidence=0.85, description='The text discusses cloud services and their scalable infrastructure, which directly relates to the category of Cloud Services.', evidence=[Evidence(text='Pilvipalvelut tarjoavat skaalautuvan infrastruktuurin käyttöönottoon.', relevance=0.9)], themes=['scalability', 'infrastructure']), CategoryMatch(name='Microservices Architecture', confidence=0.8, description='The mention of microservices architecture indicates a focus on modular system design, which is a key aspect of this category.', evidence=[Evidence(text='Mikropalveluarkkitehtuuri mahdollistaa modulaarisen järjestelmäsuunnittelun.', relevance=0.9)], themes=['modularity', 'system design'])]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO: HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Raw LLM response: {'themes': [{'name': 'Pilvipalvelut', 'description': 'Pilvipalvelut tarjoavat skaalautuvan infrastruktuurin, joka mahdollistaa joustavan ja tehokkaan resurssien käytön liiketoiminnassa.', 'confidence': 0.95, 'keywords': ['pilvipalvelu', 'skaalautuva', 'infrastruktuuri'], 'domain': 'technical/business'}, {'name': 'Mikropalveluarkkitehtuuri', 'description': 'Mikropalveluarkkitehtuuri mahdollistaa modulaarisen järjestelmäsuunnittelun, mikä parantaa järjestelmien hallittavuutta ja kehityksen nopeutta.', 'confidence': 0.9, 'keywords': ['mikropalvelu', 'modulaarinen', 'järjestelmäsuunnittelu'], 'domain': 'technical/business'}], 'evidence': {'Pilvipalvelut': [{'text': 'Pilvipalvelut tarjoavat skaalautuvan infrastruktuurin käyttöönottoon.', 'relevance': 0.9, 'keywords': ['pilvipalvelu', 'skaalautuva', 'infrastruktuuri']}], 'Mikropalveluarkkitehtuuri': [{'text': 'Mikropalveluarkkitehtuuri mahdollistaa modulaarisen järjestelmäsuunnittelun.', 'relevance': 0.9, 'keywords': ['mikropalvelu', 'modulaarinen', 'järjestelmäsuunnittelu']}]}, 'relationships': {'Pilvipalvelut': ['Mikropalveluarkkitehtuuri']}}\n",
      "\n",
      "Processed LLM response: {'themes': [{'name': 'Pilvipalvelut', 'description': 'Pilvipalvelut tarjoavat skaalautuvan infrastruktuurin, joka mahdollistaa joustavan ja tehokkaan resurssien käytön liiketoiminnassa.', 'confidence': 0.95, 'keywords': ['pilvipalvelu', 'skaalautuva', 'infrastruktuuri'], 'domain': 'technical/business'}, {'name': 'Mikropalveluarkkitehtuuri', 'description': 'Mikropalveluarkkitehtuuri mahdollistaa modulaarisen järjestelmäsuunnittelun, mikä parantaa järjestelmien hallittavuutta ja kehityksen nopeutta.', 'confidence': 0.9, 'keywords': ['mikropalvelu', 'modulaarinen', 'järjestelmäsuunnittelu'], 'domain': 'technical/business'}], 'evidence': {'Pilvipalvelut': [{'text': 'Pilvipalvelut tarjoavat skaalautuvan infrastruktuurin käyttöönottoon.', 'relevance': 0.9, 'keywords': ['pilvipalvelu', 'skaalautuva', 'infrastruktuuri']}], 'Mikropalveluarkkitehtuuri': [{'text': 'Mikropalveluarkkitehtuuri mahdollistaa modulaarisen järjestelmäsuunnittelun.', 'relevance': 0.9, 'keywords': ['mikropalvelu', 'modulaarinen', 'järjestelmäsuunnittelu']}]}, 'relationships': {'Pilvipalvelut': ['Mikropalveluarkkitehtuuri']}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO: HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-12-11 12:04:48,262 - FileUtils.core.file_utils - INFO - Project root: c:\\Users\\tja\\OneDrive - Rastor-instituutti ry\\Tiedostot\\Rastor-instituutti\\kehittäminen\\analytiikka\\repos\\semantic-text-analyzer\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO: Project root: c:\\Users\\tja\\OneDrive - Rastor-instituutti ry\\Tiedostot\\Rastor-instituutti\\kehittäminen\\analytiikka\\repos\\semantic-text-analyzer\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-12-11 12:04:48,272 - FileUtils.core.file_utils - INFO - FileUtils initialized with local storage\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO: FileUtils initialized with local storage\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-12-11 12:04:48,361 - FileUtils.core.file_utils - INFO - Project root: c:\\Users\\tja\\OneDrive - Rastor-instituutti ry\\Tiedostot\\Rastor-instituutti\\kehittäminen\\analytiikka\\repos\\semantic-text-analyzer\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO: Project root: c:\\Users\\tja\\OneDrive - Rastor-instituutti ry\\Tiedostot\\Rastor-instituutti\\kehittäminen\\analytiikka\\repos\\semantic-text-analyzer\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-12-11 12:04:48,370 - FileUtils.core.file_utils - INFO - FileUtils initialized with local storage\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO: FileUtils initialized with local storage\n",
      "INFO: Loaded 747 stopwords from c:\\Users\\tja\\OneDrive - Rastor-instituutti ry\\Tiedostot\\Rastor-instituutti\\kehittäminen\\analytiikka\\repos\\semantic-text-analyzer\\data\\configurations\\stop_words\\fi.txt\n",
      "DEBUG: Initialized with config: {'default_language': 'en', 'content_column': 'content', 'analysis': {'keywords': {'max_keywords': 5, 'min_keyword_length': 3, 'include_compounds': True}, 'themes': {'max_themes': 3, 'min_confidence': 0.5, 'include_hierarchy': True}, 'categories': {'max_categories': 3, 'min_confidence': 0.3, 'require_evidence': True}}, 'models': {'default_provider': 'openai', 'default_model': 'gpt-4o-mini', 'parameters': {'temperature': 0.0, 'max_tokens': 1000, 'top_p': 1.0, 'frequency_penalty': 0.0, 'presence_penalty': 0.0}, 'providers': {'azure': {'api_version': '2024-02-15-preview', 'api_type': 'azure'}, 'openai': {'api_type': 'open_ai'}, 'anthropic': {'api_type': 'anthropic'}}}, 'features': {'use_caching': True, 'use_async': True, 'use_batching': True, 'enable_finnish_support': True}, 'language': 'fi'}\n",
      "DEBUG: Trying library paths: ['C:\\\\scripts\\\\Voikko\\\\libvoikko-1.dll', 'C:\\\\Program Files\\\\Voikko\\\\libvoikko-1.dll', 'C:\\\\Voikko\\\\libvoikko-1.dll']\n",
      "DEBUG: Trying dictionary paths: ['C:\\\\scripts\\\\Voikko', 'C:\\\\Program Files\\\\Voikko', 'C:\\\\Voikko']\n",
      "DEBUG: Added C:\\scripts\\Voikko to DLL search path\n",
      "INFO: Successfully initialized Voikko with path: C:\\scripts\\Voikko\n",
      "INFO: Language switched to fi\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-12-11 12:04:48,440 - FileUtils.core.file_utils - INFO - Project root: c:\\Users\\tja\\OneDrive - Rastor-instituutti ry\\Tiedostot\\Rastor-instituutti\\kehittäminen\\analytiikka\\repos\\semantic-text-analyzer\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO: Project root: c:\\Users\\tja\\OneDrive - Rastor-instituutti ry\\Tiedostot\\Rastor-instituutti\\kehittäminen\\analytiikka\\repos\\semantic-text-analyzer\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-12-11 12:04:48,458 - FileUtils.core.file_utils - INFO - FileUtils initialized with local storage\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO: FileUtils initialized with local storage\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-12-11 12:04:48,595 - FileUtils.core.file_utils - INFO - Project root: c:\\Users\\tja\\OneDrive - Rastor-instituutti ry\\Tiedostot\\Rastor-instituutti\\kehittäminen\\analytiikka\\repos\\semantic-text-analyzer\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO: Project root: c:\\Users\\tja\\OneDrive - Rastor-instituutti ry\\Tiedostot\\Rastor-instituutti\\kehittäminen\\analytiikka\\repos\\semantic-text-analyzer\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-12-11 12:04:48,608 - FileUtils.core.file_utils - INFO - FileUtils initialized with local storage\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO: FileUtils initialized with local storage\n",
      "INFO: Loaded 747 stopwords from c:\\Users\\tja\\OneDrive - Rastor-instituutti ry\\Tiedostot\\Rastor-instituutti\\kehittäminen\\analytiikka\\repos\\semantic-text-analyzer\\data\\configurations\\stop_words\\fi.txt\n",
      "DEBUG: Initialized with config: {'default_language': 'en', 'content_column': 'content', 'analysis': {'keywords': {'max_keywords': 5, 'min_keyword_length': 3, 'include_compounds': True}, 'themes': {'max_themes': 3, 'min_confidence': 0.5, 'include_hierarchy': True}, 'categories': {'max_categories': 3, 'min_confidence': 0.3, 'require_evidence': True}}, 'models': {'default_provider': 'openai', 'default_model': 'gpt-4o-mini', 'parameters': {'temperature': 0.0, 'max_tokens': 1000, 'top_p': 1.0, 'frequency_penalty': 0.0, 'presence_penalty': 0.0}, 'providers': {'azure': {'api_version': '2024-02-15-preview', 'api_type': 'azure'}, 'openai': {'api_type': 'open_ai'}, 'anthropic': {'api_type': 'anthropic'}}}, 'features': {'use_caching': True, 'use_async': True, 'use_batching': True, 'enable_finnish_support': True}, 'language': 'fi'}\n",
      "DEBUG: Trying library paths: ['C:\\\\scripts\\\\Voikko\\\\libvoikko-1.dll', 'C:\\\\Program Files\\\\Voikko\\\\libvoikko-1.dll', 'C:\\\\Voikko\\\\libvoikko-1.dll']\n",
      "DEBUG: Trying dictionary paths: ['C:\\\\scripts\\\\Voikko', 'C:\\\\Program Files\\\\Voikko', 'C:\\\\Voikko']\n",
      "DEBUG: Added C:\\scripts\\Voikko to DLL search path\n",
      "INFO: Successfully initialized Voikko with path: C:\\scripts\\Voikko\n",
      "INFO: Language switched to fi\n",
      "INFO: HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO: HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Raw LLM response: {'themes': [{'name': 'Versionhallintajärjestelmät', 'description': 'Versionhallintajärjestelmät ovat työkaluja, jotka seuraavat ja hallitsevat lähdekoodin muutoksia, mahdollistaen tehokkaan kehitystyön.', 'confidence': 0.9, 'keywords': ['versionhallinta', 'lähdekoodi', 'muutokset'], 'domain': 'technical', 'parent_theme': None}, {'name': 'Jatkuva integraatio', 'description': 'Jatkuva integraatio on prosessi, joka varmistaa koodin laadun ja mahdollistaa automaattitestauksen, mikä parantaa ohjelmistokehityksen tehokkuutta.', 'confidence': 0.95, 'keywords': ['jatkuva', 'integraatio', 'laatu', 'automaattitestaus'], 'domain': 'technical', 'parent_theme': None}], 'evidence': {'Versionhallintajärjestelmät': [{'text': 'Versionhallintajärjestelmät seuraavat lähdekoodin muutoksia.', 'relevance': 0.9, 'keywords': ['versionhallinta', 'lähdekoodi']}], 'Jatkuva integraatio': [{'text': 'Jatkuva integraatio varmistaa koodin laadun ja automaattitestauksen.', 'relevance': 0.95, 'keywords': ['jatkuva', 'laatu', 'automaattitestaus']}]}, 'relationships': {'Versionhallintajärjestelmät': ['Jatkuva integraatio'], 'Jatkuva integraatio': []}}\n",
      "\n",
      "Processed LLM response: {'themes': [{'name': 'Versionhallintajärjestelmät', 'description': 'Versionhallintajärjestelmät ovat työkaluja, jotka seuraavat ja hallitsevat lähdekoodin muutoksia, mahdollistaen tehokkaan kehitystyön.', 'confidence': 0.9, 'keywords': ['versionhallinta', 'lähdekoodi', 'muutokset'], 'domain': 'technical', 'parent_theme': None}, {'name': 'Jatkuva integraatio', 'description': 'Jatkuva integraatio on prosessi, joka varmistaa koodin laadun ja mahdollistaa automaattitestauksen, mikä parantaa ohjelmistokehityksen tehokkuutta.', 'confidence': 0.95, 'keywords': ['jatkuva', 'integraatio', 'laatu', 'automaattitestaus'], 'domain': 'technical', 'parent_theme': None}], 'evidence': {'Versionhallintajärjestelmät': [{'text': 'Versionhallintajärjestelmät seuraavat lähdekoodin muutoksia.', 'relevance': 0.9, 'keywords': ['versionhallinta', 'lähdekoodi']}], 'Jatkuva integraatio': [{'text': 'Jatkuva integraatio varmistaa koodin laadun ja automaattitestauksen.', 'relevance': 0.95, 'keywords': ['jatkuva', 'laatu', 'automaattitestaus']}]}, 'relationships': {'Versionhallintajärjestelmät': ['Jatkuva integraatio'], 'Jatkuva integraatio': []}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO: HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing response: {'categories': [{'category': 'Software Development', 'confidence': 0.85, 'explanation': 'The text discusses version control systems and continuous integration, which are key concepts in software development.', 'evidence': [{'text': 'Versionhallintajärjestelmät seuraavat lähdekoodin muutoksia.', 'relevance': 0.9, 'matched_keywords': ['lähdekoodi', 'muutos', 'versionhallintajärjestelmät'], 'context': 'The sentence introduces version control systems that track changes in source code.'}, {'text': 'Jatkuva integraatio varmistaa koodin laadun ja automaattitestauksen.', 'relevance': 0.9, 'matched_keywords': ['jatkuva', 'integraatio', 'laatu', 'koodi'], 'context': 'This part emphasizes the importance of continuous integration in ensuring code quality and automated testing.'}], 'themes': ['version control', 'continuous integration', 'code quality']}], 'relationships': {'Software Development': ['DevOps', 'Quality Assurance']}}\n",
      "\n",
      "Processing category: {'category': 'Software Development', 'confidence': 0.85, 'explanation': 'The text discusses version control systems and continuous integration, which are key concepts in software development.', 'evidence': [{'text': 'Versionhallintajärjestelmät seuraavat lähdekoodin muutoksia.', 'relevance': 0.9, 'matched_keywords': ['lähdekoodi', 'muutos', 'versionhallintajärjestelmät'], 'context': 'The sentence introduces version control systems that track changes in source code.'}, {'text': 'Jatkuva integraatio varmistaa koodin laadun ja automaattitestauksen.', 'relevance': 0.9, 'matched_keywords': ['jatkuva', 'integraatio', 'laatu', 'koodi'], 'context': 'This part emphasizes the importance of continuous integration in ensuring code quality and automated testing.'}], 'themes': ['version control', 'continuous integration', 'code quality']}\n",
      "Created category: name='Software Development' confidence=0.85 description='The text discusses version control systems and continuous integration, which are key concepts in software development.' evidence=[Evidence(text='Versionhallintajärjestelmät seuraavat lähdekoodin muutoksia.', relevance=0.9), Evidence(text='Jatkuva integraatio varmistaa koodin laadun ja automaattitestauksen.', relevance=0.9)] themes=['version control', 'continuous integration', 'code quality']\n",
      "\n",
      "Final categories: [CategoryMatch(name='Software Development', confidence=0.85, description='The text discusses version control systems and continuous integration, which are key concepts in software development.', evidence=[Evidence(text='Versionhallintajärjestelmät seuraavat lähdekoodin muutoksia.', relevance=0.9), Evidence(text='Jatkuva integraatio varmistaa koodin laadun ja automaattitestauksen.', relevance=0.9)], themes=['version control', 'continuous integration', 'code quality'])]\n",
      "2024-12-11 12:04:56,381 - FileUtils.core.file_utils - INFO - Project root: c:\\Users\\tja\\OneDrive - Rastor-instituutti ry\\Tiedostot\\Rastor-instituutti\\kehittäminen\\analytiikka\\repos\\semantic-text-analyzer\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO: Project root: c:\\Users\\tja\\OneDrive - Rastor-instituutti ry\\Tiedostot\\Rastor-instituutti\\kehittäminen\\analytiikka\\repos\\semantic-text-analyzer\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-12-11 12:04:56,389 - FileUtils.core.file_utils - INFO - FileUtils initialized with local storage\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO: FileUtils initialized with local storage\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-12-11 12:04:56,545 - FileUtils.core.file_utils - INFO - Project root: c:\\Users\\tja\\OneDrive - Rastor-instituutti ry\\Tiedostot\\Rastor-instituutti\\kehittäminen\\analytiikka\\repos\\semantic-text-analyzer\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO: Project root: c:\\Users\\tja\\OneDrive - Rastor-instituutti ry\\Tiedostot\\Rastor-instituutti\\kehittäminen\\analytiikka\\repos\\semantic-text-analyzer\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-12-11 12:04:56,554 - FileUtils.core.file_utils - INFO - FileUtils initialized with local storage\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO: FileUtils initialized with local storage\n",
      "INFO: Loaded 747 stopwords from c:\\Users\\tja\\OneDrive - Rastor-instituutti ry\\Tiedostot\\Rastor-instituutti\\kehittäminen\\analytiikka\\repos\\semantic-text-analyzer\\data\\configurations\\stop_words\\fi.txt\n",
      "DEBUG: Initialized with config: {'default_language': 'en', 'content_column': 'content', 'analysis': {'keywords': {'max_keywords': 5, 'min_keyword_length': 3, 'include_compounds': True}, 'themes': {'max_themes': 3, 'min_confidence': 0.5, 'include_hierarchy': True}, 'categories': {'max_categories': 3, 'min_confidence': 0.3, 'require_evidence': True}}, 'models': {'default_provider': 'openai', 'default_model': 'gpt-4o-mini', 'parameters': {'temperature': 0.0, 'max_tokens': 1000, 'top_p': 1.0, 'frequency_penalty': 0.0, 'presence_penalty': 0.0}, 'providers': {'azure': {'api_version': '2024-02-15-preview', 'api_type': 'azure'}, 'openai': {'api_type': 'open_ai'}, 'anthropic': {'api_type': 'anthropic'}}}, 'features': {'use_caching': True, 'use_async': True, 'use_batching': True, 'enable_finnish_support': True}, 'language': 'fi'}\n",
      "DEBUG: Trying library paths: ['C:\\\\scripts\\\\Voikko\\\\libvoikko-1.dll', 'C:\\\\Program Files\\\\Voikko\\\\libvoikko-1.dll', 'C:\\\\Voikko\\\\libvoikko-1.dll']\n",
      "DEBUG: Trying dictionary paths: ['C:\\\\scripts\\\\Voikko', 'C:\\\\Program Files\\\\Voikko', 'C:\\\\Voikko']\n",
      "DEBUG: Added C:\\scripts\\Voikko to DLL search path\n",
      "INFO: Successfully initialized Voikko with path: C:\\scripts\\Voikko\n",
      "INFO: Language switched to fi\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-12-11 12:04:56,622 - FileUtils.core.file_utils - INFO - Project root: c:\\Users\\tja\\OneDrive - Rastor-instituutti ry\\Tiedostot\\Rastor-instituutti\\kehittäminen\\analytiikka\\repos\\semantic-text-analyzer\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO: Project root: c:\\Users\\tja\\OneDrive - Rastor-instituutti ry\\Tiedostot\\Rastor-instituutti\\kehittäminen\\analytiikka\\repos\\semantic-text-analyzer\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-12-11 12:04:56,632 - FileUtils.core.file_utils - INFO - FileUtils initialized with local storage\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO: FileUtils initialized with local storage\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-12-11 12:04:56,723 - FileUtils.core.file_utils - INFO - Project root: c:\\Users\\tja\\OneDrive - Rastor-instituutti ry\\Tiedostot\\Rastor-instituutti\\kehittäminen\\analytiikka\\repos\\semantic-text-analyzer\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO: Project root: c:\\Users\\tja\\OneDrive - Rastor-instituutti ry\\Tiedostot\\Rastor-instituutti\\kehittäminen\\analytiikka\\repos\\semantic-text-analyzer\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-12-11 12:04:56,733 - FileUtils.core.file_utils - INFO - FileUtils initialized with local storage\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO: FileUtils initialized with local storage\n",
      "INFO: Loaded 747 stopwords from c:\\Users\\tja\\OneDrive - Rastor-instituutti ry\\Tiedostot\\Rastor-instituutti\\kehittäminen\\analytiikka\\repos\\semantic-text-analyzer\\data\\configurations\\stop_words\\fi.txt\n",
      "DEBUG: Initialized with config: {'default_language': 'en', 'content_column': 'content', 'analysis': {'keywords': {'max_keywords': 5, 'min_keyword_length': 3, 'include_compounds': True}, 'themes': {'max_themes': 3, 'min_confidence': 0.5, 'include_hierarchy': True}, 'categories': {'max_categories': 3, 'min_confidence': 0.3, 'require_evidence': True}}, 'models': {'default_provider': 'openai', 'default_model': 'gpt-4o-mini', 'parameters': {'temperature': 0.0, 'max_tokens': 1000, 'top_p': 1.0, 'frequency_penalty': 0.0, 'presence_penalty': 0.0}, 'providers': {'azure': {'api_version': '2024-02-15-preview', 'api_type': 'azure'}, 'openai': {'api_type': 'open_ai'}, 'anthropic': {'api_type': 'anthropic'}}}, 'features': {'use_caching': True, 'use_async': True, 'use_batching': True, 'enable_finnish_support': True}, 'language': 'fi'}\n",
      "DEBUG: Trying library paths: ['C:\\\\scripts\\\\Voikko\\\\libvoikko-1.dll', 'C:\\\\Program Files\\\\Voikko\\\\libvoikko-1.dll', 'C:\\\\Voikko\\\\libvoikko-1.dll']\n",
      "DEBUG: Trying dictionary paths: ['C:\\\\scripts\\\\Voikko', 'C:\\\\Program Files\\\\Voikko', 'C:\\\\Voikko']\n",
      "DEBUG: Added C:\\scripts\\Voikko to DLL search path\n",
      "INFO: Successfully initialized Voikko with path: C:\\scripts\\Voikko\n",
      "INFO: Language switched to fi\n",
      "INFO: HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing response: {'categories': [{'category': 'Business Performance', 'confidence': 0.95, 'explanation': 'The text discusses financial results, including revenue growth and improved margins, which are key indicators of business performance.', 'evidence': [{'text': 'Q3 taloudelliset tulokset osoittavat 15% liikevaihdon kasvun ja parantuneet katteet.', 'relevance': 0.9, 'matched_keywords': ['liikevaihto', 'kasvu', 'kate'], 'context': 'The text provides specific financial metrics indicating business performance.'}, {'text': 'Asiakashankinnan kustannukset laskivat ja asiakaspysyvyys parani.', 'relevance': 0.85, 'matched_keywords': ['asiakashankinta', 'kustannus', 'asiakaspysyvyys'], 'context': 'This part of the text highlights cost reduction in customer acquisition and improved customer retention, both of which are critical for assessing business health.'}], 'themes': ['financial growth', 'customer acquisition', 'retention strategies']}], 'relationships': {'Business Performance': ['Financial Analysis', 'Customer Relationship Management']}}\n",
      "\n",
      "Processing category: {'category': 'Business Performance', 'confidence': 0.95, 'explanation': 'The text discusses financial results, including revenue growth and improved margins, which are key indicators of business performance.', 'evidence': [{'text': 'Q3 taloudelliset tulokset osoittavat 15% liikevaihdon kasvun ja parantuneet katteet.', 'relevance': 0.9, 'matched_keywords': ['liikevaihto', 'kasvu', 'kate'], 'context': 'The text provides specific financial metrics indicating business performance.'}, {'text': 'Asiakashankinnan kustannukset laskivat ja asiakaspysyvyys parani.', 'relevance': 0.85, 'matched_keywords': ['asiakashankinta', 'kustannus', 'asiakaspysyvyys'], 'context': 'This part of the text highlights cost reduction in customer acquisition and improved customer retention, both of which are critical for assessing business health.'}], 'themes': ['financial growth', 'customer acquisition', 'retention strategies']}\n",
      "Created category: name='Business Performance' confidence=0.95 description='The text discusses financial results, including revenue growth and improved margins, which are key indicators of business performance.' evidence=[Evidence(text='Q3 taloudelliset tulokset osoittavat 15% liikevaihdon kasvun ja parantuneet katteet.', relevance=0.9), Evidence(text='Asiakashankinnan kustannukset laskivat ja asiakaspysyvyys parani.', relevance=0.85)] themes=['financial growth', 'customer acquisition', 'retention strategies']\n",
      "\n",
      "Final categories: [CategoryMatch(name='Business Performance', confidence=0.95, description='The text discusses financial results, including revenue growth and improved margins, which are key indicators of business performance.', evidence=[Evidence(text='Q3 taloudelliset tulokset osoittavat 15% liikevaihdon kasvun ja parantuneet katteet.', relevance=0.9), Evidence(text='Asiakashankinnan kustannukset laskivat ja asiakaspysyvyys parani.', relevance=0.85)], themes=['financial growth', 'customer acquisition', 'retention strategies'])]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO: HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO: HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Raw LLM response: {'themes': [{'name': 'Taloudellinen kasvu', 'description': 'Viittaa yrityksen liikevaihdon kasvuun ja parantuneisiin taloudellisiin tuloksiin.', 'confidence': 0.95, 'keywords': ['liikevaihto', 'kasvu', 'taloudellinen'], 'domain': 'business', 'parent_theme': None}, {'name': 'Asiakashankinta ja pysyvyys', 'description': 'Käsittelee asiakashankinnan kustannusten laskua ja asiakaspysyvyyden parantumista.', 'confidence': 0.9, 'keywords': ['asiakashankinta', 'asiakaspysyvyys', 'kustannus'], 'domain': 'business', 'parent_theme': None}, {'name': 'Katteet', 'description': 'Viittaa parantuneisiin katteisiin, jotka ovat merkki yrityksen taloudellisesta terveydestä.', 'confidence': 0.85, 'keywords': ['katteet', 'parantunut'], 'domain': 'business', 'parent_theme': 'Taloudellinen kasvu'}], 'evidence': {'Taloudellinen kasvu': [{'text': 'Q3 taloudelliset tulokset osoittavat 15% liikevaihdon kasvun', 'relevance': 0.9, 'keywords': ['liikevaihto', 'kasvu']}], 'Asiakashankinta ja pysyvyys': [{'text': 'Asiakashankinnan kustannukset laskivat ja asiakaspysyvyys parani.', 'relevance': 0.9, 'keywords': ['asiakashankinta', 'asiakaspysyvyys', 'kustannus']}], 'Katteet': [{'text': 'parantuneet katteet', 'relevance': 0.85, 'keywords': ['katteet', 'parantunut']}]}, 'relationships': {'Taloudellinen kasvu': ['Katteet', 'Asiakashankinta ja pysyvyys'], 'Asiakashankinta ja pysyvyys': [], 'Katteet': []}}\n",
      "\n",
      "Processed LLM response: {'themes': [{'name': 'Taloudellinen kasvu', 'description': 'Viittaa yrityksen liikevaihdon kasvuun ja parantuneisiin taloudellisiin tuloksiin.', 'confidence': 0.95, 'keywords': ['liikevaihto', 'kasvu', 'taloudellinen'], 'domain': 'business', 'parent_theme': None}, {'name': 'Asiakashankinta ja pysyvyys', 'description': 'Käsittelee asiakashankinnan kustannusten laskua ja asiakaspysyvyyden parantumista.', 'confidence': 0.9, 'keywords': ['asiakashankinta', 'asiakaspysyvyys', 'kustannus'], 'domain': 'business', 'parent_theme': None}, {'name': 'Katteet', 'description': 'Viittaa parantuneisiin katteisiin, jotka ovat merkki yrityksen taloudellisesta terveydestä.', 'confidence': 0.85, 'keywords': ['katteet', 'parantunut'], 'domain': 'business', 'parent_theme': 'Taloudellinen kasvu'}], 'evidence': {'Taloudellinen kasvu': [{'text': 'Q3 taloudelliset tulokset osoittavat 15% liikevaihdon kasvun', 'relevance': 0.9, 'keywords': ['liikevaihto', 'kasvu']}], 'Asiakashankinta ja pysyvyys': [{'text': 'Asiakashankinnan kustannukset laskivat ja asiakaspysyvyys parani.', 'relevance': 0.9, 'keywords': ['asiakashankinta', 'asiakaspysyvyys', 'kustannus']}], 'Katteet': [{'text': 'parantuneet katteet', 'relevance': 0.85, 'keywords': ['katteet', 'parantunut']}]}, 'relationships': {'Taloudellinen kasvu': ['Katteet', 'Asiakashankinta ja pysyvyys'], 'Asiakashankinta ja pysyvyys': [], 'Katteet': []}}\n",
      "2024-12-11 12:05:05,349 - FileUtils.core.file_utils - INFO - Project root: c:\\Users\\tja\\OneDrive - Rastor-instituutti ry\\Tiedostot\\Rastor-instituutti\\kehittäminen\\analytiikka\\repos\\semantic-text-analyzer\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO: Project root: c:\\Users\\tja\\OneDrive - Rastor-instituutti ry\\Tiedostot\\Rastor-instituutti\\kehittäminen\\analytiikka\\repos\\semantic-text-analyzer\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-12-11 12:05:05,358 - FileUtils.core.file_utils - INFO - FileUtils initialized with local storage\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO: FileUtils initialized with local storage\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-12-11 12:05:05,445 - FileUtils.core.file_utils - INFO - Project root: c:\\Users\\tja\\OneDrive - Rastor-instituutti ry\\Tiedostot\\Rastor-instituutti\\kehittäminen\\analytiikka\\repos\\semantic-text-analyzer\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO: Project root: c:\\Users\\tja\\OneDrive - Rastor-instituutti ry\\Tiedostot\\Rastor-instituutti\\kehittäminen\\analytiikka\\repos\\semantic-text-analyzer\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-12-11 12:05:05,456 - FileUtils.core.file_utils - INFO - FileUtils initialized with local storage\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO: FileUtils initialized with local storage\n",
      "INFO: Loaded 747 stopwords from c:\\Users\\tja\\OneDrive - Rastor-instituutti ry\\Tiedostot\\Rastor-instituutti\\kehittäminen\\analytiikka\\repos\\semantic-text-analyzer\\data\\configurations\\stop_words\\fi.txt\n",
      "DEBUG: Initialized with config: {'default_language': 'en', 'content_column': 'content', 'analysis': {'keywords': {'max_keywords': 5, 'min_keyword_length': 3, 'include_compounds': True}, 'themes': {'max_themes': 3, 'min_confidence': 0.5, 'include_hierarchy': True}, 'categories': {'max_categories': 3, 'min_confidence': 0.3, 'require_evidence': True}}, 'models': {'default_provider': 'openai', 'default_model': 'gpt-4o-mini', 'parameters': {'temperature': 0.0, 'max_tokens': 1000, 'top_p': 1.0, 'frequency_penalty': 0.0, 'presence_penalty': 0.0}, 'providers': {'azure': {'api_version': '2024-02-15-preview', 'api_type': 'azure'}, 'openai': {'api_type': 'open_ai'}, 'anthropic': {'api_type': 'anthropic'}}}, 'features': {'use_caching': True, 'use_async': True, 'use_batching': True, 'enable_finnish_support': True}, 'language': 'fi'}\n",
      "DEBUG: Trying library paths: ['C:\\\\scripts\\\\Voikko\\\\libvoikko-1.dll', 'C:\\\\Program Files\\\\Voikko\\\\libvoikko-1.dll', 'C:\\\\Voikko\\\\libvoikko-1.dll']\n",
      "DEBUG: Trying dictionary paths: ['C:\\\\scripts\\\\Voikko', 'C:\\\\Program Files\\\\Voikko', 'C:\\\\Voikko']\n",
      "DEBUG: Added C:\\scripts\\Voikko to DLL search path\n",
      "INFO: Successfully initialized Voikko with path: C:\\scripts\\Voikko\n",
      "INFO: Language switched to fi\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-12-11 12:05:05,519 - FileUtils.core.file_utils - INFO - Project root: c:\\Users\\tja\\OneDrive - Rastor-instituutti ry\\Tiedostot\\Rastor-instituutti\\kehittäminen\\analytiikka\\repos\\semantic-text-analyzer\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO: Project root: c:\\Users\\tja\\OneDrive - Rastor-instituutti ry\\Tiedostot\\Rastor-instituutti\\kehittäminen\\analytiikka\\repos\\semantic-text-analyzer\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-12-11 12:05:05,528 - FileUtils.core.file_utils - INFO - FileUtils initialized with local storage\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO: FileUtils initialized with local storage\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-12-11 12:05:05,624 - FileUtils.core.file_utils - INFO - Project root: c:\\Users\\tja\\OneDrive - Rastor-instituutti ry\\Tiedostot\\Rastor-instituutti\\kehittäminen\\analytiikka\\repos\\semantic-text-analyzer\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO: Project root: c:\\Users\\tja\\OneDrive - Rastor-instituutti ry\\Tiedostot\\Rastor-instituutti\\kehittäminen\\analytiikka\\repos\\semantic-text-analyzer\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-12-11 12:05:05,636 - FileUtils.core.file_utils - INFO - FileUtils initialized with local storage\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO: FileUtils initialized with local storage\n",
      "INFO: Loaded 747 stopwords from c:\\Users\\tja\\OneDrive - Rastor-instituutti ry\\Tiedostot\\Rastor-instituutti\\kehittäminen\\analytiikka\\repos\\semantic-text-analyzer\\data\\configurations\\stop_words\\fi.txt\n",
      "DEBUG: Initialized with config: {'default_language': 'en', 'content_column': 'content', 'analysis': {'keywords': {'max_keywords': 5, 'min_keyword_length': 3, 'include_compounds': True}, 'themes': {'max_themes': 3, 'min_confidence': 0.5, 'include_hierarchy': True}, 'categories': {'max_categories': 3, 'min_confidence': 0.3, 'require_evidence': True}}, 'models': {'default_provider': 'openai', 'default_model': 'gpt-4o-mini', 'parameters': {'temperature': 0.0, 'max_tokens': 1000, 'top_p': 1.0, 'frequency_penalty': 0.0, 'presence_penalty': 0.0}, 'providers': {'azure': {'api_version': '2024-02-15-preview', 'api_type': 'azure'}, 'openai': {'api_type': 'open_ai'}, 'anthropic': {'api_type': 'anthropic'}}}, 'features': {'use_caching': True, 'use_async': True, 'use_batching': True, 'enable_finnish_support': True}, 'language': 'fi'}\n",
      "DEBUG: Trying library paths: ['C:\\\\scripts\\\\Voikko\\\\libvoikko-1.dll', 'C:\\\\Program Files\\\\Voikko\\\\libvoikko-1.dll', 'C:\\\\Voikko\\\\libvoikko-1.dll']\n",
      "DEBUG: Trying dictionary paths: ['C:\\\\scripts\\\\Voikko', 'C:\\\\Program Files\\\\Voikko', 'C:\\\\Voikko']\n",
      "DEBUG: Added C:\\scripts\\Voikko to DLL search path\n",
      "INFO: Successfully initialized Voikko with path: C:\\scripts\\Voikko\n",
      "INFO: Language switched to fi\n",
      "INFO: HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO: HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing response: {'categories': [{'category': 'Business Development', 'confidence': 0.85, 'explanation': 'The text discusses strategic partnerships and their role in promoting innovation and market penetration, which are key aspects of business development.', 'evidence': [{'text': 'Strategiset kumppanuudet edistävät innovaatiota ja markkinapenetraatiota.', 'relevance': 0.9, 'matched_keywords': ['kumppanuus', 'innovaatio', 'strateginen'], 'context': 'The text emphasizes the importance of strategic partnerships in driving innovation and market entry.'}], 'themes': ['innovation', 'market strategy']}, {'category': 'Research and Development', 'confidence': 0.75, 'explanation': 'The mention of R&D investments leading to new product launches indicates a focus on research and development activities.', 'evidence': [{'text': 'T&K-investoinnit johtivat kolmeen uuteen tuotelanseeraukseen.', 'relevance': 0.85, 'matched_keywords': ['T&K', 'tuotelanseeraukseen'], 'context': 'The text highlights the outcomes of R&D investments, specifically new product launches.'}], 'themes': ['product development', 'innovation']}], 'relationships': {'Business Development': ['Market Strategy', 'Partnerships'], 'Research and Development': ['Innovation', 'Product Development']}}\n",
      "\n",
      "Processing category: {'category': 'Business Development', 'confidence': 0.85, 'explanation': 'The text discusses strategic partnerships and their role in promoting innovation and market penetration, which are key aspects of business development.', 'evidence': [{'text': 'Strategiset kumppanuudet edistävät innovaatiota ja markkinapenetraatiota.', 'relevance': 0.9, 'matched_keywords': ['kumppanuus', 'innovaatio', 'strateginen'], 'context': 'The text emphasizes the importance of strategic partnerships in driving innovation and market entry.'}], 'themes': ['innovation', 'market strategy']}\n",
      "Created category: name='Business Development' confidence=0.85 description='The text discusses strategic partnerships and their role in promoting innovation and market penetration, which are key aspects of business development.' evidence=[Evidence(text='Strategiset kumppanuudet edistävät innovaatiota ja markkinapenetraatiota.', relevance=0.9)] themes=['innovation', 'market strategy']\n",
      "\n",
      "Processing category: {'category': 'Research and Development', 'confidence': 0.75, 'explanation': 'The mention of R&D investments leading to new product launches indicates a focus on research and development activities.', 'evidence': [{'text': 'T&K-investoinnit johtivat kolmeen uuteen tuotelanseeraukseen.', 'relevance': 0.85, 'matched_keywords': ['T&K', 'tuotelanseeraukseen'], 'context': 'The text highlights the outcomes of R&D investments, specifically new product launches.'}], 'themes': ['product development', 'innovation']}\n",
      "Created category: name='Research and Development' confidence=0.75 description='The mention of R&D investments leading to new product launches indicates a focus on research and development activities.' evidence=[Evidence(text='T&K-investoinnit johtivat kolmeen uuteen tuotelanseeraukseen.', relevance=0.85)] themes=['product development', 'innovation']\n",
      "\n",
      "Final categories: [CategoryMatch(name='Business Development', confidence=0.85, description='The text discusses strategic partnerships and their role in promoting innovation and market penetration, which are key aspects of business development.', evidence=[Evidence(text='Strategiset kumppanuudet edistävät innovaatiota ja markkinapenetraatiota.', relevance=0.9)], themes=['innovation', 'market strategy']), CategoryMatch(name='Research and Development', confidence=0.75, description='The mention of R&D investments leading to new product launches indicates a focus on research and development activities.', evidence=[Evidence(text='T&K-investoinnit johtivat kolmeen uuteen tuotelanseeraukseen.', relevance=0.85)], themes=['product development', 'innovation'])]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO: HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Raw LLM response: {'themes': [{'name': 'Strategic Partnerships', 'description': 'The role of strategic partnerships in fostering innovation and market penetration.', 'confidence': 0.95, 'keywords': ['strateginen', 'kumppanuudet', 'markkinapenetraatio'], 'domain': 'business', 'parent_theme': None}, {'name': 'Innovation', 'description': 'The impact of research and development investments on innovation and product launches.', 'confidence': 0.9, 'keywords': ['innovaatio', 'T&K-investoinnit', 'tuotelanseeraus'], 'domain': 'technical', 'parent_theme': None}, {'name': 'Product Launches', 'description': 'The outcomes of R&D investments leading to new product launches.', 'confidence': 0.85, 'keywords': ['tuotelanseeraus', 'investoinnit', 'innovaatiot'], 'domain': 'business', 'parent_theme': 'Innovation'}], 'evidence': {'Strategic Partnerships': [{'text': 'Strategiset kumppanuudet edistävät innovaatiota ja markkinapenetraatiota.', 'relevance': 0.9, 'keywords': ['strateginen', 'kumppanuudet', 'markkinapenetraatio']}], 'Innovation': [{'text': 'T&K-investoinnit johtivat kolmeen uuteen tuotelanseeraukseen.', 'relevance': 0.9, 'keywords': ['innovaatio', 'T&K-investoinnit', 'tuotelanseeraus']}], 'Product Launches': [{'text': 'T&K-investoinnit johtivat kolmeen uuteen tuotelanseeraukseen.', 'relevance': 0.85, 'keywords': ['tuotelanseeraus', 'investoinnit', 'innovaatiot']}]}, 'relationships': {'Strategic Partnerships': ['Innovation'], 'Innovation': ['Product Launches'], 'Product Launches': []}}\n",
      "\n",
      "Processed LLM response: {'themes': [{'name': 'Strategic Partnerships', 'description': 'The role of strategic partnerships in fostering innovation and market penetration.', 'confidence': 0.95, 'keywords': ['strateginen', 'kumppanuudet', 'markkinapenetraatio'], 'domain': 'business', 'parent_theme': None}, {'name': 'Innovation', 'description': 'The impact of research and development investments on innovation and product launches.', 'confidence': 0.9, 'keywords': ['innovaatio', 'T&K-investoinnit', 'tuotelanseeraus'], 'domain': 'technical', 'parent_theme': None}, {'name': 'Product Launches', 'description': 'The outcomes of R&D investments leading to new product launches.', 'confidence': 0.85, 'keywords': ['tuotelanseeraus', 'investoinnit', 'innovaatiot'], 'domain': 'business', 'parent_theme': 'Innovation'}], 'evidence': {'Strategic Partnerships': [{'text': 'Strategiset kumppanuudet edistävät innovaatiota ja markkinapenetraatiota.', 'relevance': 0.9, 'keywords': ['strateginen', 'kumppanuudet', 'markkinapenetraatio']}], 'Innovation': [{'text': 'T&K-investoinnit johtivat kolmeen uuteen tuotelanseeraukseen.', 'relevance': 0.9, 'keywords': ['innovaatio', 'T&K-investoinnit', 'tuotelanseeraus']}], 'Product Launches': [{'text': 'T&K-investoinnit johtivat kolmeen uuteen tuotelanseeraukseen.', 'relevance': 0.85, 'keywords': ['tuotelanseeraus', 'investoinnit', 'innovaatiot']}]}, 'relationships': {'Strategic Partnerships': ['Innovation'], 'Innovation': ['Product Launches'], 'Product Launches': []}}\n",
      "2024-12-11 12:05:13,627 - FileUtils.core.file_utils - INFO - Project root: c:\\Users\\tja\\OneDrive - Rastor-instituutti ry\\Tiedostot\\Rastor-instituutti\\kehittäminen\\analytiikka\\repos\\semantic-text-analyzer\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO: Project root: c:\\Users\\tja\\OneDrive - Rastor-instituutti ry\\Tiedostot\\Rastor-instituutti\\kehittäminen\\analytiikka\\repos\\semantic-text-analyzer\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-12-11 12:05:13,637 - FileUtils.core.file_utils - INFO - FileUtils initialized with local storage\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO: FileUtils initialized with local storage\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-12-11 12:05:13,710 - FileUtils.core.file_utils - INFO - Project root: c:\\Users\\tja\\OneDrive - Rastor-instituutti ry\\Tiedostot\\Rastor-instituutti\\kehittäminen\\analytiikka\\repos\\semantic-text-analyzer\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO: Project root: c:\\Users\\tja\\OneDrive - Rastor-instituutti ry\\Tiedostot\\Rastor-instituutti\\kehittäminen\\analytiikka\\repos\\semantic-text-analyzer\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-12-11 12:05:13,719 - FileUtils.core.file_utils - INFO - FileUtils initialized with local storage\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO: FileUtils initialized with local storage\n",
      "INFO: Loaded 747 stopwords from c:\\Users\\tja\\OneDrive - Rastor-instituutti ry\\Tiedostot\\Rastor-instituutti\\kehittäminen\\analytiikka\\repos\\semantic-text-analyzer\\data\\configurations\\stop_words\\fi.txt\n",
      "DEBUG: Initialized with config: {'default_language': 'en', 'content_column': 'content', 'analysis': {'keywords': {'max_keywords': 5, 'min_keyword_length': 3, 'include_compounds': True}, 'themes': {'max_themes': 3, 'min_confidence': 0.5, 'include_hierarchy': True}, 'categories': {'max_categories': 3, 'min_confidence': 0.3, 'require_evidence': True}}, 'models': {'default_provider': 'openai', 'default_model': 'gpt-4o-mini', 'parameters': {'temperature': 0.0, 'max_tokens': 1000, 'top_p': 1.0, 'frequency_penalty': 0.0, 'presence_penalty': 0.0}, 'providers': {'azure': {'api_version': '2024-02-15-preview', 'api_type': 'azure'}, 'openai': {'api_type': 'open_ai'}, 'anthropic': {'api_type': 'anthropic'}}}, 'features': {'use_caching': True, 'use_async': True, 'use_batching': True, 'enable_finnish_support': True}, 'language': 'fi'}\n",
      "DEBUG: Trying library paths: ['C:\\\\scripts\\\\Voikko\\\\libvoikko-1.dll', 'C:\\\\Program Files\\\\Voikko\\\\libvoikko-1.dll', 'C:\\\\Voikko\\\\libvoikko-1.dll']\n",
      "DEBUG: Trying dictionary paths: ['C:\\\\scripts\\\\Voikko', 'C:\\\\Program Files\\\\Voikko', 'C:\\\\Voikko']\n",
      "DEBUG: Added C:\\scripts\\Voikko to DLL search path\n",
      "INFO: Successfully initialized Voikko with path: C:\\scripts\\Voikko\n",
      "INFO: Language switched to fi\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-12-11 12:05:13,836 - FileUtils.core.file_utils - INFO - Project root: c:\\Users\\tja\\OneDrive - Rastor-instituutti ry\\Tiedostot\\Rastor-instituutti\\kehittäminen\\analytiikka\\repos\\semantic-text-analyzer\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO: Project root: c:\\Users\\tja\\OneDrive - Rastor-instituutti ry\\Tiedostot\\Rastor-instituutti\\kehittäminen\\analytiikka\\repos\\semantic-text-analyzer\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-12-11 12:05:13,845 - FileUtils.core.file_utils - INFO - FileUtils initialized with local storage\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO: FileUtils initialized with local storage\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-12-11 12:05:13,933 - FileUtils.core.file_utils - INFO - Project root: c:\\Users\\tja\\OneDrive - Rastor-instituutti ry\\Tiedostot\\Rastor-instituutti\\kehittäminen\\analytiikka\\repos\\semantic-text-analyzer\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO: Project root: c:\\Users\\tja\\OneDrive - Rastor-instituutti ry\\Tiedostot\\Rastor-instituutti\\kehittäminen\\analytiikka\\repos\\semantic-text-analyzer\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-12-11 12:05:13,942 - FileUtils.core.file_utils - INFO - FileUtils initialized with local storage\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO: FileUtils initialized with local storage\n",
      "INFO: Loaded 747 stopwords from c:\\Users\\tja\\OneDrive - Rastor-instituutti ry\\Tiedostot\\Rastor-instituutti\\kehittäminen\\analytiikka\\repos\\semantic-text-analyzer\\data\\configurations\\stop_words\\fi.txt\n",
      "DEBUG: Initialized with config: {'default_language': 'en', 'content_column': 'content', 'analysis': {'keywords': {'max_keywords': 5, 'min_keyword_length': 3, 'include_compounds': True}, 'themes': {'max_themes': 3, 'min_confidence': 0.5, 'include_hierarchy': True}, 'categories': {'max_categories': 3, 'min_confidence': 0.3, 'require_evidence': True}}, 'models': {'default_provider': 'openai', 'default_model': 'gpt-4o-mini', 'parameters': {'temperature': 0.0, 'max_tokens': 1000, 'top_p': 1.0, 'frequency_penalty': 0.0, 'presence_penalty': 0.0}, 'providers': {'azure': {'api_version': '2024-02-15-preview', 'api_type': 'azure'}, 'openai': {'api_type': 'open_ai'}, 'anthropic': {'api_type': 'anthropic'}}}, 'features': {'use_caching': True, 'use_async': True, 'use_batching': True, 'enable_finnish_support': True}, 'language': 'fi'}\n",
      "DEBUG: Trying library paths: ['C:\\\\scripts\\\\Voikko\\\\libvoikko-1.dll', 'C:\\\\Program Files\\\\Voikko\\\\libvoikko-1.dll', 'C:\\\\Voikko\\\\libvoikko-1.dll']\n",
      "DEBUG: Trying dictionary paths: ['C:\\\\scripts\\\\Voikko', 'C:\\\\Program Files\\\\Voikko', 'C:\\\\Voikko']\n",
      "DEBUG: Added C:\\scripts\\Voikko to DLL search path\n",
      "INFO: Successfully initialized Voikko with path: C:\\scripts\\Voikko\n",
      "INFO: Language switched to fi\n",
      "INFO: HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing response: {'categories': [{'category': 'Business Efficiency', 'confidence': 0.85, 'explanation': 'The text discusses improvements in operational efficiency through process automation, which is a key aspect of business efficiency.', 'evidence': [{'text': 'Toiminnan tehokkuus parani prosessiautomaation avulla.', 'relevance': 0.9, 'matched_keywords': ['tehokkuus', 'toiminta'], 'context': 'The sentence highlights the enhancement of operational efficiency.'}], 'themes': ['process automation', 'customer satisfaction']}, {'category': 'Customer Satisfaction', 'confidence': 0.75, 'explanation': 'The mention of customer satisfaction metrics indicating positive development suggests a focus on customer experience.', 'evidence': [{'text': 'Asiakastyytyväisyysmittarit osoittavat positiivista kehitystä.', 'relevance': 0.85, 'matched_keywords': ['asiakastyytyväisyys'], 'context': 'This part of the text directly addresses customer satisfaction metrics.'}], 'themes': ['customer feedback', 'service quality']}], 'relationships': {'Business Efficiency': ['Process Improvement', 'Operational Management'], 'Customer Satisfaction': ['Customer Experience', 'Service Improvement']}}\n",
      "\n",
      "Processing category: {'category': 'Business Efficiency', 'confidence': 0.85, 'explanation': 'The text discusses improvements in operational efficiency through process automation, which is a key aspect of business efficiency.', 'evidence': [{'text': 'Toiminnan tehokkuus parani prosessiautomaation avulla.', 'relevance': 0.9, 'matched_keywords': ['tehokkuus', 'toiminta'], 'context': 'The sentence highlights the enhancement of operational efficiency.'}], 'themes': ['process automation', 'customer satisfaction']}\n",
      "Created category: name='Business Efficiency' confidence=0.85 description='The text discusses improvements in operational efficiency through process automation, which is a key aspect of business efficiency.' evidence=[Evidence(text='Toiminnan tehokkuus parani prosessiautomaation avulla.', relevance=0.9)] themes=['process automation', 'customer satisfaction']\n",
      "\n",
      "Processing category: {'category': 'Customer Satisfaction', 'confidence': 0.75, 'explanation': 'The mention of customer satisfaction metrics indicating positive development suggests a focus on customer experience.', 'evidence': [{'text': 'Asiakastyytyväisyysmittarit osoittavat positiivista kehitystä.', 'relevance': 0.85, 'matched_keywords': ['asiakastyytyväisyys'], 'context': 'This part of the text directly addresses customer satisfaction metrics.'}], 'themes': ['customer feedback', 'service quality']}\n",
      "Created category: name='Customer Satisfaction' confidence=0.75 description='The mention of customer satisfaction metrics indicating positive development suggests a focus on customer experience.' evidence=[Evidence(text='Asiakastyytyväisyysmittarit osoittavat positiivista kehitystä.', relevance=0.85)] themes=['customer feedback', 'service quality']\n",
      "\n",
      "Final categories: [CategoryMatch(name='Business Efficiency', confidence=0.85, description='The text discusses improvements in operational efficiency through process automation, which is a key aspect of business efficiency.', evidence=[Evidence(text='Toiminnan tehokkuus parani prosessiautomaation avulla.', relevance=0.9)], themes=['process automation', 'customer satisfaction']), CategoryMatch(name='Customer Satisfaction', confidence=0.75, description='The mention of customer satisfaction metrics indicating positive development suggests a focus on customer experience.', evidence=[Evidence(text='Asiakastyytyväisyysmittarit osoittavat positiivista kehitystä.', relevance=0.85)], themes=['customer feedback', 'service quality'])]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO: HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO: HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-12-11 12:05:21,793 - LocalStorage - INFO - Saved Excel file with sheets: ['analysis_results']\n",
      "INFO: Saved Excel file with sheets: ['analysis_results']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Raw LLM response: {'themes': [{'name': 'prosessiautomaatio', 'description': 'Prosessiautomaatio parantaa toiminnan tehokkuutta ja optimoi liiketoimintaprosesseja.', 'confidence': 0.95, 'keywords': ['prosessiautomaatio', 'tehokkuus'], 'domain': 'technical/business'}, {'name': 'asiakastyytyväisyys', 'description': 'Asiakastyytyväisyysmittarit osoittavat positiivista kehitystä, mikä viittaa parantuneeseen asiakaskokemukseen.', 'confidence': 0.9, 'keywords': ['asiakastyytyväisyys', 'mittarit'], 'domain': 'business'}], 'evidence': {'prosessiautomaatio': [{'text': 'Toiminnan tehokkuus parani prosessiautomaation avulla.', 'relevance': 0.9, 'keywords': ['prosessiautomaatio', 'tehokkuus']}], 'asiakastyytyväisyys': [{'text': 'Asiakastyytyväisyysmittarit osoittavat positiivista kehitystä.', 'relevance': 0.9, 'keywords': ['asiakastyytyväisyys', 'mittarit']}]}, 'relationships': {'prosessiautomaatio': ['asiakastyytyväisyys']}}\n",
      "\n",
      "Processed LLM response: {'themes': [{'name': 'prosessiautomaatio', 'description': 'Prosessiautomaatio parantaa toiminnan tehokkuutta ja optimoi liiketoimintaprosesseja.', 'confidence': 0.95, 'keywords': ['prosessiautomaatio', 'tehokkuus'], 'domain': 'technical/business'}, {'name': 'asiakastyytyväisyys', 'description': 'Asiakastyytyväisyysmittarit osoittavat positiivista kehitystä, mikä viittaa parantuneeseen asiakaskokemukseen.', 'confidence': 0.9, 'keywords': ['asiakastyytyväisyys', 'mittarit'], 'domain': 'business'}], 'evidence': {'prosessiautomaatio': [{'text': 'Toiminnan tehokkuus parani prosessiautomaation avulla.', 'relevance': 0.9, 'keywords': ['prosessiautomaatio', 'tehokkuus']}], 'asiakastyytyväisyys': [{'text': 'Asiakastyytyväisyysmittarit osoittavat positiivista kehitystä.', 'relevance': 0.9, 'keywords': ['asiakastyytyväisyys', 'mittarit']}]}, 'relationships': {'prosessiautomaatio': ['asiakastyytyväisyys']}}\n",
      "2024-12-11 12:05:21,794 - FileUtils.core.file_utils - INFO - Data saved successfully: {'analysis_results_20241211_120521': 'c:\\\\Users\\\\tja\\\\OneDrive - Rastor-instituutti ry\\\\Tiedostot\\\\Rastor-instituutti\\\\kehittäminen\\\\analytiikka\\\\repos\\\\semantic-text-analyzer\\\\data\\\\processed\\\\analysis_results_20241211_120521.xlsx'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO: Data saved successfully: {'analysis_results_20241211_120521': 'c:\\\\Users\\\\tja\\\\OneDrive - Rastor-instituutti ry\\\\Tiedostot\\\\Rastor-instituutti\\\\kehittäminen\\\\analytiikka\\\\repos\\\\semantic-text-analyzer\\\\data\\\\processed\\\\analysis_results_20241211_120521.xlsx'}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing complete!\n",
      "Results saved to: c:\\Users\\tja\\OneDrive - Rastor-instituutti ry\\Tiedostot\\Rastor-instituutti\\kehittäminen\\analytiikka\\repos\\semantic-text-analyzer\\data\\processed\\analysis_results_20241211_120521.xlsx\n",
      "\n",
      "First few rows of results:\n",
      "            id       type language                        content                       keywords                         themes                     categories\n",
      "0  technical_1  technical       fi  Koneoppimismalleja koulute...  koneoppimismalli; datajouk...  Koneoppimismallit (0.95); ...        Machine Learning (0.95)\n",
      "1  technical_2  technical       fi  Pilvipalvelut tarjoavat sk...  pilvipalvelut; skaalautuva...  Pilvipalvelut (0.95); Mikr...  Cloud Services (0.85); Mic...\n",
      "2  technical_3  technical       fi  Versionhallintajärjestelmä...  versionhallintajärjestelmä...  Versionhallintajärjestelmä...    Software Development (0.85)\n",
      "3   business_1   business       fi  Q3 taloudelliset tulokset ...  liikevaihdon kasvu; asiaka...  Taloudellinen kasvu (0.95)...    Business Performance (0.95)\n",
      "4   business_2   business       fi  Strategiset kumppanuudet e...  strategiset kumppanuudet; ...  Strategic Partnerships (0....  Business Development (0.85...\n"
     ]
    }
   ],
   "source": [
    "# 3. Excel processing\n",
    "print(\"\\n=== Excel Processing Demo ===\\n\")\n",
    "await demonstrate_excel_processing()\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. Custom format demo\n",
    "print(\"\\n=== Custom Format Demo ===\\n\")\n",
    "await demonstrate_custom_format()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5. Batch file analysis\n",
    "# print(\"\\n=== Batch File Analysis Demo ===\\n\")\n",
    "# await demonstrate_batch_file_analysis()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # 1. Single Text Analysis with Different Detail Levels\n",
    "# async def demonstrate_single_analysis(text: str):\n",
    "#     \"\"\"Demonstrate analysis of single text with different detail levels.\"\"\"\n",
    "#     print(\"Analyzing text:\")\n",
    "#     print(\"-\" * 50)\n",
    "#     print(text)\n",
    "#     print(\"\\n\")\n",
    "\n",
    "#     # Perform analysis\n",
    "#     result = await analyzer.analyze(\n",
    "#         text,\n",
    "#         analysis_types=[\"keywords\", \"themes\", \"categories\"]\n",
    "#     )\n",
    "\n",
    "#     # Show summary format\n",
    "#     print(\"Summary Output:\")\n",
    "#     print(\"-\" * 50)\n",
    "#     summary = summary_formatter.format_output(\n",
    "#         results=result,\n",
    "#         analysis_types=[\"keywords\", \"themes\", \"categories\"]\n",
    "#     )\n",
    "#     for analysis_type, output in summary.items():\n",
    "#         print(f\"\\n{analysis_type.title()}:\")\n",
    "#         print(output)\n",
    "\n",
    "#     # Show detailed format\n",
    "#     print(\"\\nDetailed Output:\")\n",
    "#     print(\"-\" * 50)\n",
    "#     detailed = detailed_formatter.format_detailed_output(\n",
    "#         results=result,\n",
    "#         analysis_types=[\"keywords\", \"themes\", \"categories\"]\n",
    "#     )\n",
    "#     for analysis_type, output in detailed.items():\n",
    "#         print(f\"\\n{analysis_type.title()}:\")\n",
    "#         print(\"Summary:\", output[\"summary\"])\n",
    "#         print(\"Details:\", output[\"details\"])\n",
    "#         print(\"Metadata:\", output[\"metadata\"])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For notebook execution\n",
    "if __name__ == \"__main__\":\n",
    "    await run_demos()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "semantic-analyzer",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
