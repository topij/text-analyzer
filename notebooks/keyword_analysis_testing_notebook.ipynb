{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Added C:\\Users\\tja\\OneDrive - Rastor-instituutti ry\\Tiedostot\\Rastor-instituutti\\kehittäminen\\analytiikka\\repos\\semantic-text-analyzer to Python path\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "from pathlib import Path\n",
    "import asyncio\n",
    "import logging\n",
    "from typing import Dict, Any, List, Tuple\n",
    "from pprint import pprint\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "# Add project root to Python path\n",
    "project_root = str(Path().resolve().parent)\n",
    "if project_root not in sys.path:\n",
    "    sys.path.append(project_root)\n",
    "    print(f\"Added {project_root} to Python path\")\n",
    "\n",
    "# Core components\n",
    "from src.semantic_analyzer.analyzer import SemanticAnalyzer\n",
    "from src.utils.FileUtils.file_utils import FileUtils\n",
    "from src.analyzers.keyword_analyzer import KeywordAnalyzer\n",
    "from src.core.language_processing import create_text_processor\n",
    "from src.loaders.parameter_adapter import ParameterAdapter\n",
    "\n",
    "# Initialize FileUtils and set up logging\n",
    "file_utils = FileUtils()\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "logger = logging.getLogger(__name__)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Environment Check Results:\n",
      "==================================================\n",
      "\n",
      "Basic Setup:\n",
      "-----------\n",
      "✓ Project root in path\n",
      "✓ Can import src\n",
      "✓ FileUtils initialized\n",
      "✓ .env file loaded\n",
      "\n",
      "Environment Variables:\n",
      "---------------------\n",
      "✓ OPENAI_API_KEY set\n",
      "✓ ANTHROPIC_API_KEY set\n",
      "\n",
      "Project Structure:\n",
      "-----------------\n",
      "✓ Raw data exists\n",
      "✓ Processed data exists\n",
      "✓ Configuration exists\n",
      "✓ Main config.yaml exists\n",
      "\n",
      "==================================================\n",
      "Environment Status: Ready ✓\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def verify_environment():\n",
    "    \"\"\"Verify that the notebook environment is properly configured.\"\"\"\n",
    "    # Load environment variables\n",
    "    from dotenv import load_dotenv\n",
    "    env_path = Path(project_root) / \".env\"\n",
    "    env_loaded = load_dotenv(env_path)\n",
    "\n",
    "    # Required environment variables\n",
    "    required_env_vars = [\n",
    "        'OPENAI_API_KEY',\n",
    "        'ANTHROPIC_API_KEY',\n",
    "    ]\n",
    "\n",
    "    # Basic checks\n",
    "    basic_checks = {\n",
    "        \"Project root in path\": project_root in sys.path,\n",
    "        \"Can import src\": \"src\" in sys.modules,\n",
    "        \"FileUtils initialized\": hasattr(file_utils, \"project_root\"),\n",
    "        \".env file loaded\": env_loaded,\n",
    "    }\n",
    "\n",
    "    # Environment variable checks\n",
    "    env_var_checks = {\n",
    "        f\"{var} set\": os.getenv(var) is not None\n",
    "        for var in required_env_vars\n",
    "    }\n",
    "\n",
    "    # Check for required paths using FileUtils\n",
    "    expected_paths = {\n",
    "        \"Raw data\": file_utils.get_data_path(\"raw\"),\n",
    "        \"Processed data\": file_utils.get_data_path(\"processed\"),\n",
    "        \"Configuration\": file_utils.get_data_path(\"configurations\"),\n",
    "        \"Main config.yaml\": Path(project_root) / \"config.yaml\"\n",
    "    }\n",
    "    \n",
    "    path_checks = {\n",
    "        f\"{name} exists\": path.exists()\n",
    "        for name, path in expected_paths.items()\n",
    "    }\n",
    "\n",
    "    # Combine all checks\n",
    "    all_checks = {\n",
    "        **basic_checks,\n",
    "        **env_var_checks,\n",
    "        **path_checks\n",
    "    }\n",
    "    \n",
    "    # Print results\n",
    "    print(\"Environment Check Results:\")\n",
    "    print(\"=\" * 50)\n",
    "    \n",
    "    def print_section(title, checks):\n",
    "        print(f\"\\n{title}:\")\n",
    "        print(\"-\" * len(title))\n",
    "        for check, result in checks.items():\n",
    "            status = \"✓\" if result else \"✗\"\n",
    "            print(f\"{status} {check}\")\n",
    "    \n",
    "    print_section(\"Basic Setup\", basic_checks)\n",
    "    print_section(\"Environment Variables\", env_var_checks)\n",
    "    print_section(\"Project Structure\", path_checks)\n",
    "    \n",
    "    # Overall status\n",
    "    all_passed = all(all_checks.values())\n",
    "    print(\"\\n\" + \"=\" * 50)\n",
    "    print(\"Environment Status:\", \"Ready ✓\" if all_passed else \"Setup needed ✗\")\n",
    "    \n",
    "    if not all_passed:\n",
    "        print(\"\\nSetup Instructions:\")\n",
    "        if not env_loaded:\n",
    "            print(\"- Create a .env file in the project root with required API keys\")\n",
    "        for var in required_env_vars:\n",
    "            if not os.getenv(var):\n",
    "                print(f\"- Add {var} to your .env file\")\n",
    "        for name, path in expected_paths.items():\n",
    "            if not path.exists():\n",
    "                print(f\"- Create {name} directory at {path}\")\n",
    "\n",
    "    return all_passed\n",
    "\n",
    "# Run verification\n",
    "verify_environment()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Tester classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class KeywordTester:\n",
    "    \"\"\"Helper class for testing keyword analysis components.\"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.file_utils = FileUtils()\n",
    "        self.test_texts = self._load_test_texts()\n",
    "        \n",
    "    def _load_test_texts(self) -> Dict[str, str]:\n",
    "        \"\"\"Load or create test texts.\"\"\"\n",
    "        texts = {\n",
    "            \"technical\": \"\"\"\n",
    "                Python is a high-level programming language known for its simplicity.\n",
    "                It supports multiple programming paradigms including procedural and\n",
    "                object-oriented programming.\n",
    "            \"\"\",\n",
    "            \"business\": \"\"\"\n",
    "                The company's Q3 results exceeded expectations with revenue growth of 15%.\n",
    "                Customer acquisition costs decreased while retention rates improved.\n",
    "                The board has approved a new strategic initiative focusing on expansion.\n",
    "            \"\"\",\n",
    "            \"finnish\": \"\"\"\n",
    "                Ohjelmistokehittäjä työskentelee asiakasprojektissa kehittäen uusia \n",
    "                ominaisuuksia verkkokauppajärjestelmään. Tekninen toteutus vaatii\n",
    "                erityistä huomiota tietoturvan osalta.\n",
    "            \"\"\"\n",
    "        }\n",
    "        \n",
    "        # Save test texts using FileUtils\n",
    "        df = pd.DataFrame([\n",
    "            {\"name\": name, \"content\": content.strip()}\n",
    "            for name, content in texts.items()\n",
    "        ])\n",
    "        \n",
    "        self.file_utils.save_data_to_disk(\n",
    "            data={\"texts\": df},\n",
    "            output_type=\"raw\",\n",
    "            file_name=\"test_texts\",\n",
    "            output_filetype=\"xlsx\",\n",
    "            include_timestamp=False\n",
    "        )\n",
    "        \n",
    "        return texts\n",
    "\n",
    "    async def test_statistical_analysis(self, text: str, language: str = None):\n",
    "        \"\"\"Test statistical keyword extraction.\"\"\"\n",
    "        if language is None:\n",
    "            # Try to detect language or use default\n",
    "            from langdetect import detect\n",
    "            try:\n",
    "                language = detect(text)\n",
    "            except:\n",
    "                language = \"en\"\n",
    "        \n",
    "        # Create processor and analyzer\n",
    "        processor = create_text_processor(language=language)\n",
    "        analyzer = KeywordAnalyzer(\n",
    "            config={\"weights\": {\"statistical\": 1.0, \"llm\": 0.0}},  # Statistical only\n",
    "            language_processor=processor\n",
    "        )\n",
    "        \n",
    "        results = await analyzer.analyze(text)\n",
    "        return results\n",
    "\n",
    "    async def test_llm_analysis(self, text: str, language: str = None):\n",
    "        \"\"\"Test LLM-based keyword extraction.\"\"\"\n",
    "        if language is None:\n",
    "            # Try to detect language or use default\n",
    "            from langdetect import detect\n",
    "            try:\n",
    "                language = detect(text)\n",
    "            except:\n",
    "                language = \"en\"\n",
    "        \n",
    "        analyzer = KeywordAnalyzer(\n",
    "            config={\"weights\": {\"statistical\": 0.0, \"llm\": 1.0}},  # LLM only\n",
    "            language_processor=create_text_processor(language=language)\n",
    "        )\n",
    "        \n",
    "        results = await analyzer.analyze(text)\n",
    "        return results\n",
    "\n",
    "    async def test_combined_analysis(self, text: str, language: str = None):\n",
    "        \"\"\"Test combined statistical and LLM analysis.\"\"\"\n",
    "        if language is None:\n",
    "            # Try to detect language or use default\n",
    "            from langdetect import detect\n",
    "            try:\n",
    "                language = detect(text)\n",
    "            except:\n",
    "                language = \"en\"\n",
    "        \n",
    "        analyzer = KeywordAnalyzer(\n",
    "            config={\n",
    "                \"weights\": {\"statistical\": 0.4, \"llm\": 0.6},\n",
    "                \"max_keywords\": 10,\n",
    "                \"min_confidence\": 0.3\n",
    "            },\n",
    "            language_processor=create_text_processor(language=language)\n",
    "        )\n",
    "        \n",
    "        results = await analyzer.analyze(text)\n",
    "        return results\n",
    "\n",
    "    # async def test_combined_analysis(self, text_key: str):\n",
    "    #     \"\"\"Test combined statistical and LLM analysis.\"\"\"\n",
    "    #     text = self.test_texts[text_key]\n",
    "    #     language = \"fi\" if text_key == \"finnish\" else \"en\"\n",
    "        \n",
    "    #     analyzer = KeywordAnalyzer(\n",
    "    #         config={\n",
    "    #             \"weights\": {\"statistical\": 0.4, \"llm\": 0.6},\n",
    "    #             \"max_keywords\": 10,\n",
    "    #             \"min_confidence\": 0.3\n",
    "    #         },\n",
    "    #         language_processor=create_text_processor(language=language)\n",
    "    #     )\n",
    "        \n",
    "    #     print(f\"\\nTesting Combined Analysis for {text_key}:\")\n",
    "    #     print(\"=\" * 50)\n",
    "    #     print(f\"Text: {text[:100]}...\")\n",
    "        \n",
    "    #     results = await analyzer.analyze(text)\n",
    "        \n",
    "    #     print(\"\\nCombined Keywords:\")\n",
    "    #     if hasattr(results, \"keywords\"):\n",
    "    #         for kw in results.keywords:\n",
    "    #             print(f\"- {kw}\")\n",
    "        \n",
    "    #     return results\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ContentTester:\n",
    "    \"\"\"Helper class for testing with different content types.\"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.file_utils = FileUtils()\n",
    "        self.test_texts = self._load_test_content()\n",
    "        self.keyword_tester = KeywordTester()\n",
    "        \n",
    "    def _load_test_content(self) -> Dict[str, Dict[str, List[str]]]:\n",
    "        \"\"\"Load test content from files.\"\"\"\n",
    "        content = {}\n",
    "        \n",
    "        for lang in [\"en\", \"fi\"]:\n",
    "            try:\n",
    "                # Load content using FileUtils\n",
    "                df = self.file_utils.load_single_file(\n",
    "                    f\"test_content_{lang}.xlsx\",\n",
    "                    input_type=\"raw\"\n",
    "                )\n",
    "                \n",
    "                # Group by content type\n",
    "                content[lang] = {}\n",
    "                for content_type, group in df.groupby(\"type\"):\n",
    "                    content[lang][content_type] = group[\"content\"].tolist()\n",
    "                \n",
    "            except Exception as e:\n",
    "                logger.warning(f\"Could not load test content for {lang}: {e}\")\n",
    "                content[lang] = {}\n",
    "        \n",
    "        return content\n",
    "\n",
    "    async def test_content_type(\n",
    "        self, \n",
    "        language: str, \n",
    "        content_type: str, \n",
    "        analyzer: KeywordAnalyzer,\n",
    "        show_comparison: bool = True\n",
    "    ) -> List[Any]:\n",
    "        \"\"\"Test analysis for specific content type with optional comparison.\"\"\"\n",
    "        if not self.test_texts.get(language, {}).get(content_type):\n",
    "            logger.warning(f\"No {content_type} content available for {language}\")\n",
    "            return []\n",
    "            \n",
    "        results = []\n",
    "        comparison_results = []\n",
    "        texts = self.test_texts[language][content_type]\n",
    "        \n",
    "        logger.info(f\"Processing {len(texts)} texts for {language} {content_type}\")\n",
    "        \n",
    "        for i, text in enumerate(texts, 1):\n",
    "            try:\n",
    "                logger.debug(f\"Processing text {i}/{len(texts)}\")\n",
    "                \n",
    "                if show_comparison:\n",
    "                    print(f\"\\nText {i}:\")\n",
    "                    print(\"-\" * 50)\n",
    "                    print(f\"Content: {text[:100]}...\")\n",
    "                    \n",
    "                    # Run comparison analysis\n",
    "                    stat_results = await self.keyword_tester.test_statistical_analysis(\n",
    "                        text, language=language\n",
    "                    )\n",
    "                    llm_results = await self.keyword_tester.test_llm_analysis(\n",
    "                        text, language=language\n",
    "                    )\n",
    "                    combined_results = await analyzer.analyze(text)\n",
    "                    \n",
    "                    # Print comparison\n",
    "                    print(\"\\nResults Comparison:\")\n",
    "                    print(\"-\" * 30)\n",
    "                    print(\"Statistical:\", stat_results.keywords if hasattr(stat_results, \"keywords\") else [])\n",
    "                    print(\"LLM:\", llm_results.keywords if hasattr(llm_results, \"keywords\") else [])\n",
    "                    print(\"Combined:\", combined_results.keywords if hasattr(combined_results, \"keywords\") else [])\n",
    "                    \n",
    "                    results.append(combined_results)\n",
    "                    comparison_results.append((stat_results, llm_results, combined_results))\n",
    "                else:\n",
    "                    # Just run normal analysis\n",
    "                    result = await analyzer.analyze(text)\n",
    "                    results.append(result)\n",
    "                    \n",
    "                    print(f\"\\nText {i}:\")\n",
    "                    print(\"Keywords:\", result.keywords if hasattr(result, \"keywords\") else [])\n",
    "                    print(\"Domain Keywords:\", result.domain_keywords if hasattr(result, \"domain_keywords\") else {})\n",
    "                \n",
    "            except Exception as e:\n",
    "                logger.error(f\"Error processing text {i}: {e}\")\n",
    "                results.append(None)\n",
    "                if show_comparison:\n",
    "                    comparison_results.append((None, None, None))\n",
    "            \n",
    "        return comparison_results if show_comparison else results\n",
    "    \n",
    "    async def analyze_text_with_comparison(\n",
    "        self,\n",
    "        text: str,\n",
    "        language: str = \"en\"\n",
    "    ) -> Tuple[Any, Any, Any]:\n",
    "        \"\"\"Analyze a single text with comparison of different methods.\"\"\"\n",
    "        try:\n",
    "            print(\"\\nRunning Analysis with Comparison:\")\n",
    "            print(\"=\" * 50)\n",
    "            print(f\"Text: {text[:100]}...\")\n",
    "            \n",
    "            # Run all analysis types\n",
    "            stat_results = await self.keyword_tester.test_statistical_analysis(\n",
    "                text, language=language\n",
    "            )\n",
    "            llm_results = await self.keyword_tester.test_llm_analysis(\n",
    "                text, language=language\n",
    "            )\n",
    "            combined_results = await self.keyword_tester.test_combined_analysis(\n",
    "                text, language=language\n",
    "            )\n",
    "            \n",
    "            # Print comparison\n",
    "            print(\"\\nResults Comparison:\")\n",
    "            print(\"-\" * 30)\n",
    "            print(\"Statistical:\", stat_results.keywords if hasattr(stat_results, \"keywords\") else [])\n",
    "            print(\"LLM:\", llm_results.keywords if hasattr(llm_results, \"keywords\") else [])\n",
    "            print(\"Combined:\", combined_results.keywords if hasattr(combined_results, \"keywords\") else [])\n",
    "            \n",
    "            return stat_results, llm_results, combined_results\n",
    "            \n",
    "        except Exception as e:\n",
    "            logger.error(f\"Error analyzing text: {e}\")\n",
    "            return None, None, None\n",
    "\n",
    "    def get_content_types(self, language: str) -> List[str]:\n",
    "        \"\"\"Get available content types for a language.\"\"\"\n",
    "        return list(self.test_texts.get(language, {}).keys())\n",
    "\n",
    "    def get_text_count(self, language: str, content_type: str) -> int:\n",
    "        \"\"\"Get number of texts for a language and content type.\"\"\"\n",
    "        return len(self.test_texts.get(language, {}).get(content_type, []))\n",
    "\n",
    "    async def analyze_single_text(\n",
    "        self,\n",
    "        text: str,\n",
    "        language: str,\n",
    "        analyzer: KeywordAnalyzer\n",
    "    ) -> Any:\n",
    "        \"\"\"Analyze a single text and display results.\"\"\"\n",
    "        try:\n",
    "            result = await analyzer.analyze(text)\n",
    "            \n",
    "            print(\"\\nAnalysis Results:\")\n",
    "            print(\"Keywords:\", result.keywords if hasattr(result, \"keywords\") else [])\n",
    "            print(\"Domain Keywords:\", result.domain_keywords if hasattr(result, \"domain_keywords\") else {})\n",
    "            \n",
    "            return result\n",
    "            \n",
    "        except Exception as e:\n",
    "            logger.error(f\"Error analyzing text: {e}\")\n",
    "            return None\n",
    "\n",
    "async def run_content_tests(show_comparison: bool = True):\n",
    "    \"\"\"Run tests for all content types.\n",
    "    \n",
    "    Args:\n",
    "        show_comparison: If True, shows comparison between statistical, LLM, and combined results\n",
    "    \"\"\"\n",
    "    from src.loaders.parameter_adapter import ParameterAdapter\n",
    "    \n",
    "    tester = ContentTester()\n",
    "    file_utils = FileUtils()\n",
    "    \n",
    "    # Load main config from project root\n",
    "    config_path = Path(file_utils.project_root) / \"config.yaml\"\n",
    "    try:\n",
    "        logger.info(f\"Loading config from: {config_path}\")\n",
    "        main_config = file_utils.load_yaml(config_path)\n",
    "        lang_configs = main_config.get(\"languages\", {})\n",
    "    except Exception as e:\n",
    "        logger.warning(f\"Could not load main config from {config_path}: {e}\")\n",
    "        lang_configs = {}\n",
    "    \n",
    "    # Load parameters using ParameterAdapter\n",
    "    en_params = ParameterAdapter(\n",
    "        file_utils.get_data_path(\"configurations\") / \"parameters_en.xlsx\"\n",
    "    ).parameters\n",
    "    \n",
    "    fi_params = ParameterAdapter(\n",
    "        file_utils.get_data_path(\"configurations\") / \"parameters_fi.xlsx\"\n",
    "    ).parameters\n",
    "    \n",
    "    # Create analyzers with parameters\n",
    "    en_analyzer = KeywordAnalyzer(\n",
    "        config={\n",
    "            **en_params.general.model_dump(),  # Convert to dict\n",
    "            \"weights\": {\"statistical\": 0.4, \"llm\": 0.6},\n",
    "            \"max_keywords\": 8\n",
    "        },\n",
    "        language_processor=create_text_processor(\n",
    "            language=\"en\",\n",
    "            config=lang_configs.get(\"en\", {})\n",
    "        )\n",
    "    )\n",
    "    \n",
    "    fi_analyzer = KeywordAnalyzer(\n",
    "        config={\n",
    "            **fi_params.general.model_dump(),  # Convert to dict\n",
    "            \"weights\": {\"statistical\": 0.4, \"llm\": 0.6},\n",
    "            \"max_keywords\": 8\n",
    "        },\n",
    "        language_processor=create_text_processor(\n",
    "            language=\"fi\",\n",
    "            config=lang_configs.get(\"fi\", {})\n",
    "        )\n",
    "    )\n",
    "    \n",
    "    results = {}\n",
    "    \n",
    "    # Test English content\n",
    "    print(\"Testing English content:\")\n",
    "    print(\"=\" * 50)\n",
    "    for content_type in tester.get_content_types(\"en\"):\n",
    "        print(f\"\\nTesting {content_type} content:\")\n",
    "        results[f\"en_{content_type}\"] = await tester.test_content_type(\n",
    "            \"en\", \n",
    "            content_type, \n",
    "            en_analyzer,\n",
    "            show_comparison=show_comparison\n",
    "        )\n",
    "    \n",
    "    # Test Finnish content\n",
    "    print(\"\\nTesting Finnish content:\")\n",
    "    print(\"=\" * 50)\n",
    "    for content_type in tester.get_content_types(\"fi\"):\n",
    "        print(f\"\\nTesting {content_type} content:\")\n",
    "        results[f\"fi_{content_type}\"] = await tester.test_content_type(\n",
    "            \"fi\", \n",
    "            content_type, \n",
    "            fi_analyzer,\n",
    "            show_comparison=show_comparison\n",
    "        )\n",
    "    \n",
    "    return results\n",
    "\n",
    "# Helper function for single text analysis\n",
    "async def analyze_single_text(text: str, language: str = \"en\", show_comparison: bool = True):\n",
    "    \"\"\"Analyze a single text with optional comparison.\n",
    "    \n",
    "    Args:\n",
    "        text: Text to analyze\n",
    "        language: Language code ('en' or 'fi')\n",
    "        show_comparison: If True, shows comparison between different analysis methods\n",
    "    \"\"\"\n",
    "    tester = ContentTester()\n",
    "    \n",
    "    if show_comparison:\n",
    "        return await tester.analyze_text_with_comparison(text, language)\n",
    "    else:\n",
    "        return await tester.analyze_single_text(text, language)\n",
    "\n",
    "\n",
    "\n",
    "# Run in notebook:\n",
    "# All tests:\n",
    "# results = await run_content_tests()\n",
    "\n",
    "# Single text analysis:\n",
    "# result = await analyze_text(\"Your text here\", language=\"en\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Display helpers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_keyword_comparison(stat_keywords: List[str], llm_keywords: List[str], combined_keywords: List[str]) -> Dict:\n",
    "    \"\"\"Analyze and compare keywords from different methods.\"\"\"\n",
    "    # Find overlaps and unique keywords\n",
    "    all_keywords = set(stat_keywords) | set(llm_keywords) | set(combined_keywords)\n",
    "    \n",
    "    analysis = {\n",
    "        \"all_methods\": set(stat_keywords) & set(llm_keywords) & set(combined_keywords),\n",
    "        \"stat_llm_only\": set(stat_keywords) & set(llm_keywords) - set(combined_keywords),\n",
    "        \"stat_combined_only\": set(stat_keywords) & set(combined_keywords) - set(llm_keywords),\n",
    "        \"llm_combined_only\": set(llm_keywords) & set(combined_keywords) - set(stat_keywords),\n",
    "        \"stat_only\": set(stat_keywords) - set(llm_keywords) - set(combined_keywords),\n",
    "        \"llm_only\": set(llm_keywords) - set(stat_keywords) - set(combined_keywords),\n",
    "        \"combined_only\": set(combined_keywords) - set(stat_keywords) - set(llm_keywords)\n",
    "    }\n",
    "    \n",
    "    return analysis\n",
    "\n",
    "def display_comparison_results(text: str, stat_results: Any, llm_results: Any, combined_results: Any):\n",
    "    \"\"\"Display enhanced comparison of analysis results.\"\"\"\n",
    "    print(\"\\nOriginal Text:\")\n",
    "    print(\"-\" * 50)\n",
    "    print(text.strip())\n",
    "    \n",
    "    print(\"\\nResults Comparison:\")\n",
    "    print(\"-\" * 50)\n",
    "    \n",
    "    # Get keywords from each method\n",
    "    stat_kw = stat_results.keywords if hasattr(stat_results, \"keywords\") else []\n",
    "    llm_kw = llm_results.keywords if hasattr(llm_results, \"keywords\") else []\n",
    "    combined_kw = combined_results.keywords if hasattr(combined_results, \"keywords\") else []\n",
    "    \n",
    "    # Analyze overlaps\n",
    "    analysis = analyze_keyword_comparison(stat_kw, llm_kw, combined_kw)\n",
    "    \n",
    "    # Display basic results\n",
    "    print(\"\\nKeywords by Method:\")\n",
    "    print(\"Statistical:\", stat_kw)\n",
    "    print(\"LLM:\", llm_kw)\n",
    "    print(\"Combined:\", combined_kw)\n",
    "    \n",
    "    # Display analysis\n",
    "    print(\"\\nKeyword Analysis:\")\n",
    "    print(\"Found by all methods:\", sorted(analysis[\"all_methods\"]))\n",
    "    print(\"Statistical & LLM only:\", sorted(analysis[\"stat_llm_only\"]))\n",
    "    print(\"Statistical & Combined only:\", sorted(analysis[\"stat_combined_only\"]))\n",
    "    print(\"LLM & Combined only:\", sorted(analysis[\"llm_combined_only\"]))\n",
    "    print(\"Statistical only:\", sorted(analysis[\"stat_only\"]))\n",
    "    print(\"LLM only:\", sorted(analysis[\"llm_only\"]))\n",
    "    print(\"Combined only:\", sorted(analysis[\"combined_only\"]))\n",
    "    \n",
    "    # Display domain-specific insights\n",
    "    print(\"\\nDomain Analysis:\")\n",
    "    if hasattr(combined_results, \"domain_keywords\"):\n",
    "        for domain, keywords in combined_results.domain_keywords.items():\n",
    "            print(f\"{domain}:\", keywords)\n",
    "    \n",
    "    # Provide insights\n",
    "    print(\"\\nInsights:\")\n",
    "    print(\"- Statistical method found\", len(stat_kw), \"keywords\")\n",
    "    print(\"- LLM method found\", len(llm_kw), \"keywords\")\n",
    "    print(\"- Combined method found\", len(combined_kw), \"keywords\")\n",
    "    print(\"- Agreement between all methods:\", len(analysis[\"all_methods\"]), \"keywords\")\n",
    "    \n",
    "    # Calculate Jaccard similarity\n",
    "    def jaccard_similarity(set1, set2):\n",
    "        if not set1 or not set2:\n",
    "            return 0\n",
    "        return len(set1 & set2) / len(set1 | set2)\n",
    "    \n",
    "    print(\"\\nSimilarity Analysis:\")\n",
    "    print(\"Statistical vs LLM:\", f\"{jaccard_similarity(set(stat_kw), set(llm_kw)):.2f}\")\n",
    "    print(\"Statistical vs Combined:\", f\"{jaccard_similarity(set(stat_kw), set(combined_kw)):.2f}\")\n",
    "    print(\"LLM vs Combined:\", f\"{jaccard_similarity(set(llm_kw), set(combined_kw)):.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-11 13:27:15 - src.utils.FileUtils.file_utils - INFO - Attempting to load file: c:\\Users\\tja\\OneDrive - Rastor-instituutti ry\\Tiedostot\\Rastor-instituutti\\kehittäminen\\analytiikka\\repos\\semantic-text-analyzer\\data\\raw\\test_content_en.xlsx\n",
      "2024-11-11 13:27:15 - src.utils.FileUtils.file_utils - INFO - Successfully loaded Excel file: c:\\Users\\tja\\OneDrive - Rastor-instituutti ry\\Tiedostot\\Rastor-instituutti\\kehittäminen\\analytiikka\\repos\\semantic-text-analyzer\\data\\raw\\test_content_en.xlsx\n",
      "2024-11-11 13:27:15 - src.utils.FileUtils.file_utils - INFO - Attempting to load file: c:\\Users\\tja\\OneDrive - Rastor-instituutti ry\\Tiedostot\\Rastor-instituutti\\kehittäminen\\analytiikka\\repos\\semantic-text-analyzer\\data\\raw\\test_content_fi.xlsx\n",
      "2024-11-11 13:27:15 - src.utils.FileUtils.file_utils - INFO - Successfully loaded Excel file: c:\\Users\\tja\\OneDrive - Rastor-instituutti ry\\Tiedostot\\Rastor-instituutti\\kehittäminen\\analytiikka\\repos\\semantic-text-analyzer\\data\\raw\\test_content_fi.xlsx\n",
      "2024-11-11 13:27:15 - src.utils.FileUtils.file_utils - INFO - Data saved to c:\\Users\\tja\\OneDrive - Rastor-instituutti ry\\Tiedostot\\Rastor-instituutti\\kehittäminen\\analytiikka\\repos\\semantic-text-analyzer\\data\\raw\\test_texts.xlsx\n",
      "2024-11-11 13:27:15 - __main__ - INFO - Loading config from: c:\\Users\\tja\\OneDrive - Rastor-instituutti ry\\Tiedostot\\Rastor-instituutti\\kehittäminen\\analytiikka\\repos\\semantic-text-analyzer\\config.yaml\n",
      "2024-11-11 13:27:15 - src.utils.FileUtils.file_utils - INFO - Successfully loaded 4 sheets from c:\\Users\\tja\\OneDrive - Rastor-instituutti ry\\Tiedostot\\Rastor-instituutti\\kehittäminen\\analytiikka\\repos\\semantic-text-analyzer\\data\\configurations\\parameters_en.xlsx\n",
      "2024-11-11 13:27:15 - src.utils.FileUtils.file_utils - INFO - Successfully loaded 4 sheets from c:\\Users\\tja\\OneDrive - Rastor-instituutti ry\\Tiedostot\\Rastor-instituutti\\kehittäminen\\analytiikka\\repos\\semantic-text-analyzer\\data\\configurations\\parameters_fi.xlsx\n",
      "2024-11-11 13:27:15 - src.core.language_processing.factory - INFO - Using default configuration\n",
      "2024-11-11 13:27:15 - src.core.language_processing.english - INFO - Initialized English processor with 831 stopwords\n",
      "2024-11-11 13:27:15 - src.core.language_processing.english - INFO - Initialized English processor with 831 stopwords\n",
      "2024-11-11 13:27:17 - src.core.language_processing.factory - INFO - Using default configuration\n",
      "2024-11-11 13:27:17 - src.core.language_processing.finnish - INFO - Loaded 747 stopwords from c:\\Users\\tja\\OneDrive - Rastor-instituutti ry\\Tiedostot\\Rastor-instituutti\\kehittäminen\\analytiikka\\repos\\semantic-text-analyzer\\data\\configurations\\stop_words\\fi.txt\n",
      "2024-11-11 13:27:17 - src.core.language_processing.finnish - INFO - Detected platform: win32\n",
      "2024-11-11 13:27:17 - src.core.language_processing.finnish - INFO - Using Voikko path from config: C:/scripts/Voikko\n",
      "Exception ignored in: <function Voikko.__del__ at 0x000002799EAD65E0>\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\tja\\AppData\\Local\\miniconda3\\envs\\semantic-analyzer\\lib\\site-packages\\libvoikko.py\", line 446, in __del__\n",
      "    self.terminate()\n",
      "  File \"c:\\Users\\tja\\AppData\\Local\\miniconda3\\envs\\semantic-analyzer\\lib\\site-packages\\libvoikko.py\", line 476, in terminate\n",
      "    if self.__handle:\n",
      "AttributeError: 'Voikko' object has no attribute '_Voikko__handle'\n",
      "2024-11-11 13:27:17 - src.core.language_processing.finnish - INFO - Added C:/scripts/Voikko to DLL search path\n",
      "2024-11-11 13:27:17 - src.core.language_processing.finnish - INFO - Verifying Voikko installation...\n",
      "2024-11-11 13:27:17 - src.core.language_processing.finnish - INFO - DLL exists: True (C:/scripts/Voikko\\libvoikko-1.dll)\n",
      "2024-11-11 13:27:17 - src.core.language_processing.finnish - INFO - Found dictionary version 5 at: C:/scripts/Voikko\\voikko\\5\\mor-standard\n",
      "2024-11-11 13:27:17 - src.core.language_processing.finnish - INFO - Successfully initialized Voikko with path: C:/scripts/Voikko\n",
      "2024-11-11 13:27:19 - __main__ - INFO - Processing 3 texts for en business\n",
      "2024-11-11 13:27:19 - src.core.language_processing.factory - INFO - Using default configuration\n",
      "2024-11-11 13:27:19 - src.core.language_processing.english - INFO - Initialized English processor with 831 stopwords\n",
      "2024-11-11 13:27:19 - src.core.language_processing.english - INFO - Initialized English processor with 831 stopwords\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing English content:\n",
      "==================================================\n",
      "\n",
      "Testing business content:\n",
      "\n",
      "Text 1:\n",
      "--------------------------------------------------\n",
      "Content: Q3 financial results show 15% revenue growth and improved profit margins. Customer acquisition costs...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-11 13:27:24 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-11-11 13:27:24 - src.core.language_processing.factory - INFO - Using default configuration\n",
      "2024-11-11 13:27:24 - src.core.language_processing.english - INFO - Initialized English processor with 831 stopwords\n",
      "2024-11-11 13:27:24 - src.core.language_processing.english - INFO - Initialized English processor with 831 stopwords\n",
      "2024-11-11 13:27:29 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-11-11 13:27:34 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-11-11 13:27:34 - src.core.language_processing.factory - INFO - Using default configuration\n",
      "2024-11-11 13:27:34 - src.core.language_processing.english - INFO - Initialized English processor with 831 stopwords\n",
      "2024-11-11 13:27:34 - src.core.language_processing.english - INFO - Initialized English processor with 831 stopwords\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Results Comparison:\n",
      "------------------------------\n",
      "Statistical: ['financial', 'revenue', 'improve', 'result', 'growth']\n",
      "LLM: ['financial', 'revenue', 'growth', 'profit', 'customer']\n",
      "Combined: ['financial', 'revenue', 'growth', 'profit', 'acquisition']\n",
      "\n",
      "Text 2:\n",
      "--------------------------------------------------\n",
      "Content: Strategic partnerships drive innovation and market penetration. Investment in R&D resulted in three ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-11 13:27:38 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-11-11 13:27:38 - src.core.language_processing.factory - INFO - Using default configuration\n",
      "2024-11-11 13:27:38 - src.core.language_processing.english - INFO - Initialized English processor with 831 stopwords\n",
      "2024-11-11 13:27:38 - src.core.language_processing.english - INFO - Initialized English processor with 831 stopwords\n",
      "2024-11-11 13:27:42 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-11-11 13:27:45 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-11-11 13:27:45 - src.core.language_processing.factory - INFO - Using default configuration\n",
      "2024-11-11 13:27:45 - src.core.language_processing.english - INFO - Initialized English processor with 831 stopwords\n",
      "2024-11-11 13:27:45 - src.core.language_processing.english - INFO - Initialized English processor with 831 stopwords\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Results Comparison:\n",
      "------------------------------\n",
      "Statistical: ['partnership', 'penetration', 'innovation', 'strategic', 'drive']\n",
      "LLM: ['strategic', 'innovation', 'partnerships', 'market', 'penetration']\n",
      "Combined: ['innovation', 'strategic', 'penetration', 'market', 'investment']\n",
      "\n",
      "Text 3:\n",
      "--------------------------------------------------\n",
      "Content: Operational efficiency improved through process automation. Customer satisfaction metrics show posit...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-11 13:27:49 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-11-11 13:27:49 - src.core.language_processing.factory - INFO - Using default configuration\n",
      "2024-11-11 13:27:49 - src.core.language_processing.english - INFO - Initialized English processor with 831 stopwords\n",
      "2024-11-11 13:27:49 - src.core.language_processing.english - INFO - Initialized English processor with 831 stopwords\n",
      "2024-11-11 13:27:53 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-11-11 13:27:56 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-11-11 13:27:56 - __main__ - INFO - Processing 2 texts for en general\n",
      "2024-11-11 13:27:56 - src.core.language_processing.factory - INFO - Using default configuration\n",
      "2024-11-11 13:27:56 - src.core.language_processing.english - INFO - Initialized English processor with 831 stopwords\n",
      "2024-11-11 13:27:56 - src.core.language_processing.english - INFO - Initialized English processor with 831 stopwords\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Results Comparison:\n",
      "------------------------------\n",
      "Statistical: ['operational', 'efficiency', 'automation', 'improve', 'process']\n",
      "LLM: ['operational', 'efficiency', 'automation', 'customer', 'satisfaction']\n",
      "Combined: ['operational', 'efficiency', 'automation', 'customer', 'satisfaction']\n",
      "\n",
      "Testing general content:\n",
      "\n",
      "Text 1:\n",
      "--------------------------------------------------\n",
      "Content: Team collaboration improved with new communication tools. Project timeline adjustments accommodate a...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-11 13:28:00 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-11-11 13:28:00 - src.core.language_processing.factory - INFO - Using default configuration\n",
      "2024-11-11 13:28:00 - src.core.language_processing.english - INFO - Initialized English processor with 831 stopwords\n",
      "2024-11-11 13:28:00 - src.core.language_processing.english - INFO - Initialized English processor with 831 stopwords\n",
      "2024-11-11 13:28:04 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-11-11 13:28:07 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-11-11 13:28:07 - src.core.language_processing.factory - INFO - Using default configuration\n",
      "2024-11-11 13:28:07 - src.core.language_processing.english - INFO - Initialized English processor with 831 stopwords\n",
      "2024-11-11 13:28:07 - src.core.language_processing.english - INFO - Initialized English processor with 831 stopwords\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Results Comparison:\n",
      "------------------------------\n",
      "Statistical: ['collaboration', 'communication', 'improve', 'team', 'tool']\n",
      "LLM: ['collaboration', 'communication', 'improved', 'team', 'tools']\n",
      "Combined: ['collaboration', 'communication', 'team', 'project', 'timeline']\n",
      "\n",
      "Text 2:\n",
      "--------------------------------------------------\n",
      "Content: Knowledge sharing sessions enhance team capabilities. Regular updates maintain stakeholder engagemen...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-11 13:28:11 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-11-11 13:28:11 - src.core.language_processing.factory - INFO - Using default configuration\n",
      "2024-11-11 13:28:11 - src.core.language_processing.english - INFO - Initialized English processor with 831 stopwords\n",
      "2024-11-11 13:28:11 - src.core.language_processing.english - INFO - Initialized English processor with 831 stopwords\n",
      "2024-11-11 13:28:16 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-11-11 13:28:19 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-11-11 13:28:19 - __main__ - INFO - Processing 3 texts for en technical\n",
      "2024-11-11 13:28:19 - src.core.language_processing.factory - INFO - Using default configuration\n",
      "2024-11-11 13:28:19 - src.core.language_processing.english - INFO - Initialized English processor with 831 stopwords\n",
      "2024-11-11 13:28:19 - src.core.language_processing.english - INFO - Initialized English processor with 831 stopwords\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Results Comparison:\n",
      "------------------------------\n",
      "Statistical: ['capability', 'knowledge', 'session', 'enhance', 'share']\n",
      "LLM: ['knowledge', 'enhance', 'sharing', 'sessions', 'capabilities']\n",
      "Combined: ['knowledge', 'enhance', 'team', 'stakeholder', 'engagement']\n",
      "\n",
      "Testing technical content:\n",
      "\n",
      "Text 1:\n",
      "--------------------------------------------------\n",
      "Content: Machine learning models are trained using large datasets to recognize patterns. The neural network a...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-11 13:28:22 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-11-11 13:28:22 - src.core.language_processing.factory - INFO - Using default configuration\n",
      "2024-11-11 13:28:22 - src.core.language_processing.english - INFO - Initialized English processor with 831 stopwords\n",
      "2024-11-11 13:28:22 - src.core.language_processing.english - INFO - Initialized English processor with 831 stopwords\n",
      "2024-11-11 13:28:26 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-11-11 13:28:29 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-11-11 13:28:29 - src.core.language_processing.factory - INFO - Using default configuration\n",
      "2024-11-11 13:28:29 - src.core.language_processing.english - INFO - Initialized English processor with 831 stopwords\n",
      "2024-11-11 13:28:29 - src.core.language_processing.english - INFO - Initialized English processor with 831 stopwords\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Results Comparison:\n",
      "------------------------------\n",
      "Statistical: ['recognize', 'datasets', 'machine', 'pattern', 'learn']\n",
      "LLM: ['machine learning', 'neural network', 'feature extraction', 'data preprocessing', 'feature engineering']\n",
      "Combined: ['machine learning', 'neural network', 'feature extraction', 'data preprocessing', 'feature engineering']\n",
      "\n",
      "Text 2:\n",
      "--------------------------------------------------\n",
      "Content: Cloud computing services provide scalable infrastructure for deployments. Microservices architecture...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-11 13:28:34 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-11-11 13:28:34 - src.core.language_processing.factory - INFO - Using default configuration\n",
      "2024-11-11 13:28:34 - src.core.language_processing.english - INFO - Initialized English processor with 831 stopwords\n",
      "2024-11-11 13:28:34 - src.core.language_processing.english - INFO - Initialized English processor with 831 stopwords\n",
      "2024-11-11 13:28:38 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-11-11 13:28:41 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-11-11 13:28:41 - src.core.language_processing.factory - INFO - Using default configuration\n",
      "2024-11-11 13:28:41 - src.core.language_processing.english - INFO - Initialized English processor with 831 stopwords\n",
      "2024-11-11 13:28:41 - src.core.language_processing.english - INFO - Initialized English processor with 831 stopwords\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Results Comparison:\n",
      "------------------------------\n",
      "Statistical: ['infrastructure', 'deployment', 'scalable', 'compute', 'service']\n",
      "LLM: ['cloud computing', 'scalable infrastructure', 'microservices architecture', 'system design', 'API endpoints']\n",
      "Combined: ['authentication', 'cloud computing', 'scalable infrastructure', 'microservices architecture', 'system design']\n",
      "\n",
      "Text 3:\n",
      "--------------------------------------------------\n",
      "Content: Version control systems track changes in source code repositories. Continuous integration ensures co...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-11 13:28:46 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-11-11 13:28:46 - src.core.language_processing.factory - INFO - Using default configuration\n",
      "2024-11-11 13:28:46 - src.core.language_processing.english - INFO - Initialized English processor with 831 stopwords\n",
      "2024-11-11 13:28:46 - src.core.language_processing.english - INFO - Initialized English processor with 831 stopwords\n",
      "2024-11-11 13:28:50 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-11-11 13:28:55 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-11-11 13:28:55 - __main__ - INFO - Processing 3 texts for fi business\n",
      "2024-11-11 13:28:55 - src.core.language_processing.factory - INFO - Using default configuration\n",
      "2024-11-11 13:28:55 - src.core.language_processing.finnish - INFO - Loaded 747 stopwords from c:\\Users\\tja\\OneDrive - Rastor-instituutti ry\\Tiedostot\\Rastor-instituutti\\kehittäminen\\analytiikka\\repos\\semantic-text-analyzer\\data\\configurations\\stop_words\\fi.txt\n",
      "2024-11-11 13:28:55 - src.core.language_processing.finnish - INFO - Detected platform: win32\n",
      "2024-11-11 13:28:55 - src.core.language_processing.finnish - INFO - Added C:\\scripts\\Voikko to DLL search path\n",
      "2024-11-11 13:28:55 - src.core.language_processing.finnish - INFO - Verifying Voikko installation...\n",
      "2024-11-11 13:28:55 - src.core.language_processing.finnish - INFO - DLL exists: True (C:\\scripts\\Voikko\\libvoikko-1.dll)\n",
      "2024-11-11 13:28:55 - src.core.language_processing.finnish - INFO - Found dictionary version 5 at: C:\\scripts\\Voikko\\voikko\\5\\mor-standard\n",
      "2024-11-11 13:28:55 - src.core.language_processing.finnish - INFO - Successfully initialized Voikko with path: C:\\scripts\\Voikko\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Results Comparison:\n",
      "------------------------------\n",
      "Statistical: ['repository', 'version', 'control', 'change', 'source']\n",
      "LLM: ['version control', 'source code', 'continuous integration', 'code quality', 'automated testing']\n",
      "Combined: ['version control', 'source code', 'continuous integration', 'code quality', 'automated testing']\n",
      "\n",
      "Testing Finnish content:\n",
      "==================================================\n",
      "\n",
      "Testing business content:\n",
      "\n",
      "Text 1:\n",
      "--------------------------------------------------\n",
      "Content: Q3 taloudelliset tulokset osoittavat 15% liikevaihdon kasvun ja parantuneet katteet. Asiakashankinna...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-11 13:29:01 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-11-11 13:29:01 - src.core.language_processing.factory - INFO - Using default configuration\n",
      "2024-11-11 13:29:01 - src.core.language_processing.finnish - INFO - Loaded 747 stopwords from c:\\Users\\tja\\OneDrive - Rastor-instituutti ry\\Tiedostot\\Rastor-instituutti\\kehittäminen\\analytiikka\\repos\\semantic-text-analyzer\\data\\configurations\\stop_words\\fi.txt\n",
      "2024-11-11 13:29:01 - src.core.language_processing.finnish - INFO - Detected platform: win32\n",
      "2024-11-11 13:29:01 - src.core.language_processing.finnish - INFO - Added C:\\scripts\\Voikko to DLL search path\n",
      "2024-11-11 13:29:01 - src.core.language_processing.finnish - INFO - Verifying Voikko installation...\n",
      "2024-11-11 13:29:01 - src.core.language_processing.finnish - INFO - DLL exists: True (C:\\scripts\\Voikko\\libvoikko-1.dll)\n",
      "2024-11-11 13:29:01 - src.core.language_processing.finnish - INFO - Found dictionary version 5 at: C:\\scripts\\Voikko\\voikko\\5\\mor-standard\n",
      "2024-11-11 13:29:01 - src.core.language_processing.finnish - INFO - Successfully initialized Voikko with path: C:\\scripts\\Voikko\n",
      "2024-11-11 13:29:06 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-11-11 13:29:10 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-11-11 13:29:10 - src.core.language_processing.factory - INFO - Using default configuration\n",
      "2024-11-11 13:29:10 - src.core.language_processing.finnish - INFO - Loaded 747 stopwords from c:\\Users\\tja\\OneDrive - Rastor-instituutti ry\\Tiedostot\\Rastor-instituutti\\kehittäminen\\analytiikka\\repos\\semantic-text-analyzer\\data\\configurations\\stop_words\\fi.txt\n",
      "2024-11-11 13:29:10 - src.core.language_processing.finnish - INFO - Detected platform: win32\n",
      "2024-11-11 13:29:10 - src.core.language_processing.finnish - INFO - Added C:\\scripts\\Voikko to DLL search path\n",
      "2024-11-11 13:29:10 - src.core.language_processing.finnish - INFO - Verifying Voikko installation...\n",
      "2024-11-11 13:29:10 - src.core.language_processing.finnish - INFO - DLL exists: True (C:\\scripts\\Voikko\\libvoikko-1.dll)\n",
      "2024-11-11 13:29:10 - src.core.language_processing.finnish - INFO - Found dictionary version 5 at: C:\\scripts\\Voikko\\voikko\\5\\mor-standard\n",
      "2024-11-11 13:29:10 - src.core.language_processing.finnish - INFO - Successfully initialized Voikko with path: C:\\scripts\\Voikko\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Results Comparison:\n",
      "------------------------------\n",
      "Statistical: ['taloudellinen', 'liikevaihto', 'parantunut', 'osoittaa', 'tulos']\n",
      "LLM: ['taloudelliset', 'liikevaihdon', 'kasvun', 'asiakashankinnan', 'asiakaspysyvyys']\n",
      "Combined: ['asiakaspysyvyys', 'taloudelliset', 'liikevaihdon', 'kasvun', 'asiakashankinnan']\n",
      "\n",
      "Text 2:\n",
      "--------------------------------------------------\n",
      "Content: Strategiset kumppanuudet edistävät innovaatiota ja markkinapenetraatiota. T&K-investoinnit johtivat ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-11 13:29:15 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-11-11 13:29:15 - src.core.language_processing.factory - INFO - Using default configuration\n",
      "2024-11-11 13:29:15 - src.core.language_processing.finnish - INFO - Loaded 747 stopwords from c:\\Users\\tja\\OneDrive - Rastor-instituutti ry\\Tiedostot\\Rastor-instituutti\\kehittäminen\\analytiikka\\repos\\semantic-text-analyzer\\data\\configurations\\stop_words\\fi.txt\n",
      "2024-11-11 13:29:15 - src.core.language_processing.finnish - INFO - Detected platform: win32\n",
      "2024-11-11 13:29:15 - src.core.language_processing.finnish - INFO - Added C:\\scripts\\Voikko to DLL search path\n",
      "2024-11-11 13:29:15 - src.core.language_processing.finnish - INFO - Verifying Voikko installation...\n",
      "2024-11-11 13:29:15 - src.core.language_processing.finnish - INFO - DLL exists: True (C:\\scripts\\Voikko\\libvoikko-1.dll)\n",
      "2024-11-11 13:29:15 - src.core.language_processing.finnish - INFO - Found dictionary version 5 at: C:\\scripts\\Voikko\\voikko\\5\\mor-standard\n",
      "2024-11-11 13:29:15 - src.core.language_processing.finnish - INFO - Successfully initialized Voikko with path: C:\\scripts\\Voikko\n",
      "2024-11-11 13:29:21 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-11-11 13:29:25 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-11-11 13:29:25 - src.core.language_processing.factory - INFO - Using default configuration\n",
      "2024-11-11 13:29:25 - src.core.language_processing.finnish - INFO - Loaded 747 stopwords from c:\\Users\\tja\\OneDrive - Rastor-instituutti ry\\Tiedostot\\Rastor-instituutti\\kehittäminen\\analytiikka\\repos\\semantic-text-analyzer\\data\\configurations\\stop_words\\fi.txt\n",
      "2024-11-11 13:29:25 - src.core.language_processing.finnish - INFO - Detected platform: win32\n",
      "2024-11-11 13:29:25 - src.core.language_processing.finnish - INFO - Added C:\\scripts\\Voikko to DLL search path\n",
      "2024-11-11 13:29:25 - src.core.language_processing.finnish - INFO - Verifying Voikko installation...\n",
      "2024-11-11 13:29:25 - src.core.language_processing.finnish - INFO - DLL exists: True (C:\\scripts\\Voikko\\libvoikko-1.dll)\n",
      "2024-11-11 13:29:25 - src.core.language_processing.finnish - INFO - Found dictionary version 5 at: C:\\scripts\\Voikko\\voikko\\5\\mor-standard\n",
      "2024-11-11 13:29:25 - src.core.language_processing.finnish - INFO - Successfully initialized Voikko with path: C:\\scripts\\Voikko\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Results Comparison:\n",
      "------------------------------\n",
      "Statistical: ['markkinapenetraatio', 'strateginen', 'kumppanuus', 'innovaatio', 'edistää']\n",
      "LLM: ['markkinapenetraatiota', 'kumppanuudet', 'innovaatiota', 'T&K-investoinnit', 'tuotelanseeraukseen']\n",
      "Combined: ['markkinapenetraatiota', 'myyntitulos', 'kumppanuudet', 'innovaatiota', 'T&K-investoinnit']\n",
      "\n",
      "Text 3:\n",
      "--------------------------------------------------\n",
      "Content: Toiminnan tehokkuus parani prosessiautomaation avulla. Asiakastyytyväisyysmittarit osoittavat positi...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-11 13:29:31 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-11-11 13:29:31 - src.core.language_processing.factory - INFO - Using default configuration\n",
      "2024-11-11 13:29:31 - src.core.language_processing.finnish - INFO - Loaded 747 stopwords from c:\\Users\\tja\\OneDrive - Rastor-instituutti ry\\Tiedostot\\Rastor-instituutti\\kehittäminen\\analytiikka\\repos\\semantic-text-analyzer\\data\\configurations\\stop_words\\fi.txt\n",
      "2024-11-11 13:29:31 - src.core.language_processing.finnish - INFO - Detected platform: win32\n",
      "2024-11-11 13:29:31 - src.core.language_processing.finnish - INFO - Added C:\\scripts\\Voikko to DLL search path\n",
      "2024-11-11 13:29:31 - src.core.language_processing.finnish - INFO - Verifying Voikko installation...\n",
      "2024-11-11 13:29:31 - src.core.language_processing.finnish - INFO - DLL exists: True (C:\\scripts\\Voikko\\libvoikko-1.dll)\n",
      "2024-11-11 13:29:31 - src.core.language_processing.finnish - INFO - Found dictionary version 5 at: C:\\scripts\\Voikko\\voikko\\5\\mor-standard\n",
      "2024-11-11 13:29:31 - src.core.language_processing.finnish - INFO - Successfully initialized Voikko with path: C:\\scripts\\Voikko\n",
      "2024-11-11 13:29:36 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-11-11 13:29:39 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-11-11 13:29:39 - __main__ - INFO - Processing 2 texts for fi general\n",
      "2024-11-11 13:29:39 - src.core.language_processing.factory - INFO - Using default configuration\n",
      "2024-11-11 13:29:39 - src.core.language_processing.finnish - INFO - Loaded 747 stopwords from c:\\Users\\tja\\OneDrive - Rastor-instituutti ry\\Tiedostot\\Rastor-instituutti\\kehittäminen\\analytiikka\\repos\\semantic-text-analyzer\\data\\configurations\\stop_words\\fi.txt\n",
      "2024-11-11 13:29:39 - src.core.language_processing.finnish - INFO - Detected platform: win32\n",
      "2024-11-11 13:29:39 - src.core.language_processing.finnish - INFO - Added C:\\scripts\\Voikko to DLL search path\n",
      "2024-11-11 13:29:39 - src.core.language_processing.finnish - INFO - Verifying Voikko installation...\n",
      "2024-11-11 13:29:39 - src.core.language_processing.finnish - INFO - DLL exists: True (C:\\scripts\\Voikko\\libvoikko-1.dll)\n",
      "2024-11-11 13:29:39 - src.core.language_processing.finnish - INFO - Found dictionary version 5 at: C:\\scripts\\Voikko\\voikko\\5\\mor-standard\n",
      "2024-11-11 13:29:39 - src.core.language_processing.finnish - INFO - Successfully initialized Voikko with path: C:\\scripts\\Voikko\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Results Comparison:\n",
      "------------------------------\n",
      "Statistical: ['prosessiautomaatio', 'tehokkuus', 'toiminta', 'para', 'asiakastyytyväisyysmittari']\n",
      "LLM: ['prosessiautomaatio', 'tehokkuus', 'asiakastyytyväisyysmittarit', 'kustannusoptimointi', 'säästöt']\n",
      "Combined: ['prosessiautomaatio', 'tehokkuus', 'toiminta', 'kustannusoptimointi', 'asiakastyytyväisyysmittarit']\n",
      "\n",
      "Testing general content:\n",
      "\n",
      "Text 1:\n",
      "--------------------------------------------------\n",
      "Content: Tiimin yhteistyö parani uusien viestintätyökalujen myötä. Projektiaikataulua mukautettiin lisävaatim...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-11 13:29:44 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-11-11 13:29:44 - src.core.language_processing.factory - INFO - Using default configuration\n",
      "2024-11-11 13:29:44 - src.core.language_processing.finnish - INFO - Loaded 747 stopwords from c:\\Users\\tja\\OneDrive - Rastor-instituutti ry\\Tiedostot\\Rastor-instituutti\\kehittäminen\\analytiikka\\repos\\semantic-text-analyzer\\data\\configurations\\stop_words\\fi.txt\n",
      "2024-11-11 13:29:44 - src.core.language_processing.finnish - INFO - Detected platform: win32\n",
      "2024-11-11 13:29:44 - src.core.language_processing.finnish - INFO - Added C:\\scripts\\Voikko to DLL search path\n",
      "2024-11-11 13:29:44 - src.core.language_processing.finnish - INFO - Verifying Voikko installation...\n",
      "2024-11-11 13:29:44 - src.core.language_processing.finnish - INFO - DLL exists: True (C:\\scripts\\Voikko\\libvoikko-1.dll)\n",
      "2024-11-11 13:29:44 - src.core.language_processing.finnish - INFO - Found dictionary version 5 at: C:\\scripts\\Voikko\\voikko\\5\\mor-standard\n",
      "2024-11-11 13:29:44 - src.core.language_processing.finnish - INFO - Successfully initialized Voikko with path: C:\\scripts\\Voikko\n",
      "2024-11-11 13:29:49 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-11-11 13:30:05 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-11-11 13:30:05 - src.core.language_processing.factory - INFO - Using default configuration\n",
      "2024-11-11 13:30:05 - src.core.language_processing.finnish - INFO - Loaded 747 stopwords from c:\\Users\\tja\\OneDrive - Rastor-instituutti ry\\Tiedostot\\Rastor-instituutti\\kehittäminen\\analytiikka\\repos\\semantic-text-analyzer\\data\\configurations\\stop_words\\fi.txt\n",
      "2024-11-11 13:30:05 - src.core.language_processing.finnish - INFO - Detected platform: win32\n",
      "2024-11-11 13:30:05 - src.core.language_processing.finnish - INFO - Added C:\\scripts\\Voikko to DLL search path\n",
      "2024-11-11 13:30:05 - src.core.language_processing.finnish - INFO - Verifying Voikko installation...\n",
      "2024-11-11 13:30:05 - src.core.language_processing.finnish - INFO - DLL exists: True (C:\\scripts\\Voikko\\libvoikko-1.dll)\n",
      "2024-11-11 13:30:05 - src.core.language_processing.finnish - INFO - Found dictionary version 5 at: C:\\scripts\\Voikko\\voikko\\5\\mor-standard\n",
      "2024-11-11 13:30:05 - src.core.language_processing.finnish - INFO - Successfully initialized Voikko with path: C:\\scripts\\Voikko\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Results Comparison:\n",
      "------------------------------\n",
      "Statistical: ['viestintätyökalu', 'yhteistyö', 'tiimi', 'para', 'projektiaikataulu']\n",
      "LLM: ['yhteistyö', 'viestintätyökalujen', 'projektiaikataulu', 'resurssien', 'tehtäväjaon']\n",
      "Combined: ['yhteistyö', 'projektiaikataulu', 'viestintätyökalujen', 'varmistaa', 'resurssien']\n",
      "\n",
      "Text 2:\n",
      "--------------------------------------------------\n",
      "Content: Tiedonjakotilaisuudet kehittävät tiimin osaamista. Säännölliset päivitykset ylläpitävät sidosryhmien...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-11 13:30:10 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-11-11 13:30:10 - src.core.language_processing.factory - INFO - Using default configuration\n",
      "2024-11-11 13:30:10 - src.core.language_processing.finnish - INFO - Loaded 747 stopwords from c:\\Users\\tja\\OneDrive - Rastor-instituutti ry\\Tiedostot\\Rastor-instituutti\\kehittäminen\\analytiikka\\repos\\semantic-text-analyzer\\data\\configurations\\stop_words\\fi.txt\n",
      "2024-11-11 13:30:10 - src.core.language_processing.finnish - INFO - Detected platform: win32\n",
      "2024-11-11 13:30:10 - src.core.language_processing.finnish - INFO - Added C:\\scripts\\Voikko to DLL search path\n",
      "2024-11-11 13:30:10 - src.core.language_processing.finnish - INFO - Verifying Voikko installation...\n",
      "2024-11-11 13:30:10 - src.core.language_processing.finnish - INFO - DLL exists: True (C:\\scripts\\Voikko\\libvoikko-1.dll)\n",
      "2024-11-11 13:30:10 - src.core.language_processing.finnish - INFO - Found dictionary version 5 at: C:\\scripts\\Voikko\\voikko\\5\\mor-standard\n",
      "2024-11-11 13:30:10 - src.core.language_processing.finnish - INFO - Successfully initialized Voikko with path: C:\\scripts\\Voikko\n",
      "2024-11-11 13:30:15 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-11-11 13:30:18 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-11-11 13:30:18 - __main__ - INFO - Processing 3 texts for fi technical\n",
      "2024-11-11 13:30:18 - src.core.language_processing.factory - INFO - Using default configuration\n",
      "2024-11-11 13:30:18 - src.core.language_processing.finnish - INFO - Loaded 747 stopwords from c:\\Users\\tja\\OneDrive - Rastor-instituutti ry\\Tiedostot\\Rastor-instituutti\\kehittäminen\\analytiikka\\repos\\semantic-text-analyzer\\data\\configurations\\stop_words\\fi.txt\n",
      "2024-11-11 13:30:18 - src.core.language_processing.finnish - INFO - Detected platform: win32\n",
      "2024-11-11 13:30:18 - src.core.language_processing.finnish - INFO - Added C:\\scripts\\Voikko to DLL search path\n",
      "2024-11-11 13:30:18 - src.core.language_processing.finnish - INFO - Verifying Voikko installation...\n",
      "2024-11-11 13:30:18 - src.core.language_processing.finnish - INFO - DLL exists: True (C:\\scripts\\Voikko\\libvoikko-1.dll)\n",
      "2024-11-11 13:30:18 - src.core.language_processing.finnish - INFO - Found dictionary version 5 at: C:\\scripts\\Voikko\\voikko\\5\\mor-standard\n",
      "2024-11-11 13:30:18 - src.core.language_processing.finnish - INFO - Successfully initialized Voikko with path: C:\\scripts\\Voikko\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Results Comparison:\n",
      "------------------------------\n",
      "Statistical: ['tiedonjakotilaisuus', 'kehittävä', 'tiimi', 'osata', 'laadunvarmistuskäytäntö']\n",
      "LLM: ['tiedonjakotilaisuus', 'laadunvarmistuskäytäntö', 'kehittävä', 'tiimi', 'osaaminen']\n",
      "Combined: ['tiedonjakotilaisuus', 'kehittävä', 'tiimi', 'laadunvarmistuskäytäntö', 'osaaminen']\n",
      "\n",
      "Testing technical content:\n",
      "\n",
      "Text 1:\n",
      "--------------------------------------------------\n",
      "Content: Koneoppimismalleja koulutetaan suurilla datajoukolla tunnistamaan kaavoja. Neuroverkon arkkitehtuuri...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-11 13:30:23 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-11-11 13:30:23 - src.core.language_processing.factory - INFO - Using default configuration\n",
      "2024-11-11 13:30:23 - src.core.language_processing.finnish - INFO - Loaded 747 stopwords from c:\\Users\\tja\\OneDrive - Rastor-instituutti ry\\Tiedostot\\Rastor-instituutti\\kehittäminen\\analytiikka\\repos\\semantic-text-analyzer\\data\\configurations\\stop_words\\fi.txt\n",
      "2024-11-11 13:30:23 - src.core.language_processing.finnish - INFO - Detected platform: win32\n",
      "2024-11-11 13:30:23 - src.core.language_processing.finnish - INFO - Added C:\\scripts\\Voikko to DLL search path\n",
      "2024-11-11 13:30:23 - src.core.language_processing.finnish - INFO - Verifying Voikko installation...\n",
      "2024-11-11 13:30:23 - src.core.language_processing.finnish - INFO - DLL exists: True (C:\\scripts\\Voikko\\libvoikko-1.dll)\n",
      "2024-11-11 13:30:23 - src.core.language_processing.finnish - INFO - Found dictionary version 5 at: C:\\scripts\\Voikko\\voikko\\5\\mor-standard\n",
      "2024-11-11 13:30:23 - src.core.language_processing.finnish - INFO - Successfully initialized Voikko with path: C:\\scripts\\Voikko\n",
      "2024-11-11 13:30:29 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-11-11 13:30:32 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-11-11 13:30:33 - src.core.language_processing.factory - INFO - Using default configuration\n",
      "2024-11-11 13:30:33 - src.core.language_processing.finnish - INFO - Loaded 747 stopwords from c:\\Users\\tja\\OneDrive - Rastor-instituutti ry\\Tiedostot\\Rastor-instituutti\\kehittäminen\\analytiikka\\repos\\semantic-text-analyzer\\data\\configurations\\stop_words\\fi.txt\n",
      "2024-11-11 13:30:33 - src.core.language_processing.finnish - INFO - Detected platform: win32\n",
      "2024-11-11 13:30:33 - src.core.language_processing.finnish - INFO - Added C:\\scripts\\Voikko to DLL search path\n",
      "2024-11-11 13:30:33 - src.core.language_processing.finnish - INFO - Verifying Voikko installation...\n",
      "2024-11-11 13:30:33 - src.core.language_processing.finnish - INFO - DLL exists: True (C:\\scripts\\Voikko\\libvoikko-1.dll)\n",
      "2024-11-11 13:30:33 - src.core.language_processing.finnish - INFO - Found dictionary version 5 at: C:\\scripts\\Voikko\\voikko\\5\\mor-standard\n",
      "2024-11-11 13:30:33 - src.core.language_processing.finnish - INFO - Successfully initialized Voikko with path: C:\\scripts\\Voikko\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Results Comparison:\n",
      "------------------------------\n",
      "Statistical: ['koneoppimismalli', 'datajoukko', 'kouluttaa', 'tunnistaa', 'kaava']\n",
      "LLM: ['koneoppimismalli', 'datajoukko', 'kouluttaa', 'tunnistaa', 'kaava']\n",
      "Combined: ['koneoppimismalli', 'datajoukko', 'kouluttaa', 'tunnistaa', 'kaava']\n",
      "\n",
      "Text 2:\n",
      "--------------------------------------------------\n",
      "Content: Pilvipalvelut tarjoavat skaalautuvan infrastruktuurin käyttöönottoon. Mikropalveluarkkitehtuuri mahd...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-11 13:30:38 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-11-11 13:30:38 - src.core.language_processing.factory - INFO - Using default configuration\n",
      "2024-11-11 13:30:38 - src.core.language_processing.finnish - INFO - Loaded 747 stopwords from c:\\Users\\tja\\OneDrive - Rastor-instituutti ry\\Tiedostot\\Rastor-instituutti\\kehittäminen\\analytiikka\\repos\\semantic-text-analyzer\\data\\configurations\\stop_words\\fi.txt\n",
      "2024-11-11 13:30:38 - src.core.language_processing.finnish - INFO - Detected platform: win32\n",
      "2024-11-11 13:30:38 - src.core.language_processing.finnish - INFO - Added C:\\scripts\\Voikko to DLL search path\n",
      "2024-11-11 13:30:38 - src.core.language_processing.finnish - INFO - Verifying Voikko installation...\n",
      "2024-11-11 13:30:38 - src.core.language_processing.finnish - INFO - DLL exists: True (C:\\scripts\\Voikko\\libvoikko-1.dll)\n",
      "2024-11-11 13:30:38 - src.core.language_processing.finnish - INFO - Found dictionary version 5 at: C:\\scripts\\Voikko\\voikko\\5\\mor-standard\n",
      "2024-11-11 13:30:38 - src.core.language_processing.finnish - INFO - Successfully initialized Voikko with path: C:\\scripts\\Voikko\n",
      "2024-11-11 13:30:45 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-11-11 13:30:49 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-11-11 13:30:49 - src.core.language_processing.factory - INFO - Using default configuration\n",
      "2024-11-11 13:30:49 - src.core.language_processing.finnish - INFO - Loaded 747 stopwords from c:\\Users\\tja\\OneDrive - Rastor-instituutti ry\\Tiedostot\\Rastor-instituutti\\kehittäminen\\analytiikka\\repos\\semantic-text-analyzer\\data\\configurations\\stop_words\\fi.txt\n",
      "2024-11-11 13:30:49 - src.core.language_processing.finnish - INFO - Detected platform: win32\n",
      "2024-11-11 13:30:49 - src.core.language_processing.finnish - INFO - Added C:\\scripts\\Voikko to DLL search path\n",
      "2024-11-11 13:30:49 - src.core.language_processing.finnish - INFO - Verifying Voikko installation...\n",
      "2024-11-11 13:30:49 - src.core.language_processing.finnish - INFO - DLL exists: True (C:\\scripts\\Voikko\\libvoikko-1.dll)\n",
      "2024-11-11 13:30:49 - src.core.language_processing.finnish - INFO - Found dictionary version 5 at: C:\\scripts\\Voikko\\voikko\\5\\mor-standard\n",
      "2024-11-11 13:30:49 - src.core.language_processing.finnish - INFO - Successfully initialized Voikko with path: C:\\scripts\\Voikko\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Results Comparison:\n",
      "------------------------------\n",
      "Statistical: ['infrastruktuuri', 'pilvipalvelu', 'käyttöönotto', 'skaalautuva', 'tarjota']\n",
      "LLM: ['pilvipalvelut', 'skaalautuvan', 'infrastruktuurin', 'käyttöönottoon', 'mikropalveluarkkitehtuuri']\n",
      "Combined: ['mikropalveluarkkitehtuuri', 'pilvipalvelut', 'skaalautuvan', 'autentikoinnin', 'infrastruktuurin']\n",
      "\n",
      "Text 3:\n",
      "--------------------------------------------------\n",
      "Content: Versionhallintajärjestelmät seuraavat lähdekoodin muutoksia. Jatkuva integraatio varmistaa koodin la...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-11 13:30:54 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-11-11 13:30:54 - src.core.language_processing.factory - INFO - Using default configuration\n",
      "2024-11-11 13:30:54 - src.core.language_processing.finnish - INFO - Loaded 747 stopwords from c:\\Users\\tja\\OneDrive - Rastor-instituutti ry\\Tiedostot\\Rastor-instituutti\\kehittäminen\\analytiikka\\repos\\semantic-text-analyzer\\data\\configurations\\stop_words\\fi.txt\n",
      "2024-11-11 13:30:54 - src.core.language_processing.finnish - INFO - Detected platform: win32\n",
      "2024-11-11 13:30:54 - src.core.language_processing.finnish - INFO - Added C:\\scripts\\Voikko to DLL search path\n",
      "2024-11-11 13:30:54 - src.core.language_processing.finnish - INFO - Verifying Voikko installation...\n",
      "2024-11-11 13:30:54 - src.core.language_processing.finnish - INFO - DLL exists: True (C:\\scripts\\Voikko\\libvoikko-1.dll)\n",
      "2024-11-11 13:30:54 - src.core.language_processing.finnish - INFO - Found dictionary version 5 at: C:\\scripts\\Voikko\\voikko\\5\\mor-standard\n",
      "2024-11-11 13:30:54 - src.core.language_processing.finnish - INFO - Successfully initialized Voikko with path: C:\\scripts\\Voikko\n",
      "2024-11-11 13:30:59 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-11-11 13:31:03 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Results Comparison:\n",
      "------------------------------\n",
      "Statistical: ['versionhallintajärjestelmä', 'lähdekoodi', 'muutos', 'automaattitestaus', 'järjestelmäarkkitehtuuri']\n",
      "LLM: ['versionhallintajärjestelmä', 'lähdekoodi', 'muutos', 'automaattitestaus', 'järjestelmäarkkitehtuuri']\n",
      "Combined: ['versionhallintajärjestelmä', 'lähdekoodi', 'muutos', 'automaattitestaus', 'järjestelmäarkkitehtuuri']\n"
     ]
    }
   ],
   "source": [
    "# Run all tests with comparison (default)\n",
    "results = await run_content_tests()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run all tests without comparison\n",
    "results = await run_content_tests(show_comparison=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze a single text without comparison\n",
    "# results = await analyze_single_text(\n",
    "#     \"\"\"Your text here...\"\"\",\n",
    "#     language=\"en\",\n",
    "#     show_comparison=False\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-11 12:38:19 - src.utils.FileUtils.file_utils - INFO - Attempting to load file: c:\\Users\\tja\\OneDrive - Rastor-instituutti ry\\Tiedostot\\Rastor-instituutti\\kehittäminen\\analytiikka\\repos\\semantic-text-analyzer\\data\\raw\\test_content_en.xlsx\n",
      "2024-11-11 12:38:19 - src.utils.FileUtils.file_utils - INFO - Successfully loaded Excel file: c:\\Users\\tja\\OneDrive - Rastor-instituutti ry\\Tiedostot\\Rastor-instituutti\\kehittäminen\\analytiikka\\repos\\semantic-text-analyzer\\data\\raw\\test_content_en.xlsx\n",
      "2024-11-11 12:38:19 - src.utils.FileUtils.file_utils - INFO - Attempting to load file: c:\\Users\\tja\\OneDrive - Rastor-instituutti ry\\Tiedostot\\Rastor-instituutti\\kehittäminen\\analytiikka\\repos\\semantic-text-analyzer\\data\\raw\\test_content_fi.xlsx\n",
      "2024-11-11 12:38:19 - src.utils.FileUtils.file_utils - INFO - Successfully loaded Excel file: c:\\Users\\tja\\OneDrive - Rastor-instituutti ry\\Tiedostot\\Rastor-instituutti\\kehittäminen\\analytiikka\\repos\\semantic-text-analyzer\\data\\raw\\test_content_fi.xlsx\n",
      "2024-11-11 12:38:19 - __main__ - WARNING - Could not load main config: File does not exist: c:\\Users\\tja\\OneDrive - Rastor-instituutti ry\\Tiedostot\\Rastor-instituutti\\kehittäminen\\analytiikka\\repos\\semantic-text-analyzer\\data\\raw\\config.yaml\n",
      "2024-11-11 12:38:19 - src.utils.FileUtils.file_utils - INFO - Successfully loaded 4 sheets from c:\\Users\\tja\\OneDrive - Rastor-instituutti ry\\Tiedostot\\Rastor-instituutti\\kehittäminen\\analytiikka\\repos\\semantic-text-analyzer\\data\\configurations\\parameters_en.xlsx\n",
      "2024-11-11 12:38:19 - src.utils.FileUtils.file_utils - INFO - Successfully loaded 4 sheets from c:\\Users\\tja\\OneDrive - Rastor-instituutti ry\\Tiedostot\\Rastor-instituutti\\kehittäminen\\analytiikka\\repos\\semantic-text-analyzer\\data\\configurations\\parameters_fi.xlsx\n",
      "2024-11-11 12:38:20 - src.core.language_processing.factory - INFO - Using default configuration\n",
      "2024-11-11 12:38:20 - src.core.language_processing.english - INFO - Initialized English processor with 831 stopwords\n",
      "2024-11-11 12:38:20 - src.core.language_processing.english - INFO - Initialized English processor with 831 stopwords\n",
      "2024-11-11 12:38:21 - src.core.language_processing.factory - INFO - Using default configuration\n",
      "2024-11-11 12:38:21 - src.core.language_processing.finnish - INFO - Loaded 747 stopwords from c:\\Users\\tja\\OneDrive - Rastor-instituutti ry\\Tiedostot\\Rastor-instituutti\\kehittäminen\\analytiikka\\repos\\semantic-text-analyzer\\data\\configurations\\stop_words\\fi.txt\n",
      "2024-11-11 12:38:21 - src.core.language_processing.finnish - INFO - Detected platform: win32\n",
      "2024-11-11 12:38:21 - src.core.language_processing.finnish - INFO - Added C:\\scripts\\Voikko to DLL search path\n",
      "2024-11-11 12:38:21 - src.core.language_processing.finnish - INFO - Verifying Voikko installation...\n",
      "2024-11-11 12:38:21 - src.core.language_processing.finnish - INFO - DLL exists: True (C:\\scripts\\Voikko\\libvoikko-1.dll)\n",
      "2024-11-11 12:38:21 - src.core.language_processing.finnish - INFO - Found dictionary version 5 at: C:\\scripts\\Voikko\\voikko\\5\\mor-standard\n",
      "2024-11-11 12:38:21 - src.core.language_processing.finnish - INFO - Successfully initialized Voikko with path: C:\\scripts\\Voikko\n",
      "2024-11-11 12:38:22 - __main__ - INFO - Processing 3 texts for en technical\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing English content:\n",
      "==================================================\n",
      "\n",
      "Testing technical content:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-11 12:38:33 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Text 1:\n",
      "Keywords: ['machine learning', 'neural network', 'feature extraction', 'data preprocessing', 'feature engineering']\n",
      "Domain Keywords: {'machine learning': ['recognize', 'datasets', 'learn', 'pattern']}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-11 12:38:36 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Text 2:\n",
      "Keywords: ['authentication', 'cloud computing', 'scalable infrastructure', 'microservices architecture', 'system design']\n",
      "Domain Keywords: {'cloud': ['cloud computing', 'scalable infrastructure', 'API endpoints'], 'architecture': ['microservices architecture', 'system design'], 'security': ['authentication', 'data validation']}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-11 12:38:39 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-11-11 12:38:39 - __main__ - INFO - Processing 3 texts for en business\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Text 3:\n",
      "Keywords: ['version control', 'source code', 'continuous integration', 'code quality', 'automated testing']\n",
      "Domain Keywords: {'version_control': ['repository', 'version', 'control', 'change', 'source']}\n",
      "\n",
      "Text 1:\n",
      "Keywords: ['machine learning', 'neural network', 'feature extraction', 'data preprocessing', 'feature engineering']\n",
      "Domain Keywords: {'machine learning': ['recognize', 'datasets', 'learn', 'pattern']}\n",
      "\n",
      "Text 2:\n",
      "Keywords: ['authentication', 'cloud computing', 'scalable infrastructure', 'microservices architecture', 'system design']\n",
      "Domain Keywords: {'cloud': ['cloud computing', 'scalable infrastructure', 'API endpoints'], 'architecture': ['microservices architecture', 'system design'], 'security': ['authentication', 'data validation']}\n",
      "\n",
      "Text 3:\n",
      "Keywords: ['version control', 'source code', 'continuous integration', 'code quality', 'automated testing']\n",
      "Domain Keywords: {'version_control': ['repository', 'version', 'control', 'change', 'source']}\n",
      "\n",
      "Testing business content:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-11 12:38:42 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Text 1:\n",
      "Keywords: ['financial', 'revenue', 'growth', 'profit', 'acquisition']\n",
      "Domain Keywords: {'finance': ['financial', 'revenue', 'profit', 'margins'], 'business': ['growth', 'acquisition', 'retention', 'strategy']}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-11 12:38:44 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Text 2:\n",
      "Keywords: ['innovation', 'strategic', 'penetration', 'market', 'investment']\n",
      "Domain Keywords: {'business': ['partnership', 'innovation', 'market', 'penetration', 'investment', 'performance', 'sales']}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-11 12:38:47 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-11-11 12:38:47 - __main__ - INFO - Processing 2 texts for en general\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Text 3:\n",
      "Keywords: ['operational', 'efficiency', 'automation', 'customer', 'satisfaction']\n",
      "Domain Keywords: {'business': ['operational', 'efficiency', 'automation', 'cost', 'optimization'], 'metrics': ['customer', 'satisfaction', 'year-over-year']}\n",
      "\n",
      "Text 1:\n",
      "Keywords: ['financial', 'revenue', 'growth', 'profit', 'acquisition']\n",
      "Domain Keywords: {'finance': ['financial', 'revenue', 'profit', 'margins'], 'business': ['growth', 'acquisition', 'retention', 'strategy']}\n",
      "\n",
      "Text 2:\n",
      "Keywords: ['innovation', 'strategic', 'penetration', 'market', 'investment']\n",
      "Domain Keywords: {'business': ['partnership', 'innovation', 'market', 'penetration', 'investment', 'performance', 'sales']}\n",
      "\n",
      "Text 3:\n",
      "Keywords: ['operational', 'efficiency', 'automation', 'customer', 'satisfaction']\n",
      "Domain Keywords: {'business': ['operational', 'efficiency', 'automation', 'cost', 'optimization'], 'metrics': ['customer', 'satisfaction', 'year-over-year']}\n",
      "\n",
      "Testing general content:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-11 12:38:51 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Text 1:\n",
      "Keywords: ['collaboration', 'communication', 'team', 'project', 'timeline']\n",
      "Domain Keywords: {'project_management': ['collaboration', 'communication', 'resource allocation', 'task distribution']}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-11 12:38:54 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-11-11 12:38:54 - __main__ - INFO - Processing 3 texts for fi technical\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Text 2:\n",
      "Keywords: ['knowledge', 'enhance', 'team', 'stakeholder', 'engagement']\n",
      "Domain Keywords: {'general': ['knowledge', 'capability', 'session', 'enhance', 'share']}\n",
      "\n",
      "Text 1:\n",
      "Keywords: ['collaboration', 'communication', 'team', 'project', 'timeline']\n",
      "Domain Keywords: {'project_management': ['collaboration', 'communication', 'resource allocation', 'task distribution']}\n",
      "\n",
      "Text 2:\n",
      "Keywords: ['knowledge', 'enhance', 'team', 'stakeholder', 'engagement']\n",
      "Domain Keywords: {'general': ['knowledge', 'capability', 'session', 'enhance', 'share']}\n",
      "\n",
      "Testing Finnish content:\n",
      "==================================================\n",
      "\n",
      "Testing technical content:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-11 12:38:57 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Text 1:\n",
      "Keywords: ['koneoppimismalli', 'datajoukko', 'kouluttaa', 'tunnistaa', 'kaava']\n",
      "Domain Keywords: {'machine_learning': ['koneoppimismalli', 'datajoukko', 'kouluttaa', 'tunnistaa', 'kaava']}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-11 12:39:01 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Text 2:\n",
      "Keywords: ['mikropalveluarkkitehtuuri', 'pilvipalvelut', 'skaalautuvan', 'autentikoinnin', 'infrastruktuurin']\n",
      "Domain Keywords: {'cloud_services': ['pilvipalvelut', 'infrastruktuuri', 'käyttöönotto'], 'architecture': ['mikropalveluarkkitehtuuri', 'modulaarisen'], 'authentication': ['autentikoinnin']}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-11 12:39:06 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-11-11 12:39:06 - __main__ - INFO - Processing 3 texts for fi business\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Text 3:\n",
      "Keywords: ['versionhallintajärjestelmä', 'lähdekoodi', 'muutos', 'automaattitestaus', 'järjestelmäarkkitehtuuri']\n",
      "Domain Keywords: {'software_development': ['versionhallintajärjestelmä', 'lähdekoodi', 'automaattitestaus', 'järjestelmäarkkitehtuuri']}\n",
      "\n",
      "Text 1:\n",
      "Keywords: ['koneoppimismalli', 'datajoukko', 'kouluttaa', 'tunnistaa', 'kaava']\n",
      "Domain Keywords: {'machine_learning': ['koneoppimismalli', 'datajoukko', 'kouluttaa', 'tunnistaa', 'kaava']}\n",
      "\n",
      "Text 2:\n",
      "Keywords: ['mikropalveluarkkitehtuuri', 'pilvipalvelut', 'skaalautuvan', 'autentikoinnin', 'infrastruktuurin']\n",
      "Domain Keywords: {'cloud_services': ['pilvipalvelut', 'infrastruktuuri', 'käyttöönotto'], 'architecture': ['mikropalveluarkkitehtuuri', 'modulaarisen'], 'authentication': ['autentikoinnin']}\n",
      "\n",
      "Text 3:\n",
      "Keywords: ['versionhallintajärjestelmä', 'lähdekoodi', 'muutos', 'automaattitestaus', 'järjestelmäarkkitehtuuri']\n",
      "Domain Keywords: {'software_development': ['versionhallintajärjestelmä', 'lähdekoodi', 'automaattitestaus', 'järjestelmäarkkitehtuuri']}\n",
      "\n",
      "Testing business content:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-11 12:39:10 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Text 1:\n",
      "Keywords: ['asiakaspysyvyys', 'taloudelliset', 'liikevaihdon', 'kasvun', 'katteet']\n",
      "Domain Keywords: {'talous': ['taloudelliset', 'liikevaihto', 'tulos'], 'markkinointi': ['asiakashankinnan', 'asiakaspysyvyys']}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-11 12:39:13 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Text 2:\n",
      "Keywords: ['markkinapenetraatiota', 'myyntitulos', 'kumppanuudet', 'innovaatiota', 'T&K-investoinnit']\n",
      "Domain Keywords: {'business': ['kumppanuudet', 'markkinapenetraatio', 'innovaatiota', 'strateginen', 'edistää']}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-11 12:39:16 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-11-11 12:39:16 - __main__ - INFO - Processing 2 texts for fi general\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Text 3:\n",
      "Keywords: ['prosessiautomaatio', 'tehokkuus', 'toiminta', 'kustannusoptimointi', 'asiakastyytyväisyysmittarit']\n",
      "Domain Keywords: {'business': ['tehokkuus', 'prosessiautomaatio', 'asiakastyytyväisyysmittarit', 'kustannusoptimointi']}\n",
      "\n",
      "Text 1:\n",
      "Keywords: ['asiakaspysyvyys', 'taloudelliset', 'liikevaihdon', 'kasvun', 'katteet']\n",
      "Domain Keywords: {'talous': ['taloudelliset', 'liikevaihto', 'tulos'], 'markkinointi': ['asiakashankinnan', 'asiakaspysyvyys']}\n",
      "\n",
      "Text 2:\n",
      "Keywords: ['markkinapenetraatiota', 'myyntitulos', 'kumppanuudet', 'innovaatiota', 'T&K-investoinnit']\n",
      "Domain Keywords: {'business': ['kumppanuudet', 'markkinapenetraatio', 'innovaatiota', 'strateginen', 'edistää']}\n",
      "\n",
      "Text 3:\n",
      "Keywords: ['prosessiautomaatio', 'tehokkuus', 'toiminta', 'kustannusoptimointi', 'asiakastyytyväisyysmittarit']\n",
      "Domain Keywords: {'business': ['tehokkuus', 'prosessiautomaatio', 'asiakastyytyväisyysmittarit', 'kustannusoptimointi']}\n",
      "\n",
      "Testing general content:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-11 12:39:21 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Text 1:\n",
      "Keywords: ['yhteistyö', 'projektiaikataulu', 'viestintätyökalujen', 'varmistaa', 'resurssien']\n",
      "Domain Keywords: {'project_management': ['yhteistyö', 'projektiaikataulu', 'resurssien']}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-11 12:39:26 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Text 2:\n",
      "Keywords: ['tiedonjakotilaisuus', 'kehittävä', 'tiimi', 'laadunvarmistuskäytäntö', 'osaaminen']\n",
      "Domain Keywords: {'team_development': ['tiedonjakotilaisuus', 'kehittävä', 'tiimi', 'osaaminen'], 'quality_assurance': ['laadunvarmistuskäytäntö', 'säännölliset']}\n",
      "\n",
      "Text 1:\n",
      "Keywords: ['yhteistyö', 'projektiaikataulu', 'viestintätyökalujen', 'varmistaa', 'resurssien']\n",
      "Domain Keywords: {'project_management': ['yhteistyö', 'projektiaikataulu', 'resurssien']}\n",
      "\n",
      "Text 2:\n",
      "Keywords: ['tiedonjakotilaisuus', 'kehittävä', 'tiimi', 'laadunvarmistuskäytäntö', 'osaaminen']\n",
      "Domain Keywords: {'team_development': ['tiedonjakotilaisuus', 'kehittävä', 'tiimi', 'osaaminen'], 'quality_assurance': ['laadunvarmistuskäytäntö', 'säännölliset']}\n"
     ]
    }
   ],
   "source": [
    "results = await run_content_tests()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze a single text with comparison\n",
    "# results = await analyze_single_text(\n",
    "#     \"\"\"Strategic partnerships drive innovation and market penetration. Investment in R&amp;D resulted in three new product launches. Sales performance exceeded targets in key market segments. \"\"\",\n",
    "#     language=\"en\",\n",
    "#     show_comparison=True\n",
    "# )\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-11 13:24:30 - src.utils.FileUtils.file_utils - INFO - Attempting to load file: c:\\Users\\tja\\OneDrive - Rastor-instituutti ry\\Tiedostot\\Rastor-instituutti\\kehittäminen\\analytiikka\\repos\\semantic-text-analyzer\\data\\raw\\test_content_en.xlsx\n",
      "2024-11-11 13:24:30 - src.utils.FileUtils.file_utils - INFO - Successfully loaded Excel file: c:\\Users\\tja\\OneDrive - Rastor-instituutti ry\\Tiedostot\\Rastor-instituutti\\kehittäminen\\analytiikka\\repos\\semantic-text-analyzer\\data\\raw\\test_content_en.xlsx\n",
      "2024-11-11 13:24:30 - src.utils.FileUtils.file_utils - INFO - Attempting to load file: c:\\Users\\tja\\OneDrive - Rastor-instituutti ry\\Tiedostot\\Rastor-instituutti\\kehittäminen\\analytiikka\\repos\\semantic-text-analyzer\\data\\raw\\test_content_fi.xlsx\n",
      "2024-11-11 13:24:30 - src.utils.FileUtils.file_utils - INFO - Successfully loaded Excel file: c:\\Users\\tja\\OneDrive - Rastor-instituutti ry\\Tiedostot\\Rastor-instituutti\\kehittäminen\\analytiikka\\repos\\semantic-text-analyzer\\data\\raw\\test_content_fi.xlsx\n",
      "2024-11-11 13:24:30 - src.utils.FileUtils.file_utils - INFO - Data saved to c:\\Users\\tja\\OneDrive - Rastor-instituutti ry\\Tiedostot\\Rastor-instituutti\\kehittäminen\\analytiikka\\repos\\semantic-text-analyzer\\data\\raw\\test_texts.xlsx\n",
      "2024-11-11 13:24:30 - src.core.language_processing.factory - INFO - Using default configuration\n",
      "2024-11-11 13:24:30 - src.core.language_processing.english - INFO - Initialized English processor with 831 stopwords\n",
      "2024-11-11 13:24:30 - src.core.language_processing.english - INFO - Initialized English processor with 831 stopwords\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Running Analysis with Comparison:\n",
      "==================================================\n",
      "Text: Strategic partnerships drive innovation and market penetration. \n",
      "Investment in R&D resulted in three...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-11 13:24:35 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-11-11 13:24:35 - src.core.language_processing.factory - INFO - Using default configuration\n",
      "2024-11-11 13:24:35 - src.core.language_processing.english - INFO - Initialized English processor with 831 stopwords\n",
      "2024-11-11 13:24:35 - src.core.language_processing.english - INFO - Initialized English processor with 831 stopwords\n",
      "2024-11-11 13:24:41 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-11-11 13:24:41 - src.core.language_processing.factory - INFO - Using default configuration\n",
      "2024-11-11 13:24:41 - src.core.language_processing.english - INFO - Initialized English processor with 831 stopwords\n",
      "2024-11-11 13:24:41 - src.core.language_processing.english - INFO - Initialized English processor with 831 stopwords\n",
      "2024-11-11 13:24:47 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Results Comparison:\n",
      "------------------------------\n",
      "Statistical: ['partnership', 'penetration', 'innovation', 'strategic', 'drive']\n",
      "LLM: ['strategic', 'innovation', 'penetration', 'partnerships', 'market']\n",
      "Combined: ['innovation', 'strategic', 'partnership', 'penetration', 'drive']\n"
     ]
    }
   ],
   "source": [
    "# Or analyze a single text with comparison\n",
    "\n",
    "text = \"\"\"Strategic partnerships drive innovation and market penetration. \n",
    "Investment in R&D resulted in three new product launches. \n",
    "Sales performance exceeded targets in key market segments.\"\"\"\n",
    "\n",
    "tester = ContentTester()\n",
    "stat_resuls, llm_resuls, combined_resuls = await tester.analyze_text_with_comparison(\n",
    "    text,\n",
    "    language=\"en\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Original Text:\n",
      "--------------------------------------------------\n",
      "Strategic partnerships drive innovation and market penetration. \n",
      "Investment in R&D resulted in three new product launches. \n",
      "Sales performance exceeded targets in key market segments.\n",
      "\n",
      "Results Comparison:\n",
      "--------------------------------------------------\n",
      "\n",
      "Keywords by Method:\n",
      "Statistical: ['partnership', 'penetration', 'innovation', 'strategic', 'drive']\n",
      "LLM: ['strategic', 'innovation', 'penetration', 'partnerships', 'market']\n",
      "Combined: ['innovation', 'strategic', 'partnership', 'penetration', 'drive']\n",
      "\n",
      "Keyword Analysis:\n",
      "Found by all methods: ['innovation', 'penetration', 'strategic']\n",
      "Statistical & LLM only: []\n",
      "Statistical & Combined only: ['drive', 'partnership']\n",
      "LLM & Combined only: []\n",
      "Statistical only: []\n",
      "LLM only: ['market', 'partnerships']\n",
      "Combined only: []\n",
      "\n",
      "Domain Analysis:\n",
      "business: ['partnership', 'innovation', 'market', 'sales', 'investment']\n",
      "\n",
      "Insights:\n",
      "- Statistical method found 5 keywords\n",
      "- LLM method found 5 keywords\n",
      "- Combined method found 5 keywords\n",
      "- Agreement between all methods: 3 keywords\n",
      "\n",
      "Similarity Analysis:\n",
      "Statistical vs LLM: 0.43\n",
      "Statistical vs Combined: 1.00\n",
      "LLM vs Combined: 0.43\n"
     ]
    }
   ],
   "source": [
    "# Example usage\n",
    "\n",
    "\n",
    "display_comparison_results(text, stat_resuls, llm_results, combined_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# results = await run_content_tests()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test technical text\n",
    "# await test_text(\"technical\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test business text\n",
    "# await test_text(\"business\")\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test Finnish text\n",
    "# await test_text(\"finnish\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "semantic-analyzer",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
