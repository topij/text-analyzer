{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "# Import required modules\n",
        "import sys\n",
        "from pathlib import Path\n",
        "from typing import List, Dict, Any, Tuple, Union\n",
        "import logging\n",
        "import asyncio\n",
        "\n",
        "# Add project root to Python path if needed\n",
        "project_root = str(Path().resolve().parent)\n",
        "if project_root not in sys.path:\n",
        "    sys.path.append(project_root)\n",
        "\n",
        "# Import necessary components\n",
        "from src.nb_helpers.environment import setup_notebook_env, verify_environment\n",
        "from src.semantic_analyzer import SemanticAnalyzer\n",
        "from src.core.config import AnalyzerConfig\n",
        "\n",
        "from src.core.language_processing import create_text_processor\n",
        "from src.core.llm.factory import create_llm\n",
        "from src.loaders.parameter_handler import ParameterHandler\n",
        "from src.analyzers.keyword_analyzer import KeywordAnalyzer\n",
        "from src.analyzers.theme_analyzer import ThemeAnalyzer\n",
        "from src.analyzers.category_analyzer import CategoryAnalyzer\n",
        "\n",
        "import FileUtils\n"
      ],
      "outputs": [],
      "execution_count": 1,
      "metadata": {
        "gather": {
          "logged": 1733580303851
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# In analyzer_demo_local_nb.ipynb and azure_notebook.ipynb\n",
        "# from src.core.llm.factory import create_llm\n",
        "\n",
        "# Setup\n",
        "# config = AnalyzerConfig()\n",
        "# llm = create_llm(config=config)\n",
        "# analyzer = SemanticAnalyzer(llm=llm)"
      ],
      "outputs": [],
      "execution_count": 24,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "print(FileUtils.__version__)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "0.5.3\n"
        }
      ],
      "execution_count": 2,
      "metadata": {
        "gather": {
          "logged": 1733580307180
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Set up environment and logging\n",
        "setup_notebook_env(log_level=\"DEBUG\")\n",
        "verify_environment()\n",
        "\n"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "2024-12-07 14:05:09,631 - FileUtils.core.file_utils - INFO - Project root: /mnt/batch/tasks/shared/LS_root/mounts/clusters/basic-cpu/code/Users/topi.jarvinen/semantic-text-analyzer\n2024-12-07 14:05:09,675 - FileUtils.core.file_utils - INFO - FileUtils initialized with local storage\n2024-12-07 14:05:09,727 - FileUtils.core.file_utils - INFO - Project root: /mnt/batch/tasks/shared/LS_root/mounts/clusters/basic-cpu/code/Users/topi.jarvinen/semantic-text-analyzer\n2024-12-07 14:05:09,736 - FileUtils.core.file_utils - INFO - FileUtils initialized with local storage\nEnvironment Check Results:\n==================================================\n\nBasic Setup:\n-----------\n✓ Project root in path\n✓ FileUtils initialized\n✓ .env file loaded\n\nEnvironment Variables:\n---------------------\n✓ OPENAI_API_KEY set\n✓ ANTHROPIC_API_KEY set\n\nProject Structure:\n-----------------\n✓ Raw data exists\n✓ Processed data exists\n✓ Configuration exists\n✓ Main config.yaml exists\n\n==================================================\nEnvironment Status: Ready ✓\n"
        },
        {
          "output_type": "execute_result",
          "execution_count": 3,
          "data": {
            "text/plain": "True"
          },
          "metadata": {}
        }
      ],
      "execution_count": 3,
      "metadata": {
        "gather": {
          "logged": 1733580309921
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Test data to use\n",
        "test_texts = {\n",
        "    \"en\": {\n",
        "        \"technical\": \"\"\"Machine learning models are trained using large datasets to recognize patterns. \n",
        "                     The neural network architecture includes multiple layers for feature extraction. \n",
        "                     Data preprocessing and feature engineering are crucial steps.\"\"\",\n",
        "        \"business\": \"\"\"Q3 financial results show 15% revenue growth and improved profit margins. \n",
        "                    Customer acquisition costs decreased while retention rates increased. \n",
        "                    Market expansion strategy focuses on emerging technology sectors.\"\"\"\n",
        "    },\n",
        "    \"fi\": {\n",
        "        \"technical\": \"\"\"Koneoppimismalleja koulutetaan suurilla datajoukolla tunnistamaan kaavoja. \n",
        "                     Neuroverkon arkkitehtuuri sisältää useita kerroksia piirteiden erottamiseen. \n",
        "                     Datan esikäsittely ja piirteiden suunnittelu ovat keskeisiä vaiheita.\"\"\",\n",
        "        \"business\": \"\"\"Q3 taloudelliset tulokset osoittavat 15% liikevaihdon kasvun ja parantuneet katteet. \n",
        "                    Asiakashankinnan kustannukset laskivat ja asiakaspysyvyys parani. \n",
        "                    Markkinalaajennusstrategia keskittyy nouseviin teknologiasektoreihin.\"\"\"\n",
        "    }\n",
        "}\n",
        "\n"
      ],
      "outputs": [],
      "execution_count": 4,
      "metadata": {
        "gather": {
          "logged": 1733580316587
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "     # llm = create_llm()\n",
        "config = AnalyzerConfig()"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "2024-12-07 14:05:19,080 - FileUtils.core.file_utils - INFO - Project root: /mnt/batch/tasks/shared/LS_root/mounts/clusters/basic-cpu/code/Users/topi.jarvinen/semantic-text-analyzer\n2024-12-07 14:05:19,172 - FileUtils.core.file_utils - INFO - FileUtils initialized with local storage\n"
        }
      ],
      "execution_count": 5,
      "metadata": {
        "gather": {
          "logged": 1733580319517
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "async def test_individual_analyzer(\n",
        "    analyzer: Union[KeywordAnalyzer, ThemeAnalyzer, CategoryAnalyzer], \n",
        "    text: str, \n",
        "    analyzer_type: str\n",
        "):\n",
        "    \"\"\"Test individual analyzer component.\"\"\"\n",
        "    print(f\"\\nTesting {analyzer_type} Analysis\")\n",
        "    print(\"=\" * 50)\n",
        "    print(\"\\nInput text:\")\n",
        "    print(text[:200] + \"...\" if len(text) > 200 else text)\n",
        "    \n",
        "    try:\n",
        "        results = await analyzer.analyze(text)\n",
        "        \n",
        "        print(\"\\nResults:\")\n",
        "        print(\"-\" * 20)\n",
        "        \n",
        "        if isinstance(analyzer, KeywordAnalyzer):\n",
        "            if results.keywords:\n",
        "                print(\"\\nKeywords:\")\n",
        "                for kw in results.keywords[:10]:  # Show top 10\n",
        "                    print(f\"• {kw.keyword:<20} ({kw.score:.2f})\")\n",
        "                    if kw.domain:\n",
        "                        print(f\"  Domain: {kw.domain}\")\n",
        "                \n",
        "                if results.compound_words:\n",
        "                    print(\"\\nCompound Words:\")\n",
        "                    print(\", \".join(results.compound_words))\n",
        "                    \n",
        "                if results.domain_keywords:\n",
        "                    print(\"\\nKeywords by Domain:\")\n",
        "                    for domain, kws in results.domain_keywords.items():\n",
        "                        print(f\"\\n{domain}:\")\n",
        "                        print(\", \".join(kws))\n",
        "                        \n",
        "        elif isinstance(analyzer, ThemeAnalyzer):\n",
        "            if results.themes:\n",
        "                print(\"\\nThemes:\")\n",
        "                for theme in results.themes:\n",
        "                    print(f\"\\n• {theme.name}\")\n",
        "                    print(f\"  Confidence: {theme.confidence:.2f}\")\n",
        "                    print(f\"  Description: {theme.description}\")\n",
        "                    if theme.keywords:\n",
        "                        print(f\"  Keywords: {', '.join(theme.keywords)}\")\n",
        "                \n",
        "                if results.theme_hierarchy:\n",
        "                    print(\"\\nTheme Hierarchy:\")\n",
        "                    for parent, children in results.theme_hierarchy.items():\n",
        "                        print(f\"{parent} -> {', '.join(children)}\")\n",
        "                        \n",
        "        elif isinstance(analyzer, CategoryAnalyzer):\n",
        "            if results.categories:\n",
        "                print(\"\\nCategories:\")\n",
        "                for cat in results.categories:\n",
        "                    print(f\"\\n• {cat.name}\")\n",
        "                    print(f\"  Confidence: {cat.confidence:.2f}\")\n",
        "                    if cat.description:\n",
        "                        print(f\"  Description: {cat.description}\")\n",
        "                    if cat.evidence:\n",
        "                        print(\"\\n  Evidence:\")\n",
        "                        for ev in cat.evidence:\n",
        "                            print(f\"  - {ev.text} (relevance: {ev.relevance:.2f})\")\n",
        "                            \n",
        "        if hasattr(results, 'error') and results.error:\n",
        "            print(f\"\\nErrors occurred: {results.error}\")\n",
        "            \n",
        "        return results\n",
        "        \n",
        "    except Exception as e:\n",
        "        print(f\"\\nError in analysis: {e}\")\n",
        "        return None"
      ],
      "outputs": [],
      "execution_count": 6,
      "metadata": {
        "gather": {
          "logged": 1733580328917
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Example 1: Test individual keyword analyzer\n",
        "async def test_keyword_analyzer(provider: str = \"openai\"):\n",
        "    \"\"\"Test keyword analyzer with different languages.\"\"\"\n",
        "    print(\"Testing Keyword Analyzer\")\n",
        "    print(\"=\" * 50)\n",
        "    \n",
        "    # Initialize components\n",
        "    parameter_handler = ParameterHandler(\"parameters_fi.xlsx\")\n",
        "    # llm = create_llm()\n",
        "    # config = AnalyzerConfig()\n",
        "    llm = create_llm(provider=provider, config=config)\n",
        "    # analyzer = SemanticAnalyzer(llm=llm)\n",
        "    \n",
        "    # Test English\n",
        "    print(\"\\nTesting English Technical Content:\")\n",
        "    en_processor = create_text_processor(language=\"en\")\n",
        "    keyword_analyzer_en = KeywordAnalyzer(\n",
        "        llm=llm,\n",
        "        config=parameter_handler.parameters.general.model_dump(),\n",
        "        language_processor=en_processor\n",
        "    )\n",
        "    await test_individual_analyzer(keyword_analyzer_en, test_texts[\"en\"][\"technical\"], \"Keyword\")\n",
        "    \n",
        "    # Test Finnish\n",
        "    print(\"\\nTesting Finnish Technical Content:\")\n",
        "    fi_processor = create_text_processor(language=\"fi\")\n",
        "    keyword_analyzer_fi = KeywordAnalyzer(\n",
        "        llm=llm,\n",
        "        config=parameter_handler.parameters.general.model_dump(),\n",
        "        language_processor=fi_processor\n",
        "    )\n",
        "    await test_individual_analyzer(keyword_analyzer_fi, test_texts[\"fi\"][\"technical\"], \"Keyword\")\n",
        "\n"
      ],
      "outputs": [],
      "execution_count": 7,
      "metadata": {
        "gather": {
          "logged": 1733580333665
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Example 2: Test all components\n",
        "async def test_components_for_language(language: str, provider: str = \"openai\"):\n",
        "    \"\"\"Test all components for a specific language.\"\"\"\n",
        "    print(f\"\\nTesting All Components for {language.upper()}\")\n",
        "    print(\"=\" * 50)\n",
        "    \n",
        "    # Initialize components\n",
        "    parameter_handler = ParameterHandler(f\"parameters_{language}.xlsx\")\n",
        "     # llm = create_llm()\n",
        "    # config = AnalyzerConfig()\n",
        "    llm = create_llm(provider=provider, config=config)\n",
        "\n",
        "    language_processor = create_text_processor(language=language)\n",
        "    \n",
        "    # Create analyzers\n",
        "    keyword_analyzer = KeywordAnalyzer(\n",
        "        llm=llm,\n",
        "        config=parameter_handler.parameters.general.model_dump(),\n",
        "        language_processor=language_processor\n",
        "    )\n",
        "    \n",
        "    theme_analyzer = ThemeAnalyzer(\n",
        "        llm=llm,\n",
        "        config=parameter_handler.parameters.general.model_dump(),\n",
        "        language_processor=language_processor\n",
        "    )\n",
        "    \n",
        "    category_analyzer = CategoryAnalyzer(\n",
        "        categories=parameter_handler.parameters.categories,\n",
        "        llm=llm,\n",
        "        config=parameter_handler.parameters.general.model_dump(),\n",
        "        language_processor=language_processor\n",
        "    )\n",
        "    \n",
        "    # Test technical content\n",
        "    print(f\"\\nTesting {language.upper()} Technical Content:\")\n",
        "    await test_individual_analyzer(keyword_analyzer, test_texts[language][\"technical\"], \"Keyword\")\n",
        "    await test_individual_analyzer(theme_analyzer, test_texts[language][\"technical\"], \"Theme\")\n",
        "    await test_individual_analyzer(category_analyzer, test_texts[language][\"technical\"], \"Category\")\n",
        "    \n",
        "    # Test business content\n",
        "    print(f\"\\nTesting {language.upper()} Business Content:\")\n",
        "    await test_individual_analyzer(keyword_analyzer, test_texts[language][\"business\"], \"Keyword\")\n",
        "    await test_individual_analyzer(theme_analyzer, test_texts[language][\"business\"], \"Theme\")\n",
        "    await test_individual_analyzer(category_analyzer, test_texts[language][\"business\"], \"Category\")\n",
        "\n"
      ],
      "outputs": [],
      "execution_count": 8,
      "metadata": {
        "gather": {
          "logged": 1733580337606
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Example 3: Quick test of full pipeline\n",
        "async def test_pipeline(provider='openai'):\n",
        "    \"\"\"Test full pipeline with both languages.\"\"\"\n",
        "    print(\"Testing Full Pipeline\")\n",
        "    print(\"=\" * 50)\n",
        "    \n",
        "    llm = create_llm(provider=provider, config=config)\n",
        "    # analyzer = SemanticAnalyzer(llm=llm)\n",
        "    # Test English pipeline\n",
        "    print(\"\\nEnglish Pipeline:\")\n",
        "    en_analyzer = SemanticAnalyzer(llm=llm, parameter_file=\"parameters_en.xlsx\")\n",
        "    result = await en_analyzer.analyze(test_texts[\"en\"][\"technical\"])\n",
        "    print(f\"Success: {result.success}\")\n",
        "    print(f\"Keywords found: {len(result.keywords.keywords)}\")\n",
        "    print(f\"Themes found: {len(result.themes.themes)}\")\n",
        "    print(f\"Categories found: {len(result.categories.matches)}\")\n",
        "    \n",
        "    # Test Finnish pipeline\n",
        "    print(\"\\nFinnish Pipeline:\")\n",
        "    fi_analyzer = SemanticAnalyzer(llm=llm, parameter_file=\"parameters_fi.xlsx\")\n",
        "    result = await fi_analyzer.analyze(test_texts[\"fi\"][\"technical\"])\n",
        "    print(f\"Success: {result.success}\")\n",
        "    print(f\"Keywords found: {len(result.keywords.keywords)}\")\n",
        "    print(f\"Themes found: {len(result.themes.themes)}\")\n",
        "    print(f\"Categories found: {len(result.categories.matches)}\")\n",
        "\n",
        "# Run the tests\n",
        "async def run_all_tests():\n",
        "    \"\"\"Run all tests.\"\"\"\n",
        "    # Test individual component\n",
        "    await test_keyword_analyzer()\n",
        "    \n",
        "    # Test all components by language\n",
        "    await test_components_for_language(\"en\")\n",
        "    await test_components_for_language(\"fi\")\n",
        "    \n",
        "    # Test full pipeline\n",
        "    await test_pipeline()\n",
        "\n"
      ],
      "outputs": [],
      "execution_count": 9,
      "metadata": {
        "gather": {
          "logged": 1733580341678
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Run in notebook\n",
        "# await run_all_tests()\n",
        "\n",
        "# Or run individual tests:\n",
        "# await test_keyword_analyzer()\n",
        "await test_components_for_language(\"fi\")\n",
        "# await test_pipeline()"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "\nTesting FI Technical Content:\n\nTesting Keyword Analysis\n==================================================\n\nInput text:\nKoneoppimismalleja koulutetaan suurilla datajoukolla tunnistamaan kaavoja. \n                     Neuroverkon arkkitehtuuri sisältää useita kerroksia piirteiden erottamiseen. \n                     Data...\n\nResults:\n--------------------\n\nKeywords:\n• koneoppimismalleja   (0.95)\n  Domain: technical\n• datajoukolla         (0.90)\n  Domain: technical\n• neuroverkon arkkitehtuuri (0.95)\n  Domain: technical\n• piirteiden erottaminen (0.90)\n  Domain: technical\n• datan esikäsittely   (0.95)\n  Domain: technical\n• piirteiden suunnittelu (0.90)\n  Domain: technical\n\nCompound Words:\nkoneoppimismalleja, datajoukolla, neuroverkon arkkitehtuuri, piirteiden erottaminen, datan esikäsittely, piirteiden suunnittelu\n\nTesting Theme Analysis\n==================================================\n\nInput text:\nKoneoppimismalleja koulutetaan suurilla datajoukolla tunnistamaan kaavoja. \n                     Neuroverkon arkkitehtuuri sisältää useita kerroksia piirteiden erottamiseen. \n                     Data...\n\nRaw LLM response: {'themes': [{'name': 'Koneoppimismallit', 'description': 'Koneoppimismallit koulutetaan suurilla datajoukolla tunnistamaan kaavoja, mikä on keskeinen osa koneoppimisen prosessia.', 'confidence': 0.95, 'keywords': ['koneoppiminen', 'datajoukko', 'kaavat'], 'domain': 'general content analysis'}, {'name': 'Neuroverkon arkkitehtuuri', 'description': 'Neuroverkon arkkitehtuuri koostuu useista kerroksista, jotka ovat tärkeitä piirteiden erottamisessa ja analysoinnissa.', 'confidence': 0.9, 'keywords': ['neuroverkko', 'arkkitehtuuri', 'kerrokset'], 'domain': 'general content analysis', 'parent_theme': 'Koneoppimismallit'}, {'name': 'Datan esikäsittely', 'description': 'Datan esikäsittely ja piirteiden suunnittelu ovat keskeisiä vaiheita koneoppimismallien tehokkuuden varmistamiseksi.', 'confidence': 0.85, 'keywords': ['esikäsittely', 'piirteet', 'suunnittelu'], 'domain': 'general content analysis', 'parent_theme': 'Koneoppimismallit'}], 'evidence': {'Koneoppimismallit': [{'text': 'Koneoppimismalleja koulutetaan suurilla datajoukolla tunnistamaan kaavoja.', 'relevance': 0.9, 'keywords': ['koneoppiminen', 'datajoukko', 'kaavat']}], 'Neuroverkon arkkitehtuuri': [{'text': 'Neuroverkon arkkitehtuuri sisältää useita kerroksia piirteiden erottamiseen.', 'relevance': 0.9, 'keywords': ['neuroverkko', 'arkkitehtuuri', 'kerrokset']}], 'Datan esikäsittely': [{'text': 'Datan esikäsittely ja piirteiden suunnittelu ovat keskeisiä vaiheita.', 'relevance': 0.9, 'keywords': ['esikäsittely', 'piirteet', 'suunnittelu']}]}, 'relationships': {'Koneoppimismallit': ['Neuroverkon arkkitehtuuri', 'Datan esikäsittely'], 'Neuroverkon arkkitehtuuri': [], 'Datan esikäsittely': []}}\n\nProcessed LLM response: {'themes': [{'name': 'Koneoppimismallit', 'description': 'Koneoppimismallit koulutetaan suurilla datajoukolla tunnistamaan kaavoja, mikä on keskeinen osa koneoppimisen prosessia.', 'confidence': 0.95, 'keywords': ['koneoppiminen', 'datajoukko', 'kaavat'], 'domain': 'general content analysis'}, {'name': 'Neuroverkon arkkitehtuuri', 'description': 'Neuroverkon arkkitehtuuri koostuu useista kerroksista, jotka ovat tärkeitä piirteiden erottamisessa ja analysoinnissa.', 'confidence': 0.9, 'keywords': ['neuroverkko', 'arkkitehtuuri', 'kerrokset'], 'domain': 'general content analysis', 'parent_theme': 'Koneoppimismallit'}, {'name': 'Datan esikäsittely', 'description': 'Datan esikäsittely ja piirteiden suunnittelu ovat keskeisiä vaiheita koneoppimismallien tehokkuuden varmistamiseksi.', 'confidence': 0.85, 'keywords': ['esikäsittely', 'piirteet', 'suunnittelu'], 'domain': 'general content analysis', 'parent_theme': 'Koneoppimismallit'}], 'evidence': {'Koneoppimismallit': [{'text': 'Koneoppimismalleja koulutetaan suurilla datajoukolla tunnistamaan kaavoja.', 'relevance': 0.9, 'keywords': ['koneoppiminen', 'datajoukko', 'kaavat']}], 'Neuroverkon arkkitehtuuri': [{'text': 'Neuroverkon arkkitehtuuri sisältää useita kerroksia piirteiden erottamiseen.', 'relevance': 0.9, 'keywords': ['neuroverkko', 'arkkitehtuuri', 'kerrokset']}], 'Datan esikäsittely': [{'text': 'Datan esikäsittely ja piirteiden suunnittelu ovat keskeisiä vaiheita.', 'relevance': 0.9, 'keywords': ['esikäsittely', 'piirteet', 'suunnittelu']}]}, 'relationships': {'Koneoppimismallit': ['Neuroverkon arkkitehtuuri', 'Datan esikäsittely'], 'Neuroverkon arkkitehtuuri': [], 'Datan esikäsittely': []}}\n\nResults:\n--------------------\n\nThemes:\n\n• Koneoppimismallit\n  Confidence: 0.95\n  Description: Koneoppimismallit koulutetaan suurilla datajoukolla tunnistamaan kaavoja, mikä on keskeinen osa koneoppimisen prosessia.\n  Keywords: koneoppiminen, datajoukko, kaavat\n\n• Neuroverkon arkkitehtuuri\n  Confidence: 0.90\n  Description: Neuroverkon arkkitehtuuri koostuu useista kerroksista, jotka ovat tärkeitä piirteiden erottamisessa ja analysoinnissa.\n  Keywords: neuroverkko, arkkitehtuuri, kerrokset\n\n• Datan esikäsittely\n  Confidence: 0.85\n  Description: Datan esikäsittely ja piirteiden suunnittelu ovat keskeisiä vaiheita koneoppimismallien tehokkuuden varmistamiseksi.\n  Keywords: esikäsittely, piirteet, suunnittelu\n\nTesting Category Analysis\n==================================================\n\nInput text:\nKoneoppimismalleja koulutetaan suurilla datajoukolla tunnistamaan kaavoja. \n                     Neuroverkon arkkitehtuuri sisältää useita kerroksia piirteiden erottamiseen. \n                     Data...\n\nProcessing response: {'categories': [{'category': 'Machine Learning', 'confidence': 0.95, 'explanation': 'The text discusses concepts related to machine learning, specifically focusing on training models with large datasets and the architecture of neural networks.', 'evidence': [{'text': 'Koneoppimismalleja koulutetaan suurilla datajoukolla tunnistamaan kaavoja.', 'relevance': 0.9, 'matched_keywords': ['koneoppimismalleja', 'datajoukolla', 'tunnistamaan'], 'context': 'The sentence explicitly mentions machine learning models being trained on large datasets.'}, {'text': 'Neuroverkon arkkitehtuuri sisältää useita kerroksia piirteiden erottamiseen.', 'relevance': 0.9, 'matched_keywords': ['neuroverkon', 'arkkitehtuuri', 'kerroksia'], 'context': 'This part of the text refers to the architecture of neural networks, which is a fundamental concept in machine learning.'}, {'text': 'Datan esikäsittely ja piirteiden suunnittelu ovat keskeisiä vaiheita.', 'relevance': 0.85, 'matched_keywords': ['datan esikäsittely', 'piirteiden suunnittelu'], 'context': 'The mention of data preprocessing and feature design highlights important steps in the machine learning process.'}], 'themes': ['neural networks', 'data preprocessing', 'feature engineering']}], 'relationships': {'Machine Learning': ['Artificial Intelligence', 'Data Science']}}\n\nProcessing category: {'category': 'Machine Learning', 'confidence': 0.95, 'explanation': 'The text discusses concepts related to machine learning, specifically focusing on training models with large datasets and the architecture of neural networks.', 'evidence': [{'text': 'Koneoppimismalleja koulutetaan suurilla datajoukolla tunnistamaan kaavoja.', 'relevance': 0.9, 'matched_keywords': ['koneoppimismalleja', 'datajoukolla', 'tunnistamaan'], 'context': 'The sentence explicitly mentions machine learning models being trained on large datasets.'}, {'text': 'Neuroverkon arkkitehtuuri sisältää useita kerroksia piirteiden erottamiseen.', 'relevance': 0.9, 'matched_keywords': ['neuroverkon', 'arkkitehtuuri', 'kerroksia'], 'context': 'This part of the text refers to the architecture of neural networks, which is a fundamental concept in machine learning.'}, {'text': 'Datan esikäsittely ja piirteiden suunnittelu ovat keskeisiä vaiheita.', 'relevance': 0.85, 'matched_keywords': ['datan esikäsittely', 'piirteiden suunnittelu'], 'context': 'The mention of data preprocessing and feature design highlights important steps in the machine learning process.'}], 'themes': ['neural networks', 'data preprocessing', 'feature engineering']}\nCreated category: name='Machine Learning' confidence=0.95 description='The text discusses concepts related to machine learning, specifically focusing on training models with large datasets and the architecture of neural networks.' evidence=[Evidence(text='Koneoppimismalleja koulutetaan suurilla datajoukolla tunnistamaan kaavoja.', relevance=0.9), Evidence(text='Neuroverkon arkkitehtuuri sisältää useita kerroksia piirteiden erottamiseen.', relevance=0.9), Evidence(text='Datan esikäsittely ja piirteiden suunnittelu ovat keskeisiä vaiheita.', relevance=0.85)] themes=['neural networks', 'data preprocessing', 'feature engineering']\n\nFinal categories: [CategoryMatch(name='Machine Learning', confidence=0.95, description='The text discusses concepts related to machine learning, specifically focusing on training models with large datasets and the architecture of neural networks.', evidence=[Evidence(text='Koneoppimismalleja koulutetaan suurilla datajoukolla tunnistamaan kaavoja.', relevance=0.9), Evidence(text='Neuroverkon arkkitehtuuri sisältää useita kerroksia piirteiden erottamiseen.', relevance=0.9), Evidence(text='Datan esikäsittely ja piirteiden suunnittelu ovat keskeisiä vaiheita.', relevance=0.85)], themes=['neural networks', 'data preprocessing', 'feature engineering'])]\n\nResults:\n--------------------\n\nCategories:\n\n• Machine Learning\n  Confidence: 0.95\n  Description: The text discusses concepts related to machine learning, specifically focusing on training models with large datasets and the architecture of neural networks.\n\n  Evidence:\n  - Koneoppimismalleja koulutetaan suurilla datajoukolla tunnistamaan kaavoja. (relevance: 0.90)\n  - Neuroverkon arkkitehtuuri sisältää useita kerroksia piirteiden erottamiseen. (relevance: 0.90)\n  - Datan esikäsittely ja piirteiden suunnittelu ovat keskeisiä vaiheita. (relevance: 0.85)\n\nTesting FI Business Content:\n\nTesting Keyword Analysis\n==================================================\n\nInput text:\nQ3 taloudelliset tulokset osoittavat 15% liikevaihdon kasvun ja parantuneet katteet. \n                    Asiakashankinnan kustannukset laskivat ja asiakaspysyvyys parani. \n                    Markkin...\n\nResults:\n--------------------\n\nKeywords:\n• liikevaihdon kasvu   (0.95)\n  Domain: business\n• asiakashankinnan kustannukset (0.90)\n  Domain: business\n• asiakaspysyvyys      (0.85)\n  Domain: business\n• markkinalaajennusstrategia (0.92)\n  Domain: business\n• nousevat teknologiasektorit (0.88)\n  Domain: technical\n\nCompound Words:\nliikevaihdon kasvu, asiakashankinnan kustannukset, asiakaspysyvyys, markkinalaajennusstrategia, nousevat teknologiasektorit\n\nTesting Theme Analysis\n==================================================\n\nInput text:\nQ3 taloudelliset tulokset osoittavat 15% liikevaihdon kasvun ja parantuneet katteet. \n                    Asiakashankinnan kustannukset laskivat ja asiakaspysyvyys parani. \n                    Markkin...\n\nRaw LLM response: {'themes': [{'name': 'taloudellinen kasvu', 'description': 'Q3 taloudelliset tulokset osoittavat merkittävää liikevaihdon kasvua ja parantuneita katteita, mikä viittaa yrityksen taloudelliseen menestykseen.', 'confidence': 0.95, 'keywords': ['liikevaihto', 'kasvu', 'katteet'], 'domain': 'general content analysis'}, {'name': 'asiakashankinta ja pysyvyys', 'description': 'Asiakashankinnan kustannusten lasku ja asiakaspysyvyyden parantuminen osoittavat tehokkuuden lisääntymistä asiakassuhteissa.', 'confidence': 0.9, 'keywords': ['asiakashankinta', 'kustannukset', 'asiakaspysyvyys'], 'domain': 'general content analysis', 'parent_theme': 'taloudellinen kasvu'}, {'name': 'markkinalaajennusstrategia', 'description': 'Markkinalaajennusstrategia keskittyy nouseviin teknologiasektoreihin, mikä voi avata uusia mahdollisuuksia ja kasvupotentiaalia.', 'confidence': 0.85, 'keywords': ['markkinalaajennus', 'teknologiasektorit', 'strategia'], 'domain': 'general content analysis'}], 'evidence': {'taloudellinen kasvu': [{'text': 'Q3 taloudelliset tulokset osoittavat 15% liikevaihdon kasvun ja parantuneet katteet.', 'relevance': 0.9, 'keywords': ['liikevaihto', 'kasvu', 'katteet']}], 'asiakashankinta ja pysyvyys': [{'text': 'Asiakashankinnan kustannukset laskivat ja asiakaspysyvyys parani.', 'relevance': 0.9, 'keywords': ['asiakashankinta', 'kustannukset', 'asiakaspysyvyys']}], 'markkinalaajennusstrategia': [{'text': 'Markkinalaajennusstrategia keskittyy nouseviin teknologiasektoreihin.', 'relevance': 0.85, 'keywords': ['markkinalaajennus', 'teknologiasektorit', 'strategia']}]}, 'relationships': {'taloudellinen kasvu': ['asiakashankinta ja pysyvyys', 'markkinalaajennusstrategia'], 'asiakashankinta ja pysyvyys': ['taloudellinen kasvu'], 'markkinalaajennusstrategia': ['taloudellinen kasvu']}}\n\nProcessed LLM response: {'themes': [{'name': 'taloudellinen kasvu', 'description': 'Q3 taloudelliset tulokset osoittavat merkittävää liikevaihdon kasvua ja parantuneita katteita, mikä viittaa yrityksen taloudelliseen menestykseen.', 'confidence': 0.95, 'keywords': ['liikevaihto', 'kasvu', 'katteet'], 'domain': 'general content analysis'}, {'name': 'asiakashankinta ja pysyvyys', 'description': 'Asiakashankinnan kustannusten lasku ja asiakaspysyvyyden parantuminen osoittavat tehokkuuden lisääntymistä asiakassuhteissa.', 'confidence': 0.9, 'keywords': ['asiakashankinta', 'kustannukset', 'asiakaspysyvyys'], 'domain': 'general content analysis', 'parent_theme': 'taloudellinen kasvu'}, {'name': 'markkinalaajennusstrategia', 'description': 'Markkinalaajennusstrategia keskittyy nouseviin teknologiasektoreihin, mikä voi avata uusia mahdollisuuksia ja kasvupotentiaalia.', 'confidence': 0.85, 'keywords': ['markkinalaajennus', 'teknologiasektorit', 'strategia'], 'domain': 'general content analysis'}], 'evidence': {'taloudellinen kasvu': [{'text': 'Q3 taloudelliset tulokset osoittavat 15% liikevaihdon kasvun ja parantuneet katteet.', 'relevance': 0.9, 'keywords': ['liikevaihto', 'kasvu', 'katteet']}], 'asiakashankinta ja pysyvyys': [{'text': 'Asiakashankinnan kustannukset laskivat ja asiakaspysyvyys parani.', 'relevance': 0.9, 'keywords': ['asiakashankinta', 'kustannukset', 'asiakaspysyvyys']}], 'markkinalaajennusstrategia': [{'text': 'Markkinalaajennusstrategia keskittyy nouseviin teknologiasektoreihin.', 'relevance': 0.85, 'keywords': ['markkinalaajennus', 'teknologiasektorit', 'strategia']}]}, 'relationships': {'taloudellinen kasvu': ['asiakashankinta ja pysyvyys', 'markkinalaajennusstrategia'], 'asiakashankinta ja pysyvyys': ['taloudellinen kasvu'], 'markkinalaajennusstrategia': ['taloudellinen kasvu']}}\n\nResults:\n--------------------\n\nThemes:\n\n• taloudellinen kasvu\n  Confidence: 0.95\n  Description: Q3 taloudelliset tulokset osoittavat merkittävää liikevaihdon kasvua ja parantuneita katteita, mikä viittaa yrityksen taloudelliseen menestykseen.\n  Keywords: liikevaihto, kasvu, katteet\n\n• asiakashankinta ja pysyvyys\n  Confidence: 0.90\n  Description: Asiakashankinnan kustannusten lasku ja asiakaspysyvyyden parantuminen osoittavat tehokkuuden lisääntymistä asiakassuhteissa.\n  Keywords: asiakashankinta, kustannukset, asiakaspysyvyys\n\n• markkinalaajennusstrategia\n  Confidence: 0.85\n  Description: Markkinalaajennusstrategia keskittyy nouseviin teknologiasektoreihin, mikä voi avata uusia mahdollisuuksia ja kasvupotentiaalia.\n  Keywords: markkinalaajennus, teknologiasektorit, strategia\n\nTesting Category Analysis\n==================================================\n\nInput text:\nQ3 taloudelliset tulokset osoittavat 15% liikevaihdon kasvun ja parantuneet katteet. \n                    Asiakashankinnan kustannukset laskivat ja asiakaspysyvyys parani. \n                    Markkin...\n\nProcessing response: {'categories': [{'category': 'Financial Performance', 'confidence': 0.9, 'explanation': 'The text discusses financial results, specifically revenue growth and improved margins, which are key indicators of financial performance.', 'evidence': [{'text': 'Q3 taloudelliset tulokset osoittavat 15% liikevaihdon kasvun ja parantuneet katteet.', 'relevance': 0.95, 'matched_keywords': ['liikevaihdon kasvu', 'taloudelliset tulokset'], 'context': 'The text provides specific financial metrics indicating performance.'}], 'themes': ['revenue growth', 'profit margins']}, {'category': 'Customer Acquisition', 'confidence': 0.85, 'explanation': 'The text mentions a decrease in customer acquisition costs and an improvement in customer retention, which are critical aspects of customer acquisition strategies.', 'evidence': [{'text': 'Asiakashankinnan kustannukset laskivat ja asiakaspysyvyys parani.', 'relevance': 0.9, 'matched_keywords': ['asiakashankinnan kustannukset', 'asiakaspysyvyys'], 'context': 'The text highlights changes in customer acquisition costs and retention rates.'}], 'themes': ['customer retention', 'cost reduction']}, {'category': 'Market Strategy', 'confidence': 0.8, 'explanation': 'The text refers to a market expansion strategy focusing on emerging technology sectors, indicating a strategic approach to market growth.', 'evidence': [{'text': 'Markkinalaajennusstrategia keskittyy nouseviin teknologiasektoreihin.', 'relevance': 0.85, 'matched_keywords': ['markkinalaajennusstrategia', 'teknologiasektoreihin'], 'context': 'The text outlines a specific strategy for market expansion.'}], 'themes': ['market expansion', 'technology sectors']}], 'relationships': {'Financial Performance': ['Customer Acquisition', 'Market Strategy'], 'Customer Acquisition': ['Financial Performance', 'Market Strategy'], 'Market Strategy': ['Financial Performance', 'Customer Acquisition']}}\n\nProcessing category: {'category': 'Financial Performance', 'confidence': 0.9, 'explanation': 'The text discusses financial results, specifically revenue growth and improved margins, which are key indicators of financial performance.', 'evidence': [{'text': 'Q3 taloudelliset tulokset osoittavat 15% liikevaihdon kasvun ja parantuneet katteet.', 'relevance': 0.95, 'matched_keywords': ['liikevaihdon kasvu', 'taloudelliset tulokset'], 'context': 'The text provides specific financial metrics indicating performance.'}], 'themes': ['revenue growth', 'profit margins']}\nCreated category: name='Financial Performance' confidence=0.9 description='The text discusses financial results, specifically revenue growth and improved margins, which are key indicators of financial performance.' evidence=[Evidence(text='Q3 taloudelliset tulokset osoittavat 15% liikevaihdon kasvun ja parantuneet katteet.', relevance=0.95)] themes=['revenue growth', 'profit margins']\n\nProcessing category: {'category': 'Customer Acquisition', 'confidence': 0.85, 'explanation': 'The text mentions a decrease in customer acquisition costs and an improvement in customer retention, which are critical aspects of customer acquisition strategies.', 'evidence': [{'text': 'Asiakashankinnan kustannukset laskivat ja asiakaspysyvyys parani.', 'relevance': 0.9, 'matched_keywords': ['asiakashankinnan kustannukset', 'asiakaspysyvyys'], 'context': 'The text highlights changes in customer acquisition costs and retention rates.'}], 'themes': ['customer retention', 'cost reduction']}\nCreated category: name='Customer Acquisition' confidence=0.85 description='The text mentions a decrease in customer acquisition costs and an improvement in customer retention, which are critical aspects of customer acquisition strategies.' evidence=[Evidence(text='Asiakashankinnan kustannukset laskivat ja asiakaspysyvyys parani.', relevance=0.9)] themes=['customer retention', 'cost reduction']\n\nProcessing category: {'category': 'Market Strategy', 'confidence': 0.8, 'explanation': 'The text refers to a market expansion strategy focusing on emerging technology sectors, indicating a strategic approach to market growth.', 'evidence': [{'text': 'Markkinalaajennusstrategia keskittyy nouseviin teknologiasektoreihin.', 'relevance': 0.85, 'matched_keywords': ['markkinalaajennusstrategia', 'teknologiasektoreihin'], 'context': 'The text outlines a specific strategy for market expansion.'}], 'themes': ['market expansion', 'technology sectors']}\nCreated category: name='Market Strategy' confidence=0.8 description='The text refers to a market expansion strategy focusing on emerging technology sectors, indicating a strategic approach to market growth.' evidence=[Evidence(text='Markkinalaajennusstrategia keskittyy nouseviin teknologiasektoreihin.', relevance=0.85)] themes=['market expansion', 'technology sectors']\n\nFinal categories: [CategoryMatch(name='Financial Performance', confidence=0.9, description='The text discusses financial results, specifically revenue growth and improved margins, which are key indicators of financial performance.', evidence=[Evidence(text='Q3 taloudelliset tulokset osoittavat 15% liikevaihdon kasvun ja parantuneet katteet.', relevance=0.95)], themes=['revenue growth', 'profit margins']), CategoryMatch(name='Customer Acquisition', confidence=0.85, description='The text mentions a decrease in customer acquisition costs and an improvement in customer retention, which are critical aspects of customer acquisition strategies.', evidence=[Evidence(text='Asiakashankinnan kustannukset laskivat ja asiakaspysyvyys parani.', relevance=0.9)], themes=['customer retention', 'cost reduction']), CategoryMatch(name='Market Strategy', confidence=0.8, description='The text refers to a market expansion strategy focusing on emerging technology sectors, indicating a strategic approach to market growth.', evidence=[Evidence(text='Markkinalaajennusstrategia keskittyy nouseviin teknologiasektoreihin.', relevance=0.85)], themes=['market expansion', 'technology sectors'])]\n\nResults:\n--------------------\n\nCategories:\n\n• Financial Performance\n  Confidence: 0.90\n  Description: The text discusses financial results, specifically revenue growth and improved margins, which are key indicators of financial performance.\n\n  Evidence:\n  - Q3 taloudelliset tulokset osoittavat 15% liikevaihdon kasvun ja parantuneet katteet. (relevance: 0.95)\n\n• Customer Acquisition\n  Confidence: 0.85\n  Description: The text mentions a decrease in customer acquisition costs and an improvement in customer retention, which are critical aspects of customer acquisition strategies.\n\n  Evidence:\n  - Asiakashankinnan kustannukset laskivat ja asiakaspysyvyys parani. (relevance: 0.90)\n\n• Market Strategy\n  Confidence: 0.80\n  Description: The text refers to a market expansion strategy focusing on emerging technology sectors, indicating a strategic approach to market growth.\n\n  Evidence:\n  - Markkinalaajennusstrategia keskittyy nouseviin teknologiasektoreihin. (relevance: 0.85)\n"
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": "INFO: HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\nINFO: HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\nINFO: HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\nINFO: HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\nINFO: HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
        }
      ],
      "execution_count": 10,
      "metadata": {
        "gather": {
          "logged": 1733580393556
        }
      }
    }
  ],
  "metadata": {
    "kernelspec": {
      "name": "semantic-analyzer",
      "language": "python",
      "display_name": "Python (semantic-analyzer)"
    },
    "language_info": {
      "name": "python",
      "version": "3.9.21",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "microsoft": {
      "ms_spell_check": {
        "ms_spell_check_language": "en"
      }
    },
    "kernel_info": {
      "name": "semantic-analyzer"
    },
    "nteract": {
      "version": "nteract-front-end@1.0.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}