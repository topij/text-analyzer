{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required modules\n",
    "import sys\n",
    "from pathlib import Path\n",
    "from typing import List, Dict, Any, Tuple, Union\n",
    "import logging\n",
    "import asyncio\n",
    "\n",
    "# Add project root to Python path if needed\n",
    "project_root = str(Path().resolve().parent)\n",
    "if project_root not in sys.path:\n",
    "    sys.path.append(project_root)\n",
    "\n",
    "# Import necessary components\n",
    "from src.nb_helpers.environment import setup_notebook_env, verify_environment\n",
    "from src.semantic_analyzer import SemanticAnalyzer\n",
    "import FileUtils\n",
    "from src.core.language_processing import create_text_processor\n",
    "from src.core.llm.factory import create_llm\n",
    "from src.loaders.parameter_handler import ParameterHandler\n",
    "from src.analyzers.keyword_analyzer import KeywordAnalyzer\n",
    "from src.analyzers.theme_analyzer import ThemeAnalyzer\n",
    "from src.analyzers.category_analyzer import CategoryAnalyzer\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# In analyzer_demo_local_nb.ipynb and azure_notebook.ipynb\n",
    "from src.core.config import AnalyzerConfig\n",
    "# from src.core.llm.factory import create_llm\n",
    "\n",
    "# Setup\n",
    "# config = AnalyzerConfig()\n",
    "# llm = create_llm(config=config)\n",
    "# analyzer = SemanticAnalyzer(llm=llm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5.0\n"
     ]
    }
   ],
   "source": [
    "print(FileUtils.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-12-05 12:29:45,035 - FileUtils.core.file_utils - INFO - Project root: /home/topi/data-science/repos/semantic-text-analyzer\n",
      "2024-12-05 12:29:45,224 - FileUtils.core.file_utils - INFO - FileUtils initialized with local storage\n",
      "2024-12-05 12:29:45,238 - FileUtils.core.file_utils - INFO - Project root: /home/topi/data-science/repos/semantic-text-analyzer\n",
      "2024-12-05 12:29:45,239 - FileUtils.core.file_utils - INFO - FileUtils initialized with local storage\n",
      "Environment Check Results:\n",
      "==================================================\n",
      "\n",
      "Basic Setup:\n",
      "-----------\n",
      "✓ Project root in path\n",
      "✓ FileUtils initialized\n",
      "✓ .env file loaded\n",
      "\n",
      "Environment Variables:\n",
      "---------------------\n",
      "✓ OPENAI_API_KEY set\n",
      "✓ ANTHROPIC_API_KEY set\n",
      "\n",
      "Project Structure:\n",
      "-----------------\n",
      "✓ Raw data exists\n",
      "✓ Processed data exists\n",
      "✓ Configuration exists\n",
      "✓ Main config.yaml exists\n",
      "\n",
      "==================================================\n",
      "Environment Status: Ready ✓\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Set up environment and logging\n",
    "setup_notebook_env(log_level=\"DEBUG\")\n",
    "verify_environment()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test data to use\n",
    "test_texts = {\n",
    "    \"en\": {\n",
    "        \"technical\": \"\"\"Machine learning models are trained using large datasets to recognize patterns. \n",
    "                     The neural network architecture includes multiple layers for feature extraction. \n",
    "                     Data preprocessing and feature engineering are crucial steps.\"\"\",\n",
    "        \"business\": \"\"\"Q3 financial results show 15% revenue growth and improved profit margins. \n",
    "                    Customer acquisition costs decreased while retention rates increased. \n",
    "                    Market expansion strategy focuses on emerging technology sectors.\"\"\"\n",
    "    },\n",
    "    \"fi\": {\n",
    "        \"technical\": \"\"\"Koneoppimismalleja koulutetaan suurilla datajoukolla tunnistamaan kaavoja. \n",
    "                     Neuroverkon arkkitehtuuri sisältää useita kerroksia piirteiden erottamiseen. \n",
    "                     Datan esikäsittely ja piirteiden suunnittelu ovat keskeisiä vaiheita.\"\"\",\n",
    "        \"business\": \"\"\"Q3 taloudelliset tulokset osoittavat 15% liikevaihdon kasvun ja parantuneet katteet. \n",
    "                    Asiakashankinnan kustannukset laskivat ja asiakaspysyvyys parani. \n",
    "                    Markkinalaajennusstrategia keskittyy nouseviin teknologiasektoreihin.\"\"\"\n",
    "    }\n",
    "}\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-12-05 12:29:46,766 - FileUtils.core.file_utils - INFO - Project root: /home/topi/data-science/repos/semantic-text-analyzer\n",
      "2024-12-05 12:29:46,768 - FileUtils.core.file_utils - INFO - FileUtils initialized with local storage\n",
      "2024-12-05 12:29:46,768 - FileUtils.core.file_utils - INFO - FileUtils initialized with local storage\n"
     ]
    }
   ],
   "source": [
    "     # llm = create_llm()\n",
    "config = AnalyzerConfig()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "async def test_individual_analyzer(\n",
    "    analyzer: Union[KeywordAnalyzer, ThemeAnalyzer, CategoryAnalyzer], \n",
    "    text: str, \n",
    "    analyzer_type: str\n",
    "):\n",
    "    \"\"\"Test individual analyzer component.\"\"\"\n",
    "    print(f\"\\nTesting {analyzer_type} Analysis\")\n",
    "    print(\"=\" * 50)\n",
    "    print(\"\\nInput text:\")\n",
    "    print(text[:200] + \"...\" if len(text) > 200 else text)\n",
    "    \n",
    "    try:\n",
    "        results = await analyzer.analyze(text)\n",
    "        \n",
    "        print(\"\\nResults:\")\n",
    "        print(\"-\" * 20)\n",
    "        \n",
    "        if isinstance(analyzer, KeywordAnalyzer):\n",
    "            if results.keywords:\n",
    "                print(\"\\nKeywords:\")\n",
    "                for kw in results.keywords[:10]:  # Show top 10\n",
    "                    print(f\"• {kw.keyword:<20} ({kw.score:.2f})\")\n",
    "                    if kw.domain:\n",
    "                        print(f\"  Domain: {kw.domain}\")\n",
    "                \n",
    "                if results.compound_words:\n",
    "                    print(\"\\nCompound Words:\")\n",
    "                    print(\", \".join(results.compound_words))\n",
    "                    \n",
    "                if results.domain_keywords:\n",
    "                    print(\"\\nKeywords by Domain:\")\n",
    "                    for domain, kws in results.domain_keywords.items():\n",
    "                        print(f\"\\n{domain}:\")\n",
    "                        print(\", \".join(kws))\n",
    "                        \n",
    "        elif isinstance(analyzer, ThemeAnalyzer):\n",
    "            if results.themes:\n",
    "                print(\"\\nThemes:\")\n",
    "                for theme in results.themes:\n",
    "                    print(f\"\\n• {theme.name}\")\n",
    "                    print(f\"  Confidence: {theme.confidence:.2f}\")\n",
    "                    print(f\"  Description: {theme.description}\")\n",
    "                    if theme.keywords:\n",
    "                        print(f\"  Keywords: {', '.join(theme.keywords)}\")\n",
    "                \n",
    "                if results.theme_hierarchy:\n",
    "                    print(\"\\nTheme Hierarchy:\")\n",
    "                    for parent, children in results.theme_hierarchy.items():\n",
    "                        print(f\"{parent} -> {', '.join(children)}\")\n",
    "                        \n",
    "        elif isinstance(analyzer, CategoryAnalyzer):\n",
    "            if results.categories:\n",
    "                print(\"\\nCategories:\")\n",
    "                for cat in results.categories:\n",
    "                    print(f\"\\n• {cat.name}\")\n",
    "                    print(f\"  Confidence: {cat.confidence:.2f}\")\n",
    "                    if cat.description:\n",
    "                        print(f\"  Description: {cat.description}\")\n",
    "                    if cat.evidence:\n",
    "                        print(\"\\n  Evidence:\")\n",
    "                        for ev in cat.evidence:\n",
    "                            print(f\"  - {ev.text} (relevance: {ev.relevance:.2f})\")\n",
    "                            \n",
    "        if hasattr(results, 'error') and results.error:\n",
    "            print(f\"\\nErrors occurred: {results.error}\")\n",
    "            \n",
    "        return results\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"\\nError in analysis: {e}\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example 1: Test individual keyword analyzer\n",
    "async def test_keyword_analyzer():\n",
    "    \"\"\"Test keyword analyzer with different languages.\"\"\"\n",
    "    print(\"Testing Keyword Analyzer\")\n",
    "    print(\"=\" * 50)\n",
    "    \n",
    "    # Initialize components\n",
    "    parameter_handler = ParameterHandler(\"parameters_fi.xlsx\")\n",
    "    # llm = create_llm()\n",
    "    # config = AnalyzerConfig()\n",
    "    llm = create_llm(config=config)\n",
    "    # analyzer = SemanticAnalyzer(llm=llm)\n",
    "    \n",
    "    # Test English\n",
    "    print(\"\\nTesting English Technical Content:\")\n",
    "    en_processor = create_text_processor(language=\"en\")\n",
    "    keyword_analyzer_en = KeywordAnalyzer(\n",
    "        llm=llm,\n",
    "        config=parameter_handler.parameters.general.model_dump(),\n",
    "        language_processor=en_processor\n",
    "    )\n",
    "    await test_individual_analyzer(keyword_analyzer_en, test_texts[\"en\"][\"technical\"], \"Keyword\")\n",
    "    \n",
    "    # Test Finnish\n",
    "    print(\"\\nTesting Finnish Technical Content:\")\n",
    "    fi_processor = create_text_processor(language=\"fi\")\n",
    "    keyword_analyzer_fi = KeywordAnalyzer(\n",
    "        llm=llm,\n",
    "        config=parameter_handler.parameters.general.model_dump(),\n",
    "        language_processor=fi_processor\n",
    "    )\n",
    "    await test_individual_analyzer(keyword_analyzer_fi, test_texts[\"fi\"][\"technical\"], \"Keyword\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example 2: Test all components\n",
    "async def test_components_for_language(language: str):\n",
    "    \"\"\"Test all components for a specific language.\"\"\"\n",
    "    print(f\"\\nTesting All Components for {language.upper()}\")\n",
    "    print(\"=\" * 50)\n",
    "    \n",
    "    # Initialize components\n",
    "    parameter_handler = ParameterHandler(f\"parameters_{language}.xlsx\")\n",
    "     # llm = create_llm()\n",
    "    # config = AnalyzerConfig()\n",
    "    llm = create_llm(provider='openai', config=config)\n",
    "\n",
    "    language_processor = create_text_processor(language=language)\n",
    "    \n",
    "    # Create analyzers\n",
    "    keyword_analyzer = KeywordAnalyzer(\n",
    "        llm=llm,\n",
    "        config=parameter_handler.parameters.general.model_dump(),\n",
    "        language_processor=language_processor\n",
    "    )\n",
    "    \n",
    "    theme_analyzer = ThemeAnalyzer(\n",
    "        llm=llm,\n",
    "        config=parameter_handler.parameters.general.model_dump(),\n",
    "        language_processor=language_processor\n",
    "    )\n",
    "    \n",
    "    category_analyzer = CategoryAnalyzer(\n",
    "        categories=parameter_handler.parameters.categories,\n",
    "        llm=llm,\n",
    "        config=parameter_handler.parameters.general.model_dump(),\n",
    "        language_processor=language_processor\n",
    "    )\n",
    "    \n",
    "    # Test technical content\n",
    "    print(f\"\\nTesting {language.upper()} Technical Content:\")\n",
    "    await test_individual_analyzer(keyword_analyzer, test_texts[language][\"technical\"], \"Keyword\")\n",
    "    await test_individual_analyzer(theme_analyzer, test_texts[language][\"technical\"], \"Theme\")\n",
    "    await test_individual_analyzer(category_analyzer, test_texts[language][\"technical\"], \"Category\")\n",
    "    \n",
    "    # Test business content\n",
    "    print(f\"\\nTesting {language.upper()} Business Content:\")\n",
    "    await test_individual_analyzer(keyword_analyzer, test_texts[language][\"business\"], \"Keyword\")\n",
    "    await test_individual_analyzer(theme_analyzer, test_texts[language][\"business\"], \"Theme\")\n",
    "    await test_individual_analyzer(category_analyzer, test_texts[language][\"business\"], \"Category\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example 3: Quick test of full pipeline\n",
    "async def test_pipeline():\n",
    "    \"\"\"Test full pipeline with both languages.\"\"\"\n",
    "    print(\"Testing Full Pipeline\")\n",
    "    print(\"=\" * 50)\n",
    "    \n",
    "    llm = create_llm(provider='openai', config=config)\n",
    "    # analyzer = SemanticAnalyzer(llm=llm)\n",
    "    # Test English pipeline\n",
    "    print(\"\\nEnglish Pipeline:\")\n",
    "    en_analyzer = SemanticAnalyzer(llm=llm, parameter_file=\"parameters_en.xlsx\")\n",
    "    result = await en_analyzer.analyze(test_texts[\"en\"][\"technical\"])\n",
    "    print(f\"Success: {result.success}\")\n",
    "    print(f\"Keywords found: {len(result.keywords.keywords)}\")\n",
    "    print(f\"Themes found: {len(result.themes.themes)}\")\n",
    "    print(f\"Categories found: {len(result.categories.matches)}\")\n",
    "    \n",
    "    # Test Finnish pipeline\n",
    "    print(\"\\nFinnish Pipeline:\")\n",
    "    fi_analyzer = SemanticAnalyzer(parameter_file=\"parameters_fi.xlsx\")\n",
    "    result = await fi_analyzer.analyze(test_texts[\"fi\"][\"technical\"])\n",
    "    print(f\"Success: {result.success}\")\n",
    "    print(f\"Keywords found: {len(result.keywords.keywords)}\")\n",
    "    print(f\"Themes found: {len(result.themes.themes)}\")\n",
    "    print(f\"Categories found: {len(result.categories.matches)}\")\n",
    "\n",
    "# Run the tests\n",
    "async def run_all_tests():\n",
    "    \"\"\"Run all tests.\"\"\"\n",
    "    # Test individual component\n",
    "    await test_keyword_analyzer()\n",
    "    \n",
    "    # Test all components by language\n",
    "    await test_components_for_language(\"en\")\n",
    "    await test_components_for_language(\"fi\")\n",
    "    \n",
    "    # Test full pipeline\n",
    "    await test_pipeline()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Testing All Components for FI\n",
      "==================================================\n",
      "2024-12-05 12:29:48,576 - FileUtils.core.file_utils - INFO - Project root: /home/topi/data-science/repos/semantic-text-analyzer\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO: Project root: /home/topi/data-science/repos/semantic-text-analyzer\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-12-05 12:29:48,578 - FileUtils.core.file_utils - INFO - FileUtils initialized with local storage\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO: FileUtils initialized with local storage\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-12-05 12:29:49,000 - FileUtils.core.file_utils - INFO - Project root: /home/topi/data-science/repos/semantic-text-analyzer\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO: Project root: /home/topi/data-science/repos/semantic-text-analyzer\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-12-05 12:29:49,003 - FileUtils.core.file_utils - INFO - FileUtils initialized with local storage\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO: FileUtils initialized with local storage\n",
      "INFO: Loaded 747 stopwords from /home/topi/data-science/repos/semantic-text-analyzer/data/configurations/stop_words/fi.txt\n",
      "INFO: Successfully initialized Voikko with path: /usr/lib/voikko\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Testing FI Technical Content:\n",
      "\n",
      "Testing Keyword Analysis\n",
      "==================================================\n",
      "\n",
      "Input text:\n",
      "Koneoppimismalleja koulutetaan suurilla datajoukolla tunnistamaan kaavoja. \n",
      "                     Neuroverkon arkkitehtuuri sisältää useita kerroksia piirteiden erottamiseen. \n",
      "                     Data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO: HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Results:\n",
      "--------------------\n",
      "\n",
      "Keywords:\n",
      "• koneoppimismalli     (0.95)\n",
      "  Domain: technical\n",
      "• datajoukko           (0.95)\n",
      "  Domain: technical\n",
      "• neuroverkon arkkitehtuuri (0.95)\n",
      "  Domain: technical\n",
      "• datan esikäsittely   (0.95)\n",
      "  Domain: technical\n",
      "• piirteiden suunnittelu (0.95)\n",
      "  Domain: technical\n",
      "\n",
      "Compound Words:\n",
      "koneoppimismalli, datajoukko, neuroverkon arkkitehtuuri, datan esikäsittely, piirteiden suunnittelu\n",
      "\n",
      "Testing Theme Analysis\n",
      "==================================================\n",
      "\n",
      "Input text:\n",
      "Koneoppimismalleja koulutetaan suurilla datajoukolla tunnistamaan kaavoja. \n",
      "                     Neuroverkon arkkitehtuuri sisältää useita kerroksia piirteiden erottamiseen. \n",
      "                     Data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO: HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Raw LLM response: {'themes': [{'name': 'Koneoppimismallien koulutus', 'description': 'Koneoppimismallien koulutus suurilla datajoukoilla on keskeinen prosessi, jossa malleja opetetaan tunnistamaan kaavoja datasta.', 'confidence': 0.95, 'keywords': ['koneoppimismalli', 'datajoukko', 'kaava'], 'domain': 'general content analysis', 'parent_theme': None}, {'name': 'Neuroverkon arkkitehtuuri', 'description': 'Neuroverkon arkkitehtuuri koostuu useista kerroksista, jotka mahdollistavat piirteiden erottamisen ja oppimisen.', 'confidence': 0.9, 'keywords': ['neuroverkko', 'arkkitehtuuri', 'kerros'], 'domain': 'general content analysis', 'parent_theme': 'Koneoppimismallien koulutus'}, {'name': 'Datan esikäsittely ja piirteiden suunnittelu', 'description': 'Datan esikäsittely ja piirteiden suunnittelu ovat keskeisiä vaiheita koneoppimismallien tehokkuuden varmistamiseksi.', 'confidence': 0.85, 'keywords': ['esikäsittely', 'suunnittelu', 'piirre'], 'domain': 'general content analysis', 'parent_theme': 'Koneoppimismallien koulutus'}], 'evidence': {'Koneoppimismallien koulutus': [{'text': 'Koneoppimismalleja koulutetaan suurilla datajoukolla tunnistamaan kaavoja.', 'relevance': 0.9, 'keywords': ['koneoppimismalli', 'datajoukko', 'kaava']}], 'Neuroverkon arkkitehtuuri': [{'text': 'Neuroverkon arkkitehtuuri sisältää useita kerroksia piirteiden erottamiseen.', 'relevance': 0.9, 'keywords': ['neuroverkko', 'arkkitehtuuri', 'kerros']}], 'Datan esikäsittely ja piirteiden suunnittelu': [{'text': 'Datan esikäsittely ja piirteiden suunnittelu ovat keskeisiä vaiheita.', 'relevance': 0.85, 'keywords': ['esikäsittely', 'suunnittelu', 'piirre']}]}, 'relationships': {'Koneoppimismallien koulutus': ['Neuroverkon arkkitehtuuri', 'Datan esikäsittely ja piirteiden suunnittelu'], 'Neuroverkon arkkitehtuuri': [], 'Datan esikäsittely ja piirteiden suunnittelu': []}}\n",
      "\n",
      "Processed LLM response: {'themes': [{'name': 'Koneoppimismallien koulutus', 'description': 'Koneoppimismallien koulutus suurilla datajoukoilla on keskeinen prosessi, jossa malleja opetetaan tunnistamaan kaavoja datasta.', 'confidence': 0.95, 'keywords': ['koneoppimismalli', 'datajoukko', 'kaava'], 'domain': 'general content analysis', 'parent_theme': None}, {'name': 'Neuroverkon arkkitehtuuri', 'description': 'Neuroverkon arkkitehtuuri koostuu useista kerroksista, jotka mahdollistavat piirteiden erottamisen ja oppimisen.', 'confidence': 0.9, 'keywords': ['neuroverkko', 'arkkitehtuuri', 'kerros'], 'domain': 'general content analysis', 'parent_theme': 'Koneoppimismallien koulutus'}, {'name': 'Datan esikäsittely ja piirteiden suunnittelu', 'description': 'Datan esikäsittely ja piirteiden suunnittelu ovat keskeisiä vaiheita koneoppimismallien tehokkuuden varmistamiseksi.', 'confidence': 0.85, 'keywords': ['esikäsittely', 'suunnittelu', 'piirre'], 'domain': 'general content analysis', 'parent_theme': 'Koneoppimismallien koulutus'}], 'evidence': {'Koneoppimismallien koulutus': [{'text': 'Koneoppimismalleja koulutetaan suurilla datajoukolla tunnistamaan kaavoja.', 'relevance': 0.9, 'keywords': ['koneoppimismalli', 'datajoukko', 'kaava']}], 'Neuroverkon arkkitehtuuri': [{'text': 'Neuroverkon arkkitehtuuri sisältää useita kerroksia piirteiden erottamiseen.', 'relevance': 0.9, 'keywords': ['neuroverkko', 'arkkitehtuuri', 'kerros']}], 'Datan esikäsittely ja piirteiden suunnittelu': [{'text': 'Datan esikäsittely ja piirteiden suunnittelu ovat keskeisiä vaiheita.', 'relevance': 0.85, 'keywords': ['esikäsittely', 'suunnittelu', 'piirre']}]}, 'relationships': {'Koneoppimismallien koulutus': ['Neuroverkon arkkitehtuuri', 'Datan esikäsittely ja piirteiden suunnittelu'], 'Neuroverkon arkkitehtuuri': [], 'Datan esikäsittely ja piirteiden suunnittelu': []}}\n",
      "\n",
      "Results:\n",
      "--------------------\n",
      "\n",
      "Themes:\n",
      "\n",
      "• Koneoppimismallien koulutus\n",
      "  Confidence: 0.95\n",
      "  Description: Koneoppimismallien koulutus suurilla datajoukoilla on keskeinen prosessi, jossa malleja opetetaan tunnistamaan kaavoja datasta.\n",
      "  Keywords: koneoppimismalli, datajoukko, kaava\n",
      "\n",
      "• Neuroverkon arkkitehtuuri\n",
      "  Confidence: 0.90\n",
      "  Description: Neuroverkon arkkitehtuuri koostuu useista kerroksista, jotka mahdollistavat piirteiden erottamisen ja oppimisen.\n",
      "  Keywords: neuroverkko, arkkitehtuuri, kerros\n",
      "\n",
      "• Datan esikäsittely ja piirteiden suunnittelu\n",
      "  Confidence: 0.85\n",
      "  Description: Datan esikäsittely ja piirteiden suunnittelu ovat keskeisiä vaiheita koneoppimismallien tehokkuuden varmistamiseksi.\n",
      "  Keywords: esikäsittely, suunnittelu, piirre\n",
      "\n",
      "Testing Category Analysis\n",
      "==================================================\n",
      "\n",
      "Input text:\n",
      "Koneoppimismalleja koulutetaan suurilla datajoukolla tunnistamaan kaavoja. \n",
      "                     Neuroverkon arkkitehtuuri sisältää useita kerroksia piirteiden erottamiseen. \n",
      "                     Data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO: HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing response: {'categories': [{'category': 'Machine Learning', 'confidence': 0.95, 'explanation': 'The text discusses concepts related to machine learning, including model training, neural network architecture, and data preprocessing.', 'evidence': [{'text': 'Koneoppimismalleja koulutetaan suurilla datajoukolla tunnistamaan kaavoja.', 'relevance': 0.9, 'matched_keywords': ['koneoppimismalli', 'datajoukko', 'kaava'], 'context': 'The sentence explicitly mentions training machine learning models on large datasets to recognize patterns.'}, {'text': 'Neuroverkon arkkitehtuuri sisältää useita kerroksia piirteiden erottamiseen.', 'relevance': 0.9, 'matched_keywords': ['neuroverkon', 'arkkitehtuuri', 'kerros', 'piirteiden'], 'context': 'This sentence describes the architecture of neural networks, which is a fundamental aspect of machine learning.'}, {'text': 'Datan esikäsittely ja piirteiden suunnittelu ovat keskeisiä vaiheita.', 'relevance': 0.85, 'matched_keywords': ['datan', 'esikäsittely', 'piirteiden', 'suunnittelu', 'keskeisiä'], 'context': 'This highlights the importance of data preprocessing and feature design in the machine learning process.'}], 'themes': ['data science', 'artificial intelligence']}], 'relationships': {'Machine Learning': ['Data Science', 'Artificial Intelligence']}}\n",
      "\n",
      "Processing category: {'category': 'Machine Learning', 'confidence': 0.95, 'explanation': 'The text discusses concepts related to machine learning, including model training, neural network architecture, and data preprocessing.', 'evidence': [{'text': 'Koneoppimismalleja koulutetaan suurilla datajoukolla tunnistamaan kaavoja.', 'relevance': 0.9, 'matched_keywords': ['koneoppimismalli', 'datajoukko', 'kaava'], 'context': 'The sentence explicitly mentions training machine learning models on large datasets to recognize patterns.'}, {'text': 'Neuroverkon arkkitehtuuri sisältää useita kerroksia piirteiden erottamiseen.', 'relevance': 0.9, 'matched_keywords': ['neuroverkon', 'arkkitehtuuri', 'kerros', 'piirteiden'], 'context': 'This sentence describes the architecture of neural networks, which is a fundamental aspect of machine learning.'}, {'text': 'Datan esikäsittely ja piirteiden suunnittelu ovat keskeisiä vaiheita.', 'relevance': 0.85, 'matched_keywords': ['datan', 'esikäsittely', 'piirteiden', 'suunnittelu', 'keskeisiä'], 'context': 'This highlights the importance of data preprocessing and feature design in the machine learning process.'}], 'themes': ['data science', 'artificial intelligence']}\n",
      "Created category: name='Machine Learning' confidence=0.95 description='The text discusses concepts related to machine learning, including model training, neural network architecture, and data preprocessing.' evidence=[Evidence(text='Koneoppimismalleja koulutetaan suurilla datajoukolla tunnistamaan kaavoja.', relevance=0.9), Evidence(text='Neuroverkon arkkitehtuuri sisältää useita kerroksia piirteiden erottamiseen.', relevance=0.9), Evidence(text='Datan esikäsittely ja piirteiden suunnittelu ovat keskeisiä vaiheita.', relevance=0.85)] themes=['data science', 'artificial intelligence']\n",
      "\n",
      "Final categories: [CategoryMatch(name='Machine Learning', confidence=0.95, description='The text discusses concepts related to machine learning, including model training, neural network architecture, and data preprocessing.', evidence=[Evidence(text='Koneoppimismalleja koulutetaan suurilla datajoukolla tunnistamaan kaavoja.', relevance=0.9), Evidence(text='Neuroverkon arkkitehtuuri sisältää useita kerroksia piirteiden erottamiseen.', relevance=0.9), Evidence(text='Datan esikäsittely ja piirteiden suunnittelu ovat keskeisiä vaiheita.', relevance=0.85)], themes=['data science', 'artificial intelligence'])]\n",
      "\n",
      "Results:\n",
      "--------------------\n",
      "\n",
      "Categories:\n",
      "\n",
      "• Machine Learning\n",
      "  Confidence: 0.95\n",
      "  Description: The text discusses concepts related to machine learning, including model training, neural network architecture, and data preprocessing.\n",
      "\n",
      "  Evidence:\n",
      "  - Koneoppimismalleja koulutetaan suurilla datajoukolla tunnistamaan kaavoja. (relevance: 0.90)\n",
      "  - Neuroverkon arkkitehtuuri sisältää useita kerroksia piirteiden erottamiseen. (relevance: 0.90)\n",
      "  - Datan esikäsittely ja piirteiden suunnittelu ovat keskeisiä vaiheita. (relevance: 0.85)\n",
      "\n",
      "Testing FI Business Content:\n",
      "\n",
      "Testing Keyword Analysis\n",
      "==================================================\n",
      "\n",
      "Input text:\n",
      "Q3 taloudelliset tulokset osoittavat 15% liikevaihdon kasvun ja parantuneet katteet. \n",
      "                    Asiakashankinnan kustannukset laskivat ja asiakaspysyvyys parani. \n",
      "                    Markkin...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO: HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Results:\n",
      "--------------------\n",
      "\n",
      "Keywords:\n",
      "• taloudellinen        (0.95)\n",
      "  Domain: business\n",
      "• tulos                (0.95)\n",
      "  Domain: business\n",
      "• liikevaihto          (0.95)\n",
      "  Domain: business\n",
      "• kasvu                (0.95)\n",
      "  Domain: business\n",
      "• parantunut           (0.95)\n",
      "  Domain: business\n",
      "• asiakashankinnan kustannukset (0.90)\n",
      "  Domain: business\n",
      "• asiakaspysyvyys      (0.90)\n",
      "  Domain: business\n",
      "• markkinalaajennusstrategia (0.90)\n",
      "  Domain: business\n",
      "• nousevat teknologiasektorit (0.90)\n",
      "  Domain: technical\n",
      "\n",
      "Compound Words:\n",
      "asiakashankinnan kustannukset, markkinalaajennusstrategia, nousevat teknologiasektorit\n",
      "\n",
      "Testing Theme Analysis\n",
      "==================================================\n",
      "\n",
      "Input text:\n",
      "Q3 taloudelliset tulokset osoittavat 15% liikevaihdon kasvun ja parantuneet katteet. \n",
      "                    Asiakashankinnan kustannukset laskivat ja asiakaspysyvyys parani. \n",
      "                    Markkin...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO: HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Raw LLM response: {'themes': [{'name': 'Taloudellinen kasvu', 'description': 'Tämä teema käsittelee yrityksen taloudellista kehitystä, erityisesti liikevaihdon kasvua ja parantuneita katteita.', 'confidence': 0.95, 'keywords': ['kasvu', 'liikevaihto', 'kate', 'taloudellinen'], 'domain': 'general content analysis', 'parent_theme': None}, {'name': 'Asiakashankinta ja pysyvyys', 'description': 'Teema keskittyy asiakashankinnan kustannusten laskemiseen ja asiakaspysyvyyden parantamiseen, mikä on tärkeää liiketoiminnan kestävyyden kannalta.', 'confidence': 0.9, 'keywords': ['asiakashankinta', 'asiakaspysyvyys', 'kustannus'], 'domain': 'general content analysis', 'parent_theme': None}, {'name': 'Markkinalaajennusstrategia', 'description': 'Tämä teema käsittelee yrityksen strategiaa laajentaa markkinoitaan nouseviin teknologiasektoreihin.', 'confidence': 0.85, 'keywords': ['markkinalaajennusstrategia', 'teknologia', 'nouseva', 'sektori'], 'domain': 'general content analysis', 'parent_theme': None}], 'evidence': {'Taloudellinen kasvu': [{'text': 'Q3 taloudelliset tulokset osoittavat 15% liikevaihdon kasvun ja parantuneet katteet.', 'relevance': 0.9, 'keywords': ['kasvu', 'liikevaihto', 'kate']}], 'Asiakashankinta ja pysyvyys': [{'text': 'Asiakashankinnan kustannukset laskivat ja asiakaspysyvyys parani.', 'relevance': 0.85, 'keywords': ['asiakashankinta', 'asiakaspysyvyys', 'kustannus']}], 'Markkinalaajennusstrategia': [{'text': 'Markkinalaajennusstrategia keskittyy nouseviin teknologiasektoreihin.', 'relevance': 0.8, 'keywords': ['markkinalaajennusstrategia', 'teknologia', 'nouseva', 'sektori']}]}, 'relationships': {'Taloudellinen kasvu': ['Asiakashankinta ja pysyvyys', 'Markkinalaajennusstrategia'], 'Asiakashankinta ja pysyvyys': ['Taloudellinen kasvu'], 'Markkinalaajennusstrategia': ['Taloudellinen kasvu']}}\n",
      "\n",
      "Processed LLM response: {'themes': [{'name': 'Taloudellinen kasvu', 'description': 'Tämä teema käsittelee yrityksen taloudellista kehitystä, erityisesti liikevaihdon kasvua ja parantuneita katteita.', 'confidence': 0.95, 'keywords': ['kasvu', 'liikevaihto', 'kate', 'taloudellinen'], 'domain': 'general content analysis', 'parent_theme': None}, {'name': 'Asiakashankinta ja pysyvyys', 'description': 'Teema keskittyy asiakashankinnan kustannusten laskemiseen ja asiakaspysyvyyden parantamiseen, mikä on tärkeää liiketoiminnan kestävyyden kannalta.', 'confidence': 0.9, 'keywords': ['asiakashankinta', 'asiakaspysyvyys', 'kustannus'], 'domain': 'general content analysis', 'parent_theme': None}, {'name': 'Markkinalaajennusstrategia', 'description': 'Tämä teema käsittelee yrityksen strategiaa laajentaa markkinoitaan nouseviin teknologiasektoreihin.', 'confidence': 0.85, 'keywords': ['markkinalaajennusstrategia', 'teknologia', 'nouseva', 'sektori'], 'domain': 'general content analysis', 'parent_theme': None}], 'evidence': {'Taloudellinen kasvu': [{'text': 'Q3 taloudelliset tulokset osoittavat 15% liikevaihdon kasvun ja parantuneet katteet.', 'relevance': 0.9, 'keywords': ['kasvu', 'liikevaihto', 'kate']}], 'Asiakashankinta ja pysyvyys': [{'text': 'Asiakashankinnan kustannukset laskivat ja asiakaspysyvyys parani.', 'relevance': 0.85, 'keywords': ['asiakashankinta', 'asiakaspysyvyys', 'kustannus']}], 'Markkinalaajennusstrategia': [{'text': 'Markkinalaajennusstrategia keskittyy nouseviin teknologiasektoreihin.', 'relevance': 0.8, 'keywords': ['markkinalaajennusstrategia', 'teknologia', 'nouseva', 'sektori']}]}, 'relationships': {'Taloudellinen kasvu': ['Asiakashankinta ja pysyvyys', 'Markkinalaajennusstrategia'], 'Asiakashankinta ja pysyvyys': ['Taloudellinen kasvu'], 'Markkinalaajennusstrategia': ['Taloudellinen kasvu']}}\n",
      "\n",
      "Results:\n",
      "--------------------\n",
      "\n",
      "Themes:\n",
      "\n",
      "• Taloudellinen kasvu\n",
      "  Confidence: 0.95\n",
      "  Description: Tämä teema käsittelee yrityksen taloudellista kehitystä, erityisesti liikevaihdon kasvua ja parantuneita katteita.\n",
      "  Keywords: kasvu, liikevaihto, kate, taloudellinen\n",
      "\n",
      "• Asiakashankinta ja pysyvyys\n",
      "  Confidence: 0.90\n",
      "  Description: Teema keskittyy asiakashankinnan kustannusten laskemiseen ja asiakaspysyvyyden parantamiseen, mikä on tärkeää liiketoiminnan kestävyyden kannalta.\n",
      "  Keywords: asiakashankinta, asiakaspysyvyys, kustannus\n",
      "\n",
      "• Markkinalaajennusstrategia\n",
      "  Confidence: 0.85\n",
      "  Description: Tämä teema käsittelee yrityksen strategiaa laajentaa markkinoitaan nouseviin teknologiasektoreihin.\n",
      "  Keywords: markkinalaajennusstrategia, teknologia, nouseva, sektori\n",
      "\n",
      "Testing Category Analysis\n",
      "==================================================\n",
      "\n",
      "Input text:\n",
      "Q3 taloudelliset tulokset osoittavat 15% liikevaihdon kasvun ja parantuneet katteet. \n",
      "                    Asiakashankinnan kustannukset laskivat ja asiakaspysyvyys parani. \n",
      "                    Markkin...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO: HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing response: {'categories': [{'category': 'Financial Performance', 'confidence': 0.95, 'explanation': 'The text discusses financial results, specifically mentioning revenue growth and improved margins, which are key indicators of financial performance.', 'evidence': [{'text': 'Q3 taloudelliset tulokset osoittavat 15% liikevaihdon kasvun ja parantuneet katteet.', 'relevance': 0.9, 'matched_keywords': ['taloudelliset tulokset', 'liikevaihdon kasvu', 'parantuneet katteet'], 'context': 'The text provides specific financial metrics indicating performance.'}], 'themes': ['revenue growth', 'profit margins']}, {'category': 'Customer Acquisition', 'confidence': 0.85, 'explanation': 'The text mentions a decrease in customer acquisition costs and an improvement in customer retention, which are critical aspects of customer acquisition strategies.', 'evidence': [{'text': 'Asiakashankinnan kustannukset laskivat ja asiakaspysyvyys parani.', 'relevance': 0.85, 'matched_keywords': ['asiakashankinnan kustannukset', 'asiakaspysyvyys'], 'context': 'The text highlights changes in customer acquisition costs and retention rates.'}], 'themes': ['customer retention', 'cost reduction']}, {'category': 'Market Strategy', 'confidence': 0.8, 'explanation': 'The text refers to a market expansion strategy focusing on emerging technology sectors, indicating a strategic approach to market growth.', 'evidence': [{'text': 'Markkinalaajennusstrategia keskittyy nouseviin teknologiasektoreihin.', 'relevance': 0.8, 'matched_keywords': ['markkinalaajennusstrategia', 'nouseviin teknologiasektoreihin'], 'context': 'The text outlines a specific strategy aimed at expanding into new markets.'}], 'themes': ['market expansion', 'technology sectors']}], 'relationships': {'Financial Performance': ['Customer Acquisition', 'Market Strategy'], 'Customer Acquisition': ['Financial Performance', 'Market Strategy'], 'Market Strategy': ['Financial Performance', 'Customer Acquisition']}}\n",
      "\n",
      "Processing category: {'category': 'Financial Performance', 'confidence': 0.95, 'explanation': 'The text discusses financial results, specifically mentioning revenue growth and improved margins, which are key indicators of financial performance.', 'evidence': [{'text': 'Q3 taloudelliset tulokset osoittavat 15% liikevaihdon kasvun ja parantuneet katteet.', 'relevance': 0.9, 'matched_keywords': ['taloudelliset tulokset', 'liikevaihdon kasvu', 'parantuneet katteet'], 'context': 'The text provides specific financial metrics indicating performance.'}], 'themes': ['revenue growth', 'profit margins']}\n",
      "Created category: name='Financial Performance' confidence=0.95 description='The text discusses financial results, specifically mentioning revenue growth and improved margins, which are key indicators of financial performance.' evidence=[Evidence(text='Q3 taloudelliset tulokset osoittavat 15% liikevaihdon kasvun ja parantuneet katteet.', relevance=0.9)] themes=['revenue growth', 'profit margins']\n",
      "\n",
      "Processing category: {'category': 'Customer Acquisition', 'confidence': 0.85, 'explanation': 'The text mentions a decrease in customer acquisition costs and an improvement in customer retention, which are critical aspects of customer acquisition strategies.', 'evidence': [{'text': 'Asiakashankinnan kustannukset laskivat ja asiakaspysyvyys parani.', 'relevance': 0.85, 'matched_keywords': ['asiakashankinnan kustannukset', 'asiakaspysyvyys'], 'context': 'The text highlights changes in customer acquisition costs and retention rates.'}], 'themes': ['customer retention', 'cost reduction']}\n",
      "Created category: name='Customer Acquisition' confidence=0.85 description='The text mentions a decrease in customer acquisition costs and an improvement in customer retention, which are critical aspects of customer acquisition strategies.' evidence=[Evidence(text='Asiakashankinnan kustannukset laskivat ja asiakaspysyvyys parani.', relevance=0.85)] themes=['customer retention', 'cost reduction']\n",
      "\n",
      "Processing category: {'category': 'Market Strategy', 'confidence': 0.8, 'explanation': 'The text refers to a market expansion strategy focusing on emerging technology sectors, indicating a strategic approach to market growth.', 'evidence': [{'text': 'Markkinalaajennusstrategia keskittyy nouseviin teknologiasektoreihin.', 'relevance': 0.8, 'matched_keywords': ['markkinalaajennusstrategia', 'nouseviin teknologiasektoreihin'], 'context': 'The text outlines a specific strategy aimed at expanding into new markets.'}], 'themes': ['market expansion', 'technology sectors']}\n",
      "Created category: name='Market Strategy' confidence=0.8 description='The text refers to a market expansion strategy focusing on emerging technology sectors, indicating a strategic approach to market growth.' evidence=[Evidence(text='Markkinalaajennusstrategia keskittyy nouseviin teknologiasektoreihin.', relevance=0.8)] themes=['market expansion', 'technology sectors']\n",
      "\n",
      "Final categories: [CategoryMatch(name='Financial Performance', confidence=0.95, description='The text discusses financial results, specifically mentioning revenue growth and improved margins, which are key indicators of financial performance.', evidence=[Evidence(text='Q3 taloudelliset tulokset osoittavat 15% liikevaihdon kasvun ja parantuneet katteet.', relevance=0.9)], themes=['revenue growth', 'profit margins']), CategoryMatch(name='Customer Acquisition', confidence=0.85, description='The text mentions a decrease in customer acquisition costs and an improvement in customer retention, which are critical aspects of customer acquisition strategies.', evidence=[Evidence(text='Asiakashankinnan kustannukset laskivat ja asiakaspysyvyys parani.', relevance=0.85)], themes=['customer retention', 'cost reduction']), CategoryMatch(name='Market Strategy', confidence=0.8, description='The text refers to a market expansion strategy focusing on emerging technology sectors, indicating a strategic approach to market growth.', evidence=[Evidence(text='Markkinalaajennusstrategia keskittyy nouseviin teknologiasektoreihin.', relevance=0.8)], themes=['market expansion', 'technology sectors'])]\n",
      "\n",
      "Results:\n",
      "--------------------\n",
      "\n",
      "Categories:\n",
      "\n",
      "• Financial Performance\n",
      "  Confidence: 0.95\n",
      "  Description: The text discusses financial results, specifically mentioning revenue growth and improved margins, which are key indicators of financial performance.\n",
      "\n",
      "  Evidence:\n",
      "  - Q3 taloudelliset tulokset osoittavat 15% liikevaihdon kasvun ja parantuneet katteet. (relevance: 0.90)\n",
      "\n",
      "• Customer Acquisition\n",
      "  Confidence: 0.85\n",
      "  Description: The text mentions a decrease in customer acquisition costs and an improvement in customer retention, which are critical aspects of customer acquisition strategies.\n",
      "\n",
      "  Evidence:\n",
      "  - Asiakashankinnan kustannukset laskivat ja asiakaspysyvyys parani. (relevance: 0.85)\n",
      "\n",
      "• Market Strategy\n",
      "  Confidence: 0.80\n",
      "  Description: The text refers to a market expansion strategy focusing on emerging technology sectors, indicating a strategic approach to market growth.\n",
      "\n",
      "  Evidence:\n",
      "  - Markkinalaajennusstrategia keskittyy nouseviin teknologiasektoreihin. (relevance: 0.80)\n"
     ]
    }
   ],
   "source": [
    "# Run in notebook\n",
    "# await run_all_tests()\n",
    "\n",
    "# Or run individual tests:\n",
    "# await test_keyword_analyzer()\n",
    "await test_components_for_language(\"fi\")\n",
    "# await test_pipeline()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "semantic-analyzer",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
