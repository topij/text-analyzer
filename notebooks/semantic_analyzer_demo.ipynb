{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 1 - Markdown\n",
    "# Semantic Text Analyzer Demo Notebook\n",
    "\n",
    "# Cell 2 - Markdown\n",
    "## Setup and Environment\n",
    "\n",
    "# Cell 3 - Code\n",
    "import os\n",
    "import sys\n",
    "from pathlib import Path\n",
    "import asyncio\n",
    "import logging\n",
    "from typing import Dict, Any, Optional\n",
    "import pandas as pd\n",
    "\n",
    "# Add project root to Python path\n",
    "project_root = str(Path().resolve().parent)\n",
    "if project_root not in sys.path:\n",
    "    sys.path.append(project_root)\n",
    "    print(f\"Added {project_root} to Python path\")\n",
    "\n",
    "# Core components\n",
    "from src.semantic_analyzer.analyzer import SemanticAnalyzer\n",
    "from src.utils.FileUtils.file_utils import FileUtils\n",
    "from src.loaders.parameter_adapter import ParameterAdapter\n",
    "from src.core.config import AnalyzerConfig\n",
    "\n",
    "# Initialize FileUtils and set up logging\n",
    "file_utils = FileUtils()\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "# Cell 4 - Markdown\n",
    "## Environment Verification\n",
    "\n",
    "# Cell 5 - Code\n",
    "def verify_environment():\n",
    "    \"\"\"Verify that the notebook environment is properly configured.\"\"\"\n",
    "    # Load environment variables\n",
    "    from dotenv import load_dotenv\n",
    "    env_path = Path(project_root) / \".env\"\n",
    "    env_loaded = load_dotenv(env_path)\n",
    "\n",
    "    # Required environment variables\n",
    "    required_env_vars = [\n",
    "        'OPENAI_API_KEY',\n",
    "        'ANTHROPIC_API_KEY',\n",
    "    ]\n",
    "\n",
    "    # Basic checks\n",
    "    basic_checks = {\n",
    "        \"Project root in path\": project_root in sys.path,\n",
    "        \"Can import src\": \"src\" in sys.modules,\n",
    "        \"FileUtils initialized\": hasattr(file_utils, \"project_root\"),\n",
    "        \".env file loaded\": env_loaded,\n",
    "    }\n",
    "\n",
    "    # Environment variable checks\n",
    "    env_var_checks = {\n",
    "        f\"{var} set\": os.getenv(var) is not None\n",
    "        for var in required_env_vars\n",
    "    }\n",
    "\n",
    "    # Check for required paths using FileUtils\n",
    "    expected_paths = {\n",
    "        \"Raw data\": file_utils.get_data_path(\"raw\"),\n",
    "        \"Processed data\": file_utils.get_data_path(\"processed\"),\n",
    "        \"Configuration\": file_utils.get_data_path(\"configurations\"),\n",
    "        \"Main config.yaml\": Path(project_root) / \"config.yaml\"\n",
    "    }\n",
    "    \n",
    "    path_checks = {\n",
    "        f\"{name} exists\": path.exists()\n",
    "        for name, path in expected_paths.items()\n",
    "    }\n",
    "\n",
    "    # Combine all checks\n",
    "    all_checks = {\n",
    "        **basic_checks,\n",
    "        **env_var_checks,\n",
    "        **path_checks\n",
    "    }\n",
    "    \n",
    "    # Print results\n",
    "    print(\"Environment Check Results:\")\n",
    "    print(\"=\" * 50)\n",
    "    \n",
    "    def print_section(title, checks):\n",
    "        print(f\"\\n{title}:\")\n",
    "        print(\"-\" * len(title))\n",
    "        for check, result in checks.items():\n",
    "            status = \"✓\" if result else \"✗\"\n",
    "            print(f\"{status} {check}\")\n",
    "    \n",
    "    print_section(\"Basic Setup\", basic_checks)\n",
    "    print_section(\"Environment Variables\", env_var_checks)\n",
    "    print_section(\"Project Structure\", path_checks)\n",
    "    \n",
    "    # Overall status\n",
    "    all_passed = all(all_checks.values())\n",
    "    print(\"\\n\" + \"=\" * 50)\n",
    "    print(\"Environment Status:\", \"Ready ✓\" if all_passed else \"Setup needed ✗\")\n",
    "    \n",
    "    if not all_passed:\n",
    "        print(\"\\nSetup Instructions:\")\n",
    "        if not env_loaded:\n",
    "            print(\"- Create a .env file in the project root with required API keys\")\n",
    "        for var in required_env_vars:\n",
    "            if not os.getenv(var):\n",
    "                print(f\"- Add {var} to your .env file\")\n",
    "        for name, path in expected_paths.items():\n",
    "            if not path.exists():\n",
    "                print(f\"- Create {name} directory at {path}\")\n",
    "\n",
    "    return all_passed\n",
    "\n",
    "# Run verification\n",
    "verify_environment()\n",
    "\n",
    "# Cell 6 - Markdown\n",
    "## Helper Functions and Test Data Setup\n",
    "\n",
    "# Cell 7 - Code\n",
    "class NotebookAnalyzer:\n",
    "    \"\"\"Helper class for running analyses in the notebook.\"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.file_utils = FileUtils()\n",
    "        self.test_texts = self._load_test_texts()\n",
    "        self.param_adapter = ParameterAdapter(Path(project_root) / \"config.yaml\")\n",
    "    \n",
    "    def _load_test_texts(self) -> Dict[str, str]:\n",
    "        \"\"\"Load or create test texts.\"\"\"\n",
    "        texts = {\n",
    "            \"technical\": \"\"\"\n",
    "            Python is a high-level programming language known for its simplicity.\n",
    "            It supports multiple programming paradigms including procedural and\n",
    "            object-oriented programming.\n",
    "            \"\"\",\n",
    "            \"business\": \"\"\"\n",
    "            The company's Q3 results exceeded expectations with revenue growth of 15%.\n",
    "            Customer acquisition costs decreased while retention rates improved.\n",
    "            The board has approved a new strategic initiative focusing on expansion.\n",
    "            \"\"\",\n",
    "            \"finnish\": \"\"\"\n",
    "            Ohjelmistokehittäjä työskentelee asiakasprojektissa kehittäen\n",
    "            verkkokauppajärjestelmää. Tekninen toteutus vaatii erityistä huomiota\n",
    "            tietoturvan osalta.\n",
    "            \"\"\"\n",
    "        }\n",
    "        \n",
    "        # Save texts using FileUtils for future use\n",
    "        df = pd.DataFrame([\n",
    "            {\"name\": name, \"content\": content.strip()}\n",
    "            for name, content in texts.items()\n",
    "        ])\n",
    "        \n",
    "        saved_files, _ = self.file_utils.save_data_to_disk(\n",
    "            data={\"texts\": df},\n",
    "            output_type=\"raw\",\n",
    "            file_name=\"test_texts\",\n",
    "            output_filetype=\"xlsx\",\n",
    "            include_timestamp=False\n",
    "        )\n",
    "        \n",
    "        return texts\n",
    "    \n",
    "    async def analyze_text(self, text_key: str, **kwargs):\n",
    "        \"\"\"Analyze a specific test text.\"\"\"\n",
    "        if text_key not in self.test_texts:\n",
    "            raise ValueError(f\"Unknown text key: {text_key}. Available keys: {list(self.test_texts.keys())}\")\n",
    "        \n",
    "        analyzer = SemanticAnalyzer(**kwargs)\n",
    "        results = await analyzer.analyze(self.test_texts[text_key], **kwargs)\n",
    "        await self.display_results(results)\n",
    "        return results\n",
    "    \n",
    "    async def analyze_all(self, **kwargs):\n",
    "        \"\"\"Analyze all test texts.\"\"\"\n",
    "        analyzer = SemanticAnalyzer(**kwargs)\n",
    "        all_results = await analyzer.analyze_batch(\n",
    "            list(self.test_texts.values()),\n",
    "            **kwargs\n",
    "        )\n",
    "        \n",
    "        for i, results in enumerate(all_results):\n",
    "            print(f\"\\n=== Text {i+1} ===\")\n",
    "            await self.display_results(results)\n",
    "        \n",
    "        return all_results\n",
    "    \n",
    "    @staticmethod\n",
    "    async def display_results(results: Dict[str, Any]) -> None:\n",
    "        \"\"\"Display analysis results in a formatted way.\"\"\"\n",
    "        for analysis_type, data in results.items():\n",
    "            print(f\"\\n=== {analysis_type.upper()} ===\")\n",
    "            if isinstance(data, dict):\n",
    "                for key, value in data.items():\n",
    "                    print(f\"{key}: {value}\")\n",
    "            else:\n",
    "                print(data)\n",
    "    \n",
    "    def save_results(self, results: Dict[str, Any], filename: str) -> Path:\n",
    "        \"\"\"Save analysis results using FileUtils.\"\"\"\n",
    "        saved_files, _ = self.file_utils.save_data_to_disk(\n",
    "            data=results,\n",
    "            output_type=\"processed\",\n",
    "            file_name=filename,\n",
    "            output_filetype=\"yaml\"\n",
    "        )\n",
    "        return Path(list(saved_files.values())[0])\n",
    "\n",
    "# Initialize analyzer\n",
    "notebook_analyzer = NotebookAnalyzer()\n",
    "\n",
    "# Cell 8 - Markdown\n",
    "## Basic Analysis Example\n",
    "\n",
    "# Cell 9 - Code\n",
    "# Analyze technical text\n",
    "results = await notebook_analyzer.analyze_text(\n",
    "    \"technical\",\n",
    "    analysis_types=[\"keywords\", \"themes\"],\n",
    "    language=\"en\"\n",
    ")\n",
    "\n",
    "# Cell 10 - Markdown\n",
    "## Analysis with Parameters\n",
    "\n",
    "# Cell 11 - Code\n",
    "# Load parameters and analyze business text\n",
    "params = notebook_analyzer.param_adapter.load_and_convert()\n",
    "\n",
    "results = await notebook_analyzer.analyze_text(\n",
    "    \"business\",\n",
    "    analysis_types=[\"keywords\", \"themes\", \"categories\"],\n",
    "    language=\"en\",\n",
    "    parameter_file=params\n",
    ")\n",
    "\n",
    "# Cell 12 - Markdown\n",
    "## Finnish Text Analysis\n",
    "\n",
    "# Cell 13 - Code\n",
    "# Analyze Finnish text\n",
    "results = await notebook_analyzer.analyze_text(\n",
    "    \"finnish\",\n",
    "    analysis_types=[\"keywords\", \"categories\"],\n",
    "    language=\"fi\"\n",
    ")\n",
    "\n",
    "# Cell 14 - Markdown\n",
    "## Batch Analysis\n",
    "\n",
    "# Cell 15 - Code\n",
    "# Analyze all texts\n",
    "all_results = await notebook_analyzer.analyze_all(\n",
    "    analysis_types=[\"keywords\", \"themes\"]\n",
    ")\n",
    "\n",
    "# Cell 16 - Markdown\n",
    "## Saving Results\n",
    "\n",
    "# Cell 17 - Code\n",
    "# Save results\n",
    "saved_path = notebook_analyzer.save_results(results, \"analysis_results\")\n",
    "print(f\"Results saved to: {saved_path}\")\n",
    "\n",
    "# Cell 18 - Markdown\n",
    "## Custom Categories Analysis\n",
    "\n",
    "# Cell 19 - Code\n",
    "# Define custom categories\n",
    "categories = {\n",
    "    \"technical\": {\n",
    "        \"description\": \"Technical content\",\n",
    "        \"keywords\": [\"programming\", \"software\", \"technology\"],\n",
    "        \"threshold\": 0.7\n",
    "    },\n",
    "    \"business\": {\n",
    "        \"description\": \"Business content\",\n",
    "        \"keywords\": [\"revenue\", \"growth\", \"financial\"],\n",
    "        \"threshold\": 0.6\n",
    "    }\n",
    "}\n",
    "\n",
    "# Analyze with custom categories\n",
    "results = await notebook_analyzer.analyze_text(\n",
    "    \"technical\",\n",
    "    analysis_types=[\"categories\"],\n",
    "    categories=categories\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "semantic-analyzer",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
