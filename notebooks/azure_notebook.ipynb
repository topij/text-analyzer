{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "# Import required modules\n",
        "import sys\n",
        "from pathlib import Path\n",
        "# from typing import List, Dict, Any, Tuple, Union\n",
        "# import logging\n",
        "# import asyncio\n",
        "\n",
        "# Add project root to Python path if needed\n",
        "project_root = str(Path().resolve().parent)\n",
        "if project_root not in sys.path:\n",
        "    sys.path.append(project_root)\n",
        "print(f\"Project root: {project_root}\")"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Project root: /mnt/batch/tasks/shared/LS_root/mounts/clusters/basic-cpu/code/Users/topi.jarvinen/semantic-text-analyzer\n"
        }
      ],
      "execution_count": 1,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1733155680158
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# azure_notebook.ipynb\n",
        "import os\n",
        "from src.az_helpers.setup_azure import init_azure_ml # setup_environment\n",
        "from src.semantic_analyzer import SemanticAnalyzer"
      ],
      "outputs": [],
      "execution_count": 2,
      "metadata": {
        "gather": {
          "logged": 1733155711839
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from src.az_helpers.az_environment import setup_notebook_env, verify_environment"
      ],
      "outputs": [],
      "execution_count": 3,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1733155711934
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Set up environment and logging\n",
        "setup_notebook_env(log_level=\"DEBUG\")\n",
        "verify_environment()\n"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Environment Check Results:\n==================================================\n✓ Project root in path\n✓ FileUtils initialized\n✓ .env file loaded\n✓ OPENAI_API_KEY set\n✓ ANTHROPIC_API_KEY set\n✓ Raw data exists\n✓ Processed data exists\n✓ Configuration exists\n✓ Main config.yaml exists\n\n==================================================\nEnvironment Status: Ready ✓\n"
        },
        {
          "output_type": "execute_result",
          "execution_count": 4,
          "data": {
            "text/plain": "True"
          },
          "metadata": {}
        }
      ],
      "execution_count": 4,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1733155712101
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Setup environment\n",
        "from FileUtils import FileUtils\n",
        "file_utils = FileUtils()"
      ],
      "outputs": [],
      "execution_count": 5,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1733155752005
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize analyzer\n",
        "analyzer = SemanticAnalyzer(\n",
        "    parameter_file=\"azure://parameters/parameters_en.xlsx\",\n",
        "    file_utils=file_utils\n",
        ")"
      ],
      "outputs": [],
      "execution_count": 9,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1733156115480
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Test analysis\n",
        "text = \"Machine learning models process data efficiently.\"\n",
        "result = await analyzer.analyze(text)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "\nProcessing response: {'categories': [{'category': 'Technical', 'confidence': 0.85, 'explanation': 'The text discusses machine learning models, which are a key concept in the technical domain, particularly in data processing and analysis.', 'evidence': [{'text': 'Machine learning models process data efficiently.', 'relevance': 0.9, 'matched_keywords': ['machine', 'efficiently', 'process', 'model', 'data'], 'context': 'The entire sentence focuses on the capabilities of machine learning in handling data.'}], 'themes': ['data processing', 'machine learning']}], 'relationships': {'Technical': ['Business', 'Data Science']}}\n\nProcessing category: {'category': 'Technical', 'confidence': 0.85, 'explanation': 'The text discusses machine learning models, which are a key concept in the technical domain, particularly in data processing and analysis.', 'evidence': [{'text': 'Machine learning models process data efficiently.', 'relevance': 0.9, 'matched_keywords': ['machine', 'efficiently', 'process', 'model', 'data'], 'context': 'The entire sentence focuses on the capabilities of machine learning in handling data.'}], 'themes': ['data processing', 'machine learning']}\nCreated category: name='' confidence=0.85 description='' evidence=[Evidence(text='Machine learning models process data efficiently.', relevance=0.9)] themes=['data processing', 'machine learning']\n\nFinal categories: [CategoryMatch(name='', confidence=0.85, description='', evidence=[Evidence(text='Machine learning models process data efficiently.', relevance=0.9)], themes=['data processing', 'machine learning'])]\n\nRaw LLM response: {'themes': [{'name': 'Efficiency in Data Processing', 'description': 'The ability of machine learning models to process large volumes of data quickly and effectively, highlighting their efficiency in handling complex datasets.', 'confidence': 0.95, 'keywords': ['efficiently', 'process', 'data'], 'domain': 'technical', 'parent_theme': None}, {'name': 'Machine Learning Models', 'description': 'The frameworks and algorithms that enable machines to learn from data, emphasizing their role in automating data analysis and decision-making.', 'confidence': 0.9, 'keywords': ['machine', 'model', 'learn'], 'domain': 'technical', 'parent_theme': None}], 'evidence': {'Efficiency in Data Processing': [{'text': 'Machine learning models process data efficiently.', 'relevance': 0.9, 'keywords': ['efficiently', 'process', 'data']}], 'Machine Learning Models': [{'text': 'Machine learning models process data efficiently.', 'relevance': 0.85, 'keywords': ['machine', 'model', 'learn']}]}, 'relationships': {'Efficiency in Data Processing': ['Machine Learning Models'], 'Machine Learning Models': ['Efficiency in Data Processing']}}\n\nProcessed LLM response: {'themes': [{'name': 'Efficiency in Data Processing', 'description': 'The ability of machine learning models to process large volumes of data quickly and effectively, highlighting their efficiency in handling complex datasets.', 'confidence': 0.95, 'keywords': ['efficiently', 'process', 'data'], 'domain': 'technical', 'parent_theme': None}, {'name': 'Machine Learning Models', 'description': 'The frameworks and algorithms that enable machines to learn from data, emphasizing their role in automating data analysis and decision-making.', 'confidence': 0.9, 'keywords': ['machine', 'model', 'learn'], 'domain': 'technical', 'parent_theme': None}], 'evidence': {'Efficiency in Data Processing': [{'text': 'Machine learning models process data efficiently.', 'relevance': 0.9, 'keywords': ['efficiently', 'process', 'data']}], 'Machine Learning Models': [{'text': 'Machine learning models process data efficiently.', 'relevance': 0.85, 'keywords': ['machine', 'model', 'learn']}]}, 'relationships': {'Efficiency in Data Processing': ['Machine Learning Models'], 'Machine Learning Models': ['Efficiency in Data Processing']}}\n"
        }
      ],
      "execution_count": 10,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1733156123820
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Save results\n",
        "file_utils.save_data_to_disk(\n",
        "    data=result.to_dict(),\n",
        "    output_filetype=\"json\",\n",
        "    output_type=\"processed\",\n",
        "    file_name=\"analysis_result\"\n",
        ")"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    }
  ],
  "metadata": {
    "kernelspec": {
      "name": "semantic-analyzer",
      "language": "python",
      "display_name": "Python (semantic-analyzer)"
    },
    "language_info": {
      "name": "python",
      "version": "3.9.20",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "microsoft": {
      "ms_spell_check": {
        "ms_spell_check_language": "en"
      },
      "host": {
        "AzureML": {
          "notebookHasBeenCompleted": true
        }
      }
    },
    "kernel_info": {
      "name": "semantic-analyzer"
    },
    "nteract": {
      "version": "nteract-front-end@1.0.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}