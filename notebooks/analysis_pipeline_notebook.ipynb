{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Semantic Analysis Pipeline\n",
    "\n",
    "This notebook demonstrates the semantic text analysis capabilities using our custom analyzers.\n",
    "\n",
    "## Setup\n",
    "Import required packages and configure the environment:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# At start of notebook\n",
    "import sys\n",
    "from pathlib import Path\n",
    "import logging\n",
    "import os\n",
    "\n",
    "# Add project root to Python path\n",
    "project_root = str(Path().resolve().parent)\n",
    "if project_root not in sys.path:\n",
    "    sys.path.append(project_root)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-18 12:27:39,699 - src.utils.FileUtils.file_utils - DEBUG [file_utils.py:192] - Initialized FileUtils with log level: INFO\n",
      "2024-11-18 12:27:39,700 - src.utils.FileUtils.file_utils - DEBUG [file_utils.py:198] - Project root: c:\\Users\\tja\\OneDrive - Rastor-instituutti ry\\Tiedostot\\Rastor-instituutti\\kehittäminen\\analytiikka\\repos\\semantic-text-analyzer\n",
      "2024-11-18 12:27:39,705 - src.utils.FileUtils.file_utils - DEBUG [file_utils.py:192] - Initialized FileUtils with log level: INFO\n",
      "2024-11-18 12:27:39,706 - src.utils.FileUtils.file_utils - DEBUG [file_utils.py:198] - Project root: c:\\Users\\tja\\OneDrive - Rastor-instituutti ry\\Tiedostot\\Rastor-instituutti\\kehittäminen\\analytiikka\\repos\\semantic-text-analyzer\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Environment Check Results:\n",
      "==================================================\n",
      "\n",
      "Basic Setup:\n",
      "-----------\n",
      "✓ Project root in path\n",
      "✓ FileUtils initialized\n",
      "✓ .env file loaded\n",
      "\n",
      "Environment Variables:\n",
      "---------------------\n",
      "✓ OPENAI_API_KEY set\n",
      "✓ ANTHROPIC_API_KEY set\n",
      "\n",
      "Project Structure:\n",
      "-----------------\n",
      "✓ Raw data exists\n",
      "✓ Processed data exists\n",
      "✓ Configuration exists\n",
      "✓ Main config.yaml exists\n",
      "\n",
      "==================================================\n",
      "Environment Status: Ready ✓\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# import logging\n",
    "# from src.nb_helpers.logging import configure_logging\n",
    "\n",
    "# Set up environment with DEBUG level\n",
    "from src.nb_helpers.environment import setup_notebook_env, verify_environment\n",
    "setup_notebook_env(log_level=\"DEBUG\")\n",
    "\n",
    "# Any verification needed will maintain DEBUG level\n",
    "verify_environment(log_level=\"DEBUG\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary components\n",
    "from src.loaders.parameter_handler import ParameterHandler\n",
    "from src.nb_helpers.analyzers import (\n",
    "    analyze_keywords,\n",
    "    analyze_themes,\n",
    "    analyze_categories,\n",
    "    analyze_text,\n",
    "    AnalysisOptions\n",
    ")\n",
    "\n",
    "from scripts.migrate_parameters import create_example_parameters\n",
    "from src.nb_helpers.logging import configure_logging, verify_logging_setup_with_hierarchy, reset_debug_logging\n",
    "from src.loaders.parameter_handler import ParameterHandler, get_parameter_file_path, verify_parameter_file\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-18 12:27:39,843 - src.nb_helpers.logging - DEBUG - Logging configured at DEBUG level\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Logging Configuration:\n",
      "--------------------------------------------------\n",
      "\n",
      "Logger: root\n",
      "Set Level: DEBUG\n",
      "Effective Level: DEBUG\n",
      "Propagates to root: True\n",
      "Handlers:\n",
      "  Handler 1 level: DEBUG\n",
      "\n",
      "Logger: src.nb_helpers.analyzers\n",
      "Hierarchy:\n",
      "  src: NOTSET\n",
      "  src.nb_helpers: NOTSET\n",
      "  src.nb_helpers.analyzers: DEBUG\n",
      "Set Level: DEBUG\n",
      "Effective Level: DEBUG\n",
      "Propagates to root: True\n",
      "No handlers (uses root handlers)\n",
      "\n",
      "Logger: src.analyzers.keyword_analyzer\n",
      "Hierarchy:\n",
      "  src: NOTSET\n",
      "  src.analyzers: NOTSET\n",
      "  src.analyzers.keyword_analyzer: DEBUG\n",
      "Set Level: DEBUG\n",
      "Effective Level: DEBUG\n",
      "Propagates to root: True\n",
      "No handlers (uses root handlers)\n",
      "\n",
      "Logger: src.analyzers.theme_analyzer\n",
      "Hierarchy:\n",
      "  src: NOTSET\n",
      "  src.analyzers: NOTSET\n",
      "  src.analyzers.theme_analyzer: DEBUG\n",
      "Set Level: DEBUG\n",
      "Effective Level: DEBUG\n",
      "Propagates to root: True\n",
      "No handlers (uses root handlers)\n",
      "\n",
      "Logger: src.analyzers.category_analyzer\n",
      "Hierarchy:\n",
      "  src: NOTSET\n",
      "  src.analyzers: NOTSET\n",
      "  src.analyzers.category_analyzer: DEBUG\n",
      "Set Level: DEBUG\n",
      "Effective Level: DEBUG\n",
      "Propagates to root: True\n",
      "No handlers (uses root handlers)\n",
      "\n",
      "Logger: src.utils.FileUtils.file_utils\n",
      "Hierarchy:\n",
      "  src: NOTSET\n",
      "  src.utils: NOTSET\n",
      "  src.utils.FileUtils: NOTSET\n",
      "  src.utils.FileUtils.file_utils: DEBUG\n",
      "Set Level: DEBUG\n",
      "Effective Level: DEBUG\n",
      "Propagates to root: True\n",
      "No handlers (uses root handlers)\n",
      "\n",
      "Logger: httpx\n",
      "Hierarchy:\n",
      "  httpx: INFO\n",
      "Set Level: INFO\n",
      "Effective Level: INFO\n",
      "Propagates to root: True\n",
      "No handlers (uses root handlers)\n"
     ]
    }
   ],
   "source": [
    "# Set initial logging\n",
    "configure_logging(level=\"DEBUG\")\n",
    "# Keep HTTP loggers at INFO\n",
    "for name in [\"httpx\", \"httpcore\", \"openai\", \"anthropic\"]:\n",
    "    logging.getLogger(name).setLevel(logging.INFO)\n",
    "    \n",
    "verify_logging_setup_with_hierarchy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# detailed_logging_info = True\n",
    "# if detailed_logging_info:\n",
    "#     from src.nb_helpers.logging import verify_logging_setup_with_hierarchy\n",
    "#     # Configure logging\n",
    "#     # configure_logging(level=\"DEBUG\")\n",
    "#     # Verify with detailed information\n",
    "#     verify_logging_setup_with_hierarchy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example texts in different languages\n",
    "example_texts = {\n",
    "    \"English Technical\": \"\"\"\n",
    "        The cloud migration project improved system scalability while reducing costs.\n",
    "        New DevOps practices streamlined the deployment pipeline significantly.\n",
    "    \"\"\",\n",
    "    \n",
    "    \"Finnish Technical\": \"\"\"\n",
    "        Pilvipalveluihin siirtyminen paransi järjestelmän skaalautuvuutta ja vähensi kustannuksia.\n",
    "        Uudet DevOps-käytännöt tehostivat merkittävästi käyttöönottoprosessia.\n",
    "    \"\"\",\n",
    "    \n",
    "    \"English Business\": \"\"\"\n",
    "        Q3 financial results show 15% revenue growth and improved profit margins.\n",
    "        Customer acquisition costs decreased while retention rates increased.\n",
    "    \"\"\",\n",
    "    \n",
    "    \"Finnish Business\": \"\"\"\n",
    "        Q3 taloudelliset tulokset osoittavat 15% liikevaihdon kasvun ja parantuneet katteet.\n",
    "        Asiakashankinnan kustannukset laskivat ja asiakaspysyvyys parani.\n",
    "    \"\"\"\n",
    "}\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-18 12:27:39,969 - src.utils.FileUtils.file_utils - DEBUG [file_utils.py:192] - Initialized FileUtils with log level: INFO\n",
      "2024-11-18 12:27:39,969 - src.utils.FileUtils.file_utils - DEBUG - Initialized FileUtils with log level: INFO\n",
      "2024-11-18 12:27:39,971 - src.utils.FileUtils.file_utils - DEBUG [file_utils.py:198] - Project root: c:\\Users\\tja\\OneDrive - Rastor-instituutti ry\\Tiedostot\\Rastor-instituutti\\kehittäminen\\analytiikka\\repos\\semantic-text-analyzer\n",
      "2024-11-18 12:27:39,971 - src.utils.FileUtils.file_utils - DEBUG - Project root: c:\\Users\\tja\\OneDrive - Rastor-instituutti ry\\Tiedostot\\Rastor-instituutti\\kehittäminen\\analytiikka\\repos\\semantic-text-analyzer\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using existing parameter file at: c:\\Users\\tja\\OneDrive - Rastor-instituutti ry\\Tiedostot\\Rastor-instituutti\\kehittäminen\\analytiikka\\repos\\semantic-text-analyzer\\data\\parameters\\parameters_en.xlsx\n",
      "\n",
      "Parameter File Verification:\n",
      "Absolute path: C:\\Users\\tja\\OneDrive - Rastor-instituutti ry\\Tiedostot\\Rastor-instituutti\\kehittäminen\\analytiikka\\repos\\semantic-text-analyzer\\data\\parameters\\parameters_en.xlsx\n",
      "File exists: True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-18 12:27:41,260 - src.utils.FileUtils.file_utils - DEBUG [file_utils.py:192] - Initialized FileUtils with log level: INFO\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Found sheets:\n",
      "\n",
      "General Parameters:\n",
      "                parameter                           value  \\\n",
      "0            max_keywords                              10   \n",
      "1                focus_on  technical and business content   \n",
      "2  column_name_to_analyze                         content   \n",
      "3      min_keyword_length                               3   \n",
      "4       include_compounds                            True   \n",
      "\n",
      "                          description  \n",
      "0  Maximum keywords to extract (1-20)  \n",
      "1                 Analysis focus area  \n",
      "2          Name of the content column  \n",
      "3              Minimum keyword length  \n",
      "4              Include compound words  \n",
      "\n",
      "Categories:\n",
      "              category                                 description  \\\n",
      "0    technical_content  Technical and software development content   \n",
      "1     business_content              Business and financial content   \n",
      "2  educational_content            Educational and training content   \n",
      "\n",
      "                                            keywords  threshold  parent  \n",
      "0  software,development,api,programming,technical...        0.6     NaN  \n",
      "1     revenue,sales,market,growth,financial,business        0.6     NaN  \n",
      "2        learning,education,training,teaching,skills        0.5     NaN  \n",
      "\n",
      "Predefined Keywords:\n",
      "            keyword  importance     domain\n",
      "0  machine learning         1.0  technical\n",
      "1   cloud computing         0.9  technical\n",
      "2    revenue growth         0.9   business\n",
      "\n",
      "Excluded Keywords:\n",
      "  keyword       reason\n",
      "0     the  Common word\n",
      "1     and  Common word\n",
      "2     for  Common word\n",
      "\n",
      "Analysis Settings:\n",
      "                         setting  value  \\\n",
      "0  theme_analysis.min_confidence    0.5   \n",
      "1            weights.statistical    0.4   \n",
      "2                    weights.llm    0.6   \n",
      "\n",
      "                              description  \n",
      "0  Minimum confidence for theme detection  \n",
      "1         Weight for statistical analysis  \n",
      "2                 Weight for LLM analysis  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-18 12:27:41,260 - src.utils.FileUtils.file_utils - DEBUG - Initialized FileUtils with log level: INFO\n",
      "2024-11-18 12:27:41,263 - src.utils.FileUtils.file_utils - DEBUG [file_utils.py:198] - Project root: c:\\Users\\tja\\OneDrive - Rastor-instituutti ry\\Tiedostot\\Rastor-instituutti\\kehittäminen\\analytiikka\\repos\\semantic-text-analyzer\n",
      "2024-11-18 12:27:41,263 - src.utils.FileUtils.file_utils - DEBUG - Project root: c:\\Users\\tja\\OneDrive - Rastor-instituutti ry\\Tiedostot\\Rastor-instituutti\\kehittäminen\\analytiikka\\repos\\semantic-text-analyzer\n",
      "2024-11-18 12:27:41,272 - src.loaders.parameter_handler - DEBUG - Using parameter file: c:\\Users\\tja\\OneDrive - Rastor-instituutti ry\\Tiedostot\\Rastor-instituutti\\kehittäminen\\analytiikka\\repos\\semantic-text-analyzer\\data\\parameters\\parameters_en.xlsx\n",
      "2024-11-18 12:27:41,274 - src.loaders.parameter_handler - DEBUG - Loading Excel file from: c:\\Users\\tja\\OneDrive - Rastor-instituutti ry\\Tiedostot\\Rastor-instituutti\\kehittäminen\\analytiikka\\repos\\semantic-text-analyzer\\data\\parameters\\parameters_en.xlsx\n",
      "2024-11-18 12:27:41,263 - src.utils.FileUtils.file_utils - DEBUG [file_utils.py:198] - Project root: c:\\Users\\tja\\OneDrive - Rastor-instituutti ry\\Tiedostot\\Rastor-instituutti\\kehittäminen\\analytiikka\\repos\\semantic-text-analyzer\n",
      "2024-11-18 12:27:41,263 - src.utils.FileUtils.file_utils - DEBUG - Project root: c:\\Users\\tja\\OneDrive - Rastor-instituutti ry\\Tiedostot\\Rastor-instituutti\\kehittäminen\\analytiikka\\repos\\semantic-text-analyzer\n",
      "2024-11-18 12:27:41,272 - src.loaders.parameter_handler - DEBUG - Using parameter file: c:\\Users\\tja\\OneDrive - Rastor-instituutti ry\\Tiedostot\\Rastor-instituutti\\kehittäminen\\analytiikka\\repos\\semantic-text-analyzer\\data\\parameters\\parameters_en.xlsx\n",
      "2024-11-18 12:27:41,274 - src.loaders.parameter_handler - DEBUG - Loading Excel file from: c:\\Users\\tja\\OneDrive - Rastor-instituutti ry\\Tiedostot\\Rastor-instituutti\\kehittäminen\\analytiikka\\repos\\semantic-text-analyzer\\data\\parameters\\parameters_en.xlsx\n",
      "2024-11-18 12:27:41,326 - src.utils.FileUtils.file_utils - INFO [file_utils.py:1018] - Successfully loaded 5 sheets from c:\\Users\\tja\\OneDrive - Rastor-instituutti ry\\Tiedostot\\Rastor-instituutti\\kehittäminen\\analytiikka\\repos\\semantic-text-analyzer\\data\\parameters\\parameters_en.xlsx\n",
      "2024-11-18 12:27:41,326 - src.utils.FileUtils.file_utils - INFO - Successfully loaded 5 sheets from c:\\Users\\tja\\OneDrive - Rastor-instituutti ry\\Tiedostot\\Rastor-instituutti\\kehittäminen\\analytiikka\\repos\\semantic-text-analyzer\\data\\parameters\\parameters_en.xlsx\n",
      "2024-11-18 12:27:41,328 - src.loaders.parameter_handler - DEBUG - Found sheets: ['General Parameters', 'Categories', 'Predefined Keywords', 'Excluded Keywords', 'Analysis Settings']\n",
      "2024-11-18 12:27:41,329 - src.loaders.parameter_handler - DEBUG - Looking for general parameters in sheet: General Parameters\n",
      "2024-11-18 12:27:41,333 - src.loaders.parameter_handler - DEBUG - General sheet columns: ['parameter', 'value', 'description']\n",
      "2024-11-18 12:27:41,336 - src.loaders.parameter_handler - DEBUG - General sheet content:\n",
      "                parameter                           value  \\\n",
      "0            max_keywords                              10   \n",
      "1                focus_on  technical and business content   \n",
      "2  column_name_to_analyze                         content   \n",
      "3      min_keyword_length                               3   \n",
      "4       include_compounds                            True   \n",
      "5                language                              en   \n",
      "\n",
      "                          description  \n",
      "0  Maximum keywords to extract (1-20)  \n",
      "1                 Analysis focus area  \n",
      "2          Name of the content column  \n",
      "3              Minimum keyword length  \n",
      "4              Include compound words  \n",
      "5                    Content language  \n",
      "2024-11-18 12:27:41,338 - src.loaders.parameter_handler - DEBUG - Starting with default general parameters: {'max_keywords': 10, 'min_keyword_length': 3, 'language': 'en', 'focus_on': 'general content analysis', 'include_compounds': True, 'max_themes': 3, 'min_confidence': 0.3, 'column_name_to_analyze': 'text'}\n",
      "2024-11-18 12:27:41,339 - src.loaders.parameter_handler - DEBUG - Found parameter and value columns\n",
      "2024-11-18 12:27:41,344 - src.loaders.parameter_handler - DEBUG - Full dataframe:\n",
      "                parameter                           value  \\\n",
      "0            max_keywords                              10   \n",
      "1                focus_on  technical and business content   \n",
      "2  column_name_to_analyze                         content   \n",
      "3      min_keyword_length                               3   \n",
      "4       include_compounds                            True   \n",
      "5                language                              en   \n",
      "\n",
      "                          description  \n",
      "0  Maximum keywords to extract (1-20)  \n",
      "1                 Analysis focus area  \n",
      "2          Name of the content column  \n",
      "3              Minimum keyword length  \n",
      "4              Include compound words  \n",
      "5                    Content language  \n",
      "2024-11-18 12:27:41,345 - src.loaders.parameter_handler - DEBUG - Setting max_keywords = 10\n",
      "2024-11-18 12:27:41,347 - src.loaders.parameter_handler - DEBUG - Setting focus_on = technical and business content\n",
      "2024-11-18 12:27:41,351 - src.loaders.parameter_handler - DEBUG - Setting column_name_to_analyze = content\n",
      "2024-11-18 12:27:41,354 - src.loaders.parameter_handler - DEBUG - Setting min_keyword_length = 3\n",
      "2024-11-18 12:27:41,356 - src.loaders.parameter_handler - DEBUG - Setting include_compounds = True\n",
      "2024-11-18 12:27:41,358 - src.loaders.parameter_handler - DEBUG - Setting language = en\n",
      "2024-11-18 12:27:41,359 - src.loaders.parameter_handler - DEBUG - Final general parameters: {'max_keywords': 10, 'min_keyword_length': 3, 'language': 'en', 'focus_on': 'technical and business content', 'include_compounds': True, 'max_themes': 3, 'min_confidence': 0.3, 'column_name_to_analyze': 'content'}\n",
      "2024-11-18 12:27:41,361 - src.loaders.parameter_handler - DEBUG - Parsed general parameters: {'max_keywords': 10, 'min_keyword_length': 3, 'language': 'en', 'focus_on': 'technical and business content', 'include_compounds': True, 'max_themes': 3, 'min_confidence': 0.3, 'column_name_to_analyze': 'content'}\n",
      "2024-11-18 12:27:41,365 - src.loaders.parameter_handler - DEBUG - Created parameter set: {'general': {'max_keywords': 10, 'min_keyword_length': 3, 'language': 'en', 'focus_on': 'technical and business content', 'include_compounds': True, 'max_themes': 3, 'min_confidence': 0.3, 'column_name_to_analyze': 'content'}, 'categories': {'technical_content': {'description': 'Technical and software development content', 'keywords': ['software', 'development', 'api', 'programming', 'technical', 'code'], 'threshold': 0.6, 'parent': None}, 'business_content': {'description': 'Business and financial content', 'keywords': ['revenue', 'sales', 'market', 'growth', 'financial', 'business'], 'threshold': 0.6, 'parent': None}, 'educational_content': {'description': 'Educational and training content', 'keywords': ['learning', 'education', 'training', 'teaching', 'skills'], 'threshold': 0.5, 'parent': None}}, 'predefined_keywords': {'machine learning': {'importance': 1.0, 'domain': 'technical', 'compound_parts': []}, 'cloud computing': {'importance': 0.9, 'domain': 'technical', 'compound_parts': []}, 'revenue growth': {'importance': 0.9, 'domain': 'business', 'compound_parts': []}}, 'excluded_keywords': {'for', 'and', 'the'}, 'analysis_settings': {'theme_analysis': {'enabled': True, 'min_confidence': 0.5}, 'weights': {'statistical': 0.4, 'llm': 0.6}}, 'domain_context': {}}\n"
     ]
    }
   ],
   "source": [
    "# Create and load parameters\n",
    "params_file_name = \"parameters_en.xlsx\"\n",
    "\n",
    "# Get the full parameter file path\n",
    "params_file = get_parameter_file_path(params_file_name)\n",
    "\n",
    "# Create file if it doesn't exist\n",
    "if not params_file.exists():\n",
    "    params_file = create_example_parameters(params_file_name)\n",
    "    print(f\"Created parameter file at: {params_file}\")\n",
    "else:\n",
    "    print(f\"Using existing parameter file at: {params_file}\")\n",
    "\n",
    "# Verify the file\n",
    "verify_parameter_file(params_file)\n",
    "\n",
    "# Load parameters\n",
    "handler = ParameterHandler(params_file_name)  # Can now use just the file name\n",
    "params = handler.get_parameters()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Loaded parameters:\n",
      "ParameterSet(\n",
      "  general=max_keywords=10 min_keyword_length=3 language='en' focus_on='technical and business content' include_compounds=True max_themes=3 min_confidence=0.3 column_name_to_analyze='content',\n",
      "  categories=3 items,\n",
      "  predefined_keywords=3 items,\n",
      "  excluded_keywords=3 items,\n",
      "  analysis_settings=theme_analysis=ThemeAnalysisSettings(enabled=True, min_confidence=0.5) weights=AnalysisWeights(statistical=0.4, llm=0.6),\n",
      "  domain_context=0 items\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nLoaded parameters:\")\n",
    "# params.print()  # Uses the new print method\n",
    "\n",
    "# Or just\n",
    "print(params)  # Uses the new __str__ method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Not creating new example files.\n"
     ]
    }
   ],
   "source": [
    "# Create example files\n",
    "\n",
    "create_new_example_files=False\n",
    "\n",
    "if create_new_example_files:\n",
    "    en_params = create_example_parameters(\"parameters_en.xlsx\", \"en\")\n",
    "    fi_params = create_example_parameters(\"parameters_fi.xlsx\", \"fi\")\n",
    "    print(f\"Created parameter files:\\n- {en_params}\\n- {fi_params}\")\n",
    "    print(f\"Created parameter files:\\n- {en_params}\\n- {fi_params}\")\n",
    "else:\n",
    "    print(\"Not creating new example files.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter Validation:\n",
      "--------------------------------------------------\n",
      "\n",
      "Parameters validated successfully!\n"
     ]
    }
   ],
   "source": [
    "# Check parameter validation\n",
    "print(\"Parameter Validation:\")\n",
    "print(\"-\" * 50)\n",
    "is_valid, warnings, errors = handler.validate()\n",
    "if warnings:\n",
    "    print(\"\\nWarnings:\")\n",
    "    for warning in warnings:\n",
    "        print(f\"- {warning}\")\n",
    "if not is_valid:\n",
    "    print(\"\\nErrors:\")\n",
    "    for error in errors:\n",
    "        print(f\"- {error}\")\n",
    "else:\n",
    "    print(\"\\nParameters validated successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-18 12:27:41,566 - src.nb_helpers.analyzers - DEBUG - Starting keyword analysis\n",
      "2024-11-18 12:27:41,569 - src.utils.FileUtils.file_utils - DEBUG [file_utils.py:192] - Initialized FileUtils with log level: INFO\n",
      "2024-11-18 12:27:41,569 - src.utils.FileUtils.file_utils - DEBUG - Initialized FileUtils with log level: INFO\n",
      "2024-11-18 12:27:41,572 - src.utils.FileUtils.file_utils - DEBUG [file_utils.py:198] - Project root: c:\\Users\\tja\\OneDrive - Rastor-instituutti ry\\Tiedostot\\Rastor-instituutti\\kehittäminen\\analytiikka\\repos\\semantic-text-analyzer\n",
      "2024-11-18 12:27:41,572 - src.utils.FileUtils.file_utils - DEBUG - Project root: c:\\Users\\tja\\OneDrive - Rastor-instituutti ry\\Tiedostot\\Rastor-instituutti\\kehittäminen\\analytiikka\\repos\\semantic-text-analyzer\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Single Language Analysis:\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-18 12:27:41,581 - src.nb_helpers.analyzers - DEBUG - Initialized TextAnalyzer with options: AnalysisOptions(show_confidence=True, show_evidence=True, show_keywords=True, show_raw_data=True, debug_mode=True, language='en', parameter_file=None)\n",
      "2024-11-18 12:27:41,583 - src.core.language_processing.factory - DEBUG - Using default configuration\n",
      "2024-11-18 12:27:41,584 - src.core.language_processing.factory - DEBUG - Creating en processor\n",
      "2024-11-18 12:27:41,587 - src.utils.FileUtils.file_utils - DEBUG [file_utils.py:192] - Initialized FileUtils with log level: INFO\n",
      "2024-11-18 12:27:41,587 - src.utils.FileUtils.file_utils - DEBUG - Initialized FileUtils with log level: INFO\n",
      "2024-11-18 12:27:41,590 - src.utils.FileUtils.file_utils - DEBUG [file_utils.py:198] - Project root: c:\\Users\\tja\\OneDrive - Rastor-instituutti ry\\Tiedostot\\Rastor-instituutti\\kehittäminen\\analytiikka\\repos\\semantic-text-analyzer\n",
      "2024-11-18 12:27:41,590 - src.utils.FileUtils.file_utils - DEBUG - Project root: c:\\Users\\tja\\OneDrive - Rastor-instituutti ry\\Tiedostot\\Rastor-instituutti\\kehittäminen\\analytiikka\\repos\\semantic-text-analyzer\n",
      "2024-11-18 12:27:41,617 - src.core.language_processing.english - DEBUG - Loaded 179 NLTK stopwords\n",
      "2024-11-18 12:27:41,621 - src.core.language_processing.english - DEBUG - Loaded 733 additional stopwords from file\n",
      "2024-11-18 12:27:41,623 - src.core.language_processing.english - DEBUG - Total English stopwords: 831\n",
      "2024-11-18 12:27:41,624 - src.core.language_processing.english - DEBUG - Initialized English processor with 831 stopwords\n",
      "2024-11-18 12:27:43,313 - src.utils.FileUtils.file_utils - DEBUG [file_utils.py:192] - Initialized FileUtils with log level: INFO\n",
      "2024-11-18 12:27:43,313 - src.utils.FileUtils.file_utils - DEBUG - Initialized FileUtils with log level: INFO\n",
      "2024-11-18 12:27:43,315 - src.utils.FileUtils.file_utils - DEBUG [file_utils.py:198] - Project root: c:\\Users\\tja\\OneDrive - Rastor-instituutti ry\\Tiedostot\\Rastor-instituutti\\kehittäminen\\analytiikka\\repos\\semantic-text-analyzer\n",
      "2024-11-18 12:27:43,315 - src.utils.FileUtils.file_utils - DEBUG - Project root: c:\\Users\\tja\\OneDrive - Rastor-instituutti ry\\Tiedostot\\Rastor-instituutti\\kehittäminen\\analytiikka\\repos\\semantic-text-analyzer\n",
      "2024-11-18 12:27:43,326 - src.analyzers.keyword_analyzer - DEBUG - Initialized with weights: {'statistical': 0.4, 'llm': 0.6, 'compound_bonus': 0.2, 'domain_bonus': 0.15, 'length_factor': 0.1, 'generic_penalty': 0.3}\n",
      "2024-11-18 12:27:43,327 - src.analyzers.keyword_analyzer - DEBUG - Initialized with config: {'language': 'en', 'weights': {'statistical': 0.4, 'llm': 0.6}}\n",
      "2024-11-18 12:27:43,328 - src.nb_helpers.analyzers - DEBUG - Running keyword analysis\n",
      "2024-11-18 12:27:43,330 - src.nb_helpers.testers - DEBUG - KeywordTester starting analysis\n",
      "2024-11-18 12:27:43,333 - src.analyzers.keyword_analyzer - DEBUG - Starting keyword analysis\n",
      "2024-11-18 12:27:43,335 - src.analyzers.keyword_analyzer - DEBUG - Analyzing text of length 171\n",
      "2024-11-18 12:27:43,336 - src.analyzers.keyword_analyzer - DEBUG - Starting internal analysis\n",
      "2024-11-18 12:28:05,223 - src.core.language_processing.english - DEBUG - Found compound word 'improve' with parts: ['imp', 'rove']\n",
      "2024-11-18 12:28:05,229 - src.core.language_processing.english - DEBUG - Found compound word 'streamline' with parts: ['stream', 'line']\n",
      "2024-11-18 12:28:05,234 - src.core.language_processing.english - DEBUG - Found compound word 'pipeline' with parts: ['pipe', 'line']\n",
      "2024-11-18 12:28:05,276 - src.core.language_processing.english - DEBUG - Found compound word 'improve' with parts: ['imp', 'rove']\n",
      "2024-11-18 12:28:05,287 - src.core.language_processing.english - DEBUG - Found compound word 'streamline' with parts: ['stream', 'line']\n",
      "2024-11-18 12:28:05,293 - src.core.language_processing.english - DEBUG - Found compound word 'pipeline' with parts: ['pipe', 'line']\n",
      "2024-11-18 12:28:11,468 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-11-18 12:28:11,497 - src.analyzers.keyword_analyzer - DEBUG - Processing compound words\n",
      "2024-11-18 12:28:11,500 - src.core.language_processing.english - DEBUG - Found compound word 'improve' with parts: ['imp', 'rove']\n",
      "2024-11-18 12:28:11,501 - src.analyzers.keyword_analyzer - DEBUG - Found compound word: improve -> ['imp', 'rove']\n",
      "2024-11-18 12:28:11,507 - src.core.language_processing.english - DEBUG - Found compound word 'pipeline' with parts: ['pipe', 'line']\n",
      "2024-11-18 12:28:11,510 - src.analyzers.keyword_analyzer - DEBUG - Found compound word: pipeline -> ['pipe', 'line']\n",
      "2024-11-18 12:28:11,523 - src.core.language_processing.english - DEBUG - Found compound word 'streamlined' with parts: ['stream', 'line']\n",
      "2024-11-18 12:28:11,526 - src.analyzers.keyword_analyzer - DEBUG - Found compound word: streamlined -> ['stream', 'line']\n",
      "2024-11-18 12:28:11,530 - src.analyzers.keyword_analyzer - DEBUG - Calculating score for 'cloud' with base score 0.4\n",
      "2024-11-18 12:28:11,536 - src.analyzers.keyword_analyzer - DEBUG - Final score for 'cloud': 0.4\n",
      "2024-11-18 12:28:11,541 - src.analyzers.keyword_analyzer - DEBUG - Calculating score for 'migration' with base score 0.4\n",
      "2024-11-18 12:28:11,543 - src.analyzers.keyword_analyzer - DEBUG - Final score for 'migration': 0.4\n",
      "2024-11-18 12:28:11,546 - src.analyzers.keyword_analyzer - DEBUG - Calculating score for 'project' with base score 0.4\n",
      "2024-11-18 12:28:11,547 - src.analyzers.keyword_analyzer - DEBUG - Applied generic penalty (0.3) to 'project', new score: 0.27999999999999997\n",
      "2024-11-18 12:28:11,549 - src.analyzers.keyword_analyzer - DEBUG - Final score for 'project': 0.27999999999999997\n",
      "2024-11-18 12:28:11,551 - src.core.language_processing.english - DEBUG - Found compound word 'improve' with parts: ['imp', 'rove']\n",
      "2024-11-18 12:28:11,552 - src.analyzers.keyword_analyzer - DEBUG - Processing compound word: improve\n",
      "2024-11-18 12:28:11,555 - src.analyzers.keyword_analyzer - DEBUG - Found parts: ['imp', 'rove']\n",
      "2024-11-18 12:28:11,559 - src.analyzers.keyword_analyzer - DEBUG - Calculating score for 'improve' with base score 0.4\n",
      "2024-11-18 12:28:11,560 - src.analyzers.keyword_analyzer - DEBUG - Applied generic penalty (0.3) to 'improve', new score: 0.27999999999999997\n",
      "2024-11-18 12:28:11,562 - src.analyzers.keyword_analyzer - DEBUG - Applied compound boost (1.2) for 2 parts, new score: 0.33599999999999997\n",
      "2024-11-18 12:28:11,563 - src.analyzers.keyword_analyzer - DEBUG - Final score for 'improve': 0.33599999999999997\n",
      "2024-11-18 12:28:11,567 - src.analyzers.keyword_analyzer - DEBUG - Calculating score for 'system' with base score 0.4\n",
      "2024-11-18 12:28:11,568 - src.analyzers.keyword_analyzer - DEBUG - Applied generic penalty (0.3) to 'system', new score: 0.27999999999999997\n",
      "2024-11-18 12:28:11,570 - src.analyzers.keyword_analyzer - DEBUG - Final score for 'system': 0.27999999999999997\n",
      "2024-11-18 12:28:11,576 - src.analyzers.keyword_analyzer - DEBUG - Calculating score for 'scalability' with base score 0.4\n",
      "2024-11-18 12:28:11,578 - src.analyzers.keyword_analyzer - DEBUG - Final score for 'scalability': 0.4\n",
      "2024-11-18 12:28:11,580 - src.analyzers.keyword_analyzer - DEBUG - Calculating score for 'reduce' with base score 0.4\n",
      "2024-11-18 12:28:11,583 - src.analyzers.keyword_analyzer - DEBUG - Applied generic penalty (0.3) to 'reduce', new score: 0.27999999999999997\n",
      "2024-11-18 12:28:11,584 - src.analyzers.keyword_analyzer - DEBUG - Final score for 'reduce': 0.27999999999999997\n",
      "2024-11-18 12:28:11,586 - src.analyzers.keyword_analyzer - DEBUG - Calculating score for 'cost' with base score 0.4\n",
      "2024-11-18 12:28:11,588 - src.analyzers.keyword_analyzer - DEBUG - Final score for 'cost': 0.4\n",
      "2024-11-18 12:28:11,590 - src.analyzers.keyword_analyzer - DEBUG - Calculating score for 'devops' with base score 0.4\n",
      "2024-11-18 12:28:11,592 - src.analyzers.keyword_analyzer - DEBUG - Final score for 'devops': 0.4\n",
      "2024-11-18 12:28:11,597 - src.analyzers.keyword_analyzer - DEBUG - Calculating score for 'practice' with base score 0.4\n",
      "2024-11-18 12:28:11,599 - src.analyzers.keyword_analyzer - DEBUG - Final score for 'practice': 0.4\n",
      "2024-11-18 12:28:11,601 - src.analyzers.keyword_analyzer - DEBUG - Calculating score for 'cloud' with base score 0.97\n",
      "2024-11-18 12:28:11,602 - src.analyzers.keyword_analyzer - DEBUG - Applied domain boost (1.15) for 'technical', new score: 1.1155\n",
      "2024-11-18 12:28:11,603 - src.analyzers.keyword_analyzer - DEBUG - Final score for 'cloud': 1.0\n",
      "2024-11-18 12:28:11,609 - src.analyzers.keyword_analyzer - DEBUG - Calculating score for 'migration' with base score 0.9400000000000001\n",
      "2024-11-18 12:28:11,610 - src.analyzers.keyword_analyzer - DEBUG - Applied domain boost (1.15) for 'technical', new score: 1.081\n",
      "2024-11-18 12:28:11,612 - src.analyzers.keyword_analyzer - DEBUG - Final score for 'migration': 1.0\n",
      "2024-11-18 12:28:11,615 - src.analyzers.keyword_analyzer - DEBUG - Calculating score for 'project' with base score 0.79\n",
      "2024-11-18 12:28:11,616 - src.analyzers.keyword_analyzer - DEBUG - Applied generic penalty (0.3) to 'project', new score: 0.5529999999999999\n",
      "2024-11-18 12:28:11,618 - src.analyzers.keyword_analyzer - DEBUG - Applied domain boost (1.15) for 'business', new score: 0.6359499999999999\n",
      "2024-11-18 12:28:11,620 - src.analyzers.keyword_analyzer - DEBUG - Final score for 'project': 0.6359499999999999\n",
      "2024-11-18 12:28:11,631 - src.analyzers.keyword_analyzer - DEBUG - Calculating score for 'scalability' with base score 0.928\n",
      "2024-11-18 12:28:11,633 - src.analyzers.keyword_analyzer - DEBUG - Applied domain boost (1.15) for 'technical', new score: 1.0672\n",
      "2024-11-18 12:28:11,634 - src.analyzers.keyword_analyzer - DEBUG - Final score for 'scalability': 1.0\n",
      "2024-11-18 12:28:11,636 - src.analyzers.keyword_analyzer - DEBUG - Calculating score for 'costs' with base score 0.48\n",
      "2024-11-18 12:28:11,638 - src.analyzers.keyword_analyzer - DEBUG - Applied domain boost (1.15) for 'business', new score: 0.5519999999999999\n",
      "2024-11-18 12:28:11,640 - src.analyzers.keyword_analyzer - DEBUG - Final score for 'costs': 0.5519999999999999\n",
      "2024-11-18 12:28:11,642 - src.analyzers.keyword_analyzer - DEBUG - Processing compound word: DevOps\n",
      "2024-11-18 12:28:11,644 - src.analyzers.keyword_analyzer - DEBUG - Found parts: ['DevOps']\n",
      "2024-11-18 12:28:11,645 - src.analyzers.keyword_analyzer - DEBUG - Calculating score for 'DevOps' with base score 0.552\n",
      "2024-11-18 12:28:11,647 - src.analyzers.keyword_analyzer - DEBUG - Applied domain boost (1.15) for 'technical', new score: 0.6348\n",
      "2024-11-18 12:28:11,648 - src.analyzers.keyword_analyzer - DEBUG - Final score for 'DevOps': 0.6348\n",
      "2024-11-18 12:28:11,658 - src.analyzers.keyword_analyzer - DEBUG - Calculating score for 'practices' with base score 0.44999999999999996\n",
      "2024-11-18 12:28:11,660 - src.analyzers.keyword_analyzer - DEBUG - Applied domain boost (1.15) for 'business', new score: 0.5175\n",
      "2024-11-18 12:28:11,662 - src.analyzers.keyword_analyzer - DEBUG - Final score for 'practices': 0.5175\n",
      "2024-11-18 12:28:11,667 - src.analyzers.keyword_analyzer - DEBUG - Calculating score for 'deployment' with base score 0.522\n",
      "2024-11-18 12:28:11,669 - src.analyzers.keyword_analyzer - DEBUG - Term 'deployment' contains domain-specific parts\n",
      "2024-11-18 12:28:11,676 - src.analyzers.keyword_analyzer - DEBUG - Applied domain boost (1.15) for 'technical', new score: 0.6003\n",
      "2024-11-18 12:28:11,681 - src.analyzers.keyword_analyzer - DEBUG - Final score for 'deployment': 0.6003\n",
      "2024-11-18 12:28:11,694 - src.core.language_processing.english - DEBUG - Found compound word 'pipeline' with parts: ['pipe', 'line']\n",
      "2024-11-18 12:28:11,705 - src.analyzers.keyword_analyzer - DEBUG - Processing compound word: pipeline\n",
      "2024-11-18 12:28:11,708 - src.analyzers.keyword_analyzer - DEBUG - Found parts: ['pipe', 'line']\n",
      "2024-11-18 12:28:11,710 - src.analyzers.keyword_analyzer - DEBUG - Calculating score for 'pipeline' with base score 0.49799999999999994\n",
      "2024-11-18 12:28:11,713 - src.analyzers.keyword_analyzer - DEBUG - Applied domain boost (1.15) for 'technical', new score: 0.5726999999999999\n",
      "2024-11-18 12:28:11,717 - src.analyzers.keyword_analyzer - DEBUG - Applied compound boost (1.2) for 2 parts, new score: 0.6872399999999999\n",
      "2024-11-18 12:28:11,719 - src.analyzers.keyword_analyzer - DEBUG - Final score for 'pipeline': 0.6872399999999999\n",
      "2024-11-18 12:28:11,722 - src.core.language_processing.english - DEBUG - Found compound word 'streamlined' with parts: ['stream', 'line']\n",
      "2024-11-18 12:28:11,724 - src.analyzers.keyword_analyzer - DEBUG - Processing compound word: streamlined\n",
      "2024-11-18 12:28:11,728 - src.analyzers.keyword_analyzer - DEBUG - Found parts: ['stream', 'line']\n",
      "2024-11-18 12:28:11,730 - src.analyzers.keyword_analyzer - DEBUG - Calculating score for 'streamlined' with base score 0.46799999999999997\n",
      "2024-11-18 12:28:11,732 - src.analyzers.keyword_analyzer - DEBUG - Applied domain boost (1.15) for 'business', new score: 0.5381999999999999\n",
      "2024-11-18 12:28:11,734 - src.analyzers.keyword_analyzer - DEBUG - Applied compound boost (1.2) for 2 parts, new score: 0.6458399999999999\n",
      "2024-11-18 12:28:11,736 - src.analyzers.keyword_analyzer - DEBUG - Final score for 'streamlined': 0.6458399999999999\n",
      "2024-11-18 12:28:11,742 - src.core.language_processing.english - DEBUG - Found compound word 'improve' with parts: ['imp', 'rove']\n",
      "2024-11-18 12:28:11,776 - src.core.language_processing.english - DEBUG - Found compound word 'pipeline' with parts: ['pipe', 'line']\n",
      "2024-11-18 12:28:11,782 - src.core.language_processing.english - DEBUG - Found compound word 'streamlined' with parts: ['stream', 'line']\n",
      "2024-11-18 12:28:11,791 - src.core.language_processing.english - DEBUG - Found compound word 'improve' with parts: ['imp', 'rove']\n",
      "2024-11-18 12:28:11,832 - src.core.language_processing.english - DEBUG - Found compound word 'pipeline' with parts: ['pipe', 'line']\n",
      "2024-11-18 12:28:11,838 - src.core.language_processing.english - DEBUG - Found compound word 'streamlined' with parts: ['stream', 'line']\n",
      "2024-11-18 12:28:11,843 - src.core.language_processing.english - DEBUG - Found compound word 'improve' with parts: ['imp', 'rove']\n",
      "2024-11-18 12:28:11,864 - src.core.language_processing.english - DEBUG - Found compound word 'pipeline' with parts: ['pipe', 'line']\n",
      "2024-11-18 12:28:11,869 - src.core.language_processing.english - DEBUG - Found compound word 'streamlined' with parts: ['stream', 'line']\n",
      "2024-11-18 12:28:11,872 - src.core.language_processing.english - DEBUG - Found compound word 'improve' with parts: ['imp', 'rove']\n",
      "2024-11-18 12:28:11,875 - src.core.language_processing.english - DEBUG - Found compound word 'improve' with parts: ['imp', 'rove']\n",
      "2024-11-18 12:28:11,880 - src.core.language_processing.english - DEBUG - Found compound word 'improve' with parts: ['imp', 'rove']\n",
      "2024-11-18 12:28:11,885 - src.core.language_processing.english - DEBUG - Found compound word 'improve' with parts: ['imp', 'rove']\n",
      "2024-11-18 12:28:11,887 - src.core.language_processing.english - DEBUG - Found compound word 'improve' with parts: ['imp', 'rove']\n",
      "2024-11-18 12:28:11,889 - src.core.language_processing.english - DEBUG - Found compound word 'improve' with parts: ['imp', 'rove']\n",
      "2024-11-18 12:28:11,893 - src.core.language_processing.english - DEBUG - Found compound word 'improve' with parts: ['imp', 'rove']\n",
      "2024-11-18 12:28:11,895 - src.core.language_processing.english - DEBUG - Found compound word 'improve' with parts: ['imp', 'rove']\n",
      "2024-11-18 12:28:11,899 - src.core.language_processing.english - DEBUG - Found compound word 'improve' with parts: ['imp', 'rove']\n",
      "2024-11-18 12:28:11,902 - src.core.language_processing.english - DEBUG - Found compound word 'improve' with parts: ['imp', 'rove']\n",
      "2024-11-18 12:28:11,906 - src.core.language_processing.english - DEBUG - Found compound word 'improve' with parts: ['imp', 'rove']\n",
      "2024-11-18 12:28:11,908 - src.core.language_processing.english - DEBUG - Found compound word 'pipeline' with parts: ['pipe', 'line']\n",
      "2024-11-18 12:28:11,911 - src.core.language_processing.english - DEBUG - Found compound word 'improve' with parts: ['imp', 'rove']\n",
      "2024-11-18 12:28:11,916 - src.core.language_processing.english - DEBUG - Found compound word 'streamlined' with parts: ['stream', 'line']\n",
      "2024-11-18 12:28:11,935 - src.core.language_processing.english - DEBUG - Found compound word 'pipeline' with parts: ['pipe', 'line']\n",
      "2024-11-18 12:28:11,938 - src.core.language_processing.english - DEBUG - Found compound word 'streamlined' with parts: ['stream', 'line']\n",
      "2024-11-18 12:28:11,973 - src.core.language_processing.english - DEBUG - Found compound word 'pipeline' with parts: ['pipe', 'line']\n",
      "2024-11-18 12:28:11,980 - src.core.language_processing.english - DEBUG - Found compound word 'streamlined' with parts: ['stream', 'line']\n",
      "2024-11-18 12:28:11,993 - src.core.language_processing.english - DEBUG - Found compound word 'pipeline' with parts: ['pipe', 'line']\n",
      "2024-11-18 12:28:11,997 - src.core.language_processing.english - DEBUG - Found compound word 'streamlined' with parts: ['stream', 'line']\n",
      "2024-11-18 12:28:12,011 - src.core.language_processing.english - DEBUG - Found compound word 'pipeline' with parts: ['pipe', 'line']\n",
      "2024-11-18 12:28:12,016 - src.core.language_processing.english - DEBUG - Found compound word 'streamlined' with parts: ['stream', 'line']\n",
      "2024-11-18 12:28:12,026 - src.core.language_processing.english - DEBUG - Found compound word 'pipeline' with parts: ['pipe', 'line']\n",
      "2024-11-18 12:28:12,030 - src.core.language_processing.english - DEBUG - Found compound word 'streamlined' with parts: ['stream', 'line']\n",
      "2024-11-18 12:28:12,041 - src.core.language_processing.english - DEBUG - Found compound word 'pipeline' with parts: ['pipe', 'line']\n",
      "2024-11-18 12:28:12,046 - src.core.language_processing.english - DEBUG - Found compound word 'streamlined' with parts: ['stream', 'line']\n",
      "2024-11-18 12:28:12,054 - src.core.language_processing.english - DEBUG - Found compound word 'pipeline' with parts: ['pipe', 'line']\n",
      "2024-11-18 12:28:12,059 - src.core.language_processing.english - DEBUG - Found compound word 'streamlined' with parts: ['stream', 'line']\n",
      "2024-11-18 12:28:12,063 - src.core.language_processing.english - DEBUG - Found compound word 'pipeline' with parts: ['pipe', 'line']\n",
      "2024-11-18 12:28:12,070 - src.core.language_processing.english - DEBUG - Found compound word 'streamlined' with parts: ['stream', 'line']\n",
      "2024-11-18 12:28:12,074 - src.analyzers.keyword_analyzer - DEBUG - Added compound parts for pipeline: ['pipe', 'line']\n",
      "2024-11-18 12:28:12,076 - src.analyzers.keyword_analyzer - DEBUG - Added compound parts for streamlined: ['stream', 'line']\n",
      "2024-11-18 12:28:12,078 - src.analyzers.keyword_analyzer - DEBUG - Found 3 compound words\n",
      "2024-11-18 12:28:12,080 - src.analyzers.keyword_analyzer - DEBUG - Analysis complete. Found 10 keywords\n",
      "2024-11-18 12:28:12,083 - src.nb_helpers.testers - DEBUG - KeywordTester analysis complete\n",
      "2024-11-18 12:28:12,085 - src.nb_helpers.analyzers - DEBUG - Keyword analysis completed\n",
      "2024-11-18 12:28:12,086 - src.nb_helpers.analyzers - DEBUG - Formatting results\n",
      "2024-11-18 12:28:12,089 - src.nb_helpers.analyzers - DEBUG - Displaying debug information\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Keywords Found:\n",
      "  • cloud                [████████████████████] (1.00)\n",
      "  • migration            [████████████████████] (1.00)\n",
      "  • scalability          [████████████████████] (1.00)\n",
      "  • pipeline             [████████████████░░░░] (0.82)\n",
      "  • streamlined          [███████████████░░░░░] (0.78)\n",
      "  • project              [███████████████░░░░░] (0.76)\n",
      "  • DevOps               [███████████████░░░░░] (0.76)\n",
      "  • deployment           [██████████████░░░░░░] (0.72)\n",
      "  • costs                [█████████████░░░░░░░] (0.66)\n",
      "  • practices            [████████████░░░░░░░░] (0.62)\n",
      "\n",
      "Debug Information:\n",
      "--------------------\n",
      "{\n",
      "  \"keywords\": [\n",
      "    {\n",
      "      \"keyword\": \"cloud\",\n",
      "      \"score\": 1.0,\n",
      "      \"domain\": \"technical\",\n",
      "      \"compound_parts\": null\n",
      "    },\n",
      "    {\n",
      "      \"keyword\": \"migration\",\n",
      "      \"score\": 1.0,\n",
      "      \"domain\": \"technical\",\n",
      "      \"compound_parts\": null\n",
      "    },\n",
      "    {\n",
      "      \"keyword\": \"scalability\",\n",
      "      \"score\": 1.0,\n",
      "      \"domain\": \"technical\",\n",
      "      \"compound_parts\": null\n",
      "    },\n",
      "    {\n",
      "      \"keyword\": \"pipeline\",\n",
      "      \"score\": 0.8246879999999998,\n",
      "      \"domain\": \"technical\",\n",
      "      \"compound_parts\": [\n",
      "        \"pipe\",\n",
      "        \"line\"\n",
      "      ]\n",
      "    },\n",
      "    {\n",
      "      \"keyword\": \"streamlined\",\n",
      "      \"score\": 0.7750079999999998,\n",
      "      \"domain\": \"business\",\n",
      "      \"compound_parts\": [\n",
      "        \"stream\",\n",
      "        \"line\"\n",
      "      ]\n",
      "    },\n",
      "    {\n",
      "      \"keyword\": \"project\",\n",
      "      \"score\": 0.7631399999999998,\n",
      "      \"domain\": \"business\",\n",
      "      \"compound_parts\": null\n",
      "    },\n",
      "    {\n",
      "      \"keyword\": \"DevOps\",\n",
      "      \"score\": 0.76176,\n",
      "      \"domain\": \"technical\",\n",
      "      \"compound_parts\": null\n",
      "    },\n",
      "    {\n",
      "      \"keyword\": \"deployment\",\n",
      "      \"score\": 0.7203599999999999,\n",
      "      \"domain\": \"technical\",\n",
      "      \"compound_parts\": null\n",
      "    },\n",
      "    {\n",
      "      \"keyword\": \"costs\",\n",
      "      \"score\": 0.6623999999999999,\n",
      "      \"domain\": \"business\",\n",
      "      \"compound_parts\": null\n",
      "    },\n",
      "    {\n",
      "      \"keyword\": \"practices\",\n",
      "      \"score\": 0.6209999999999999,\n",
      "      \"domain\": \"business\",\n",
      "      \"compound_parts\": null\n",
      "    }\n",
      "  ],\n",
      "  \"compound_words\": [],\n",
      "  \"domain_keywords\": {\n",
      "    \"technical\": [\n",
      "      \"cloud\",\n",
      "      \"migration\",\n",
      "      \"scalability\",\n",
      "      \"pipeline\",\n",
      "      \"DevOps\",\n",
      "      \"deployment\"\n",
      "    ],\n",
      "    \"business\": [\n",
      "      \"streamlined\",\n",
      "      \"project\",\n",
      "      \"costs\",\n",
      "      \"practices\"\n",
      "    ]\n",
      "  },\n",
      "  \"language\": \"en\",\n",
      "  \"success\": true,\n",
      "  \"error\": null\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "# 2. Test single language analysis\n",
    "print(\"\\nSingle Language Analysis:\")\n",
    "print(\"-\" * 50)\n",
    "\n",
    "options_en = AnalysisOptions(\n",
    "    show_confidence=True,\n",
    "    show_evidence=True,\n",
    "    show_keywords=True,\n",
    "    show_raw_data=True,\n",
    "    debug_mode=True,\n",
    "    language=\"en\"  # Explicitly set language\n",
    ")\n",
    "\n",
    "# Analyze English text\n",
    "text = example_texts[\"English Technical\"]\n",
    "results_en = await analyze_keywords(text, options_en)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-18 12:14:21,075 - src.nb_helpers.analyzers - DEBUG - Starting keyword analysis\n",
      "2024-11-18 12:14:21,078 - src.utils.FileUtils.file_utils - DEBUG [file_utils.py:192] - Initialized FileUtils with log level: INFO\n",
      "2024-11-18 12:14:21,078 - src.utils.FileUtils.file_utils - DEBUG - Initialized FileUtils with log level: INFO\n",
      "2024-11-18 12:14:21,082 - src.utils.FileUtils.file_utils - DEBUG [file_utils.py:198] - Project root: c:\\Users\\tja\\OneDrive - Rastor-instituutti ry\\Tiedostot\\Rastor-instituutti\\kehittäminen\\analytiikka\\repos\\semantic-text-analyzer\n",
      "2024-11-18 12:14:21,082 - src.utils.FileUtils.file_utils - DEBUG - Project root: c:\\Users\\tja\\OneDrive - Rastor-instituutti ry\\Tiedostot\\Rastor-instituutti\\kehittäminen\\analytiikka\\repos\\semantic-text-analyzer\n",
      "2024-11-18 12:14:21,088 - src.nb_helpers.analyzers - DEBUG - Initialized TextAnalyzer with options: AnalysisOptions(show_confidence=True, show_evidence=True, show_keywords=True, show_raw_data=True, debug_mode=True, language='fi', parameter_file=None)\n",
      "2024-11-18 12:14:21,092 - src.utils.FileUtils.file_utils - DEBUG [file_utils.py:192] - Initialized FileUtils with log level: INFO\n",
      "2024-11-18 12:14:21,092 - src.utils.FileUtils.file_utils - DEBUG - Initialized FileUtils with log level: INFO\n",
      "2024-11-18 12:14:21,094 - src.utils.FileUtils.file_utils - DEBUG [file_utils.py:198] - Project root: c:\\Users\\tja\\OneDrive - Rastor-instituutti ry\\Tiedostot\\Rastor-instituutti\\kehittäminen\\analytiikka\\repos\\semantic-text-analyzer\n",
      "2024-11-18 12:14:21,094 - src.utils.FileUtils.file_utils - DEBUG - Project root: c:\\Users\\tja\\OneDrive - Rastor-instituutti ry\\Tiedostot\\Rastor-instituutti\\kehittäminen\\analytiikka\\repos\\semantic-text-analyzer\n",
      "2024-11-18 12:14:21,104 - src.core.language_processing.factory - DEBUG - Using default configuration\n",
      "2024-11-18 12:14:21,105 - src.core.language_processing.factory - DEBUG - Creating fi processor\n",
      "2024-11-18 12:14:21,112 - src.utils.FileUtils.file_utils - DEBUG [file_utils.py:192] - Initialized FileUtils with log level: INFO\n",
      "2024-11-18 12:14:21,112 - src.utils.FileUtils.file_utils - DEBUG - Initialized FileUtils with log level: INFO\n",
      "2024-11-18 12:14:21,115 - src.utils.FileUtils.file_utils - DEBUG [file_utils.py:198] - Project root: c:\\Users\\tja\\OneDrive - Rastor-instituutti ry\\Tiedostot\\Rastor-instituutti\\kehittäminen\\analytiikka\\repos\\semantic-text-analyzer\n",
      "2024-11-18 12:14:21,115 - src.utils.FileUtils.file_utils - DEBUG - Project root: c:\\Users\\tja\\OneDrive - Rastor-instituutti ry\\Tiedostot\\Rastor-instituutti\\kehittäminen\\analytiikka\\repos\\semantic-text-analyzer\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test Finnish keyword analysis:\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-18 12:14:21,148 - src.core.language_processing.finnish - INFO - Loaded 747 stopwords from c:\\Users\\tja\\OneDrive - Rastor-instituutti ry\\Tiedostot\\Rastor-instituutti\\kehittäminen\\analytiikka\\repos\\semantic-text-analyzer\\data\\configurations\\stop_words\\fi.txt\n",
      "2024-11-18 12:14:21,161 - src.core.language_processing.finnish - DEBUG - Added 27 technical stopwords\n",
      "2024-11-18 12:14:21,164 - src.core.language_processing.finnish - DEBUG - Total Finnish stopwords: 774\n",
      "2024-11-18 12:14:21,166 - src.core.language_processing.finnish - INFO - Detected platform: win32\n",
      "2024-11-18 12:14:21,169 - src.core.language_processing.finnish - DEBUG - Could not initialize Voikko using system libraries: Could not find module 'libvoikko-1.dll' (or one of its dependencies). Try using the full path with constructor syntax.\n",
      "Exception ignored in: <function Voikko.__del__ at 0x0000011D69E375E0>\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\tja\\AppData\\Local\\miniconda3\\envs\\semantic-analyzer\\lib\\site-packages\\libvoikko.py\", line 446, in __del__\n",
      "    self.terminate()\n",
      "  File \"c:\\Users\\tja\\AppData\\Local\\miniconda3\\envs\\semantic-analyzer\\lib\\site-packages\\libvoikko.py\", line 476, in terminate\n",
      "    if self.__handle:\n",
      "AttributeError: 'Voikko' object has no attribute '_Voikko__handle'\n",
      "2024-11-18 12:14:21,268 - src.core.language_processing.finnish - INFO - Added C:\\scripts\\Voikko to DLL search path\n",
      "2024-11-18 12:14:21,270 - src.core.language_processing.finnish - INFO - Verifying Voikko installation...\n",
      "2024-11-18 12:14:21,272 - src.core.language_processing.finnish - INFO - DLL exists: True (C:\\scripts\\Voikko\\libvoikko-1.dll)\n",
      "2024-11-18 12:14:21,273 - src.core.language_processing.finnish - INFO - Found dictionary version 5 at: C:\\scripts\\Voikko\\voikko\\5\\mor-standard\n",
      "2024-11-18 12:14:21,398 - src.core.language_processing.finnish - INFO - Successfully initialized Voikko with path: C:\\scripts\\Voikko\n",
      "2024-11-18 12:14:21,400 - src.nb_helpers.analyzers - ERROR - Analysis failed: __init__() got an unexpected keyword argument 'language_processor'\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\tja\\OneDrive - Rastor-instituutti ry\\Tiedostot\\Rastor-instituutti\\kehittäminen\\analytiikka\\repos\\semantic-text-analyzer\\src\\nb_helpers\\analyzers.py\", line 122, in analyze_keywords\n",
      "    tester = KeywordTester(\n",
      "  File \"C:\\Users\\tja\\OneDrive - Rastor-instituutti ry\\Tiedostot\\Rastor-instituutti\\kehittäminen\\analytiikka\\repos\\semantic-text-analyzer\\src\\nb_helpers\\testers.py\", line 41, in __init__\n",
      "    super().__init__(*args, **kwargs)\n",
      "TypeError: __init__() got an unexpected keyword argument 'language_processor'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Debug Information:\n",
      "--------------------\n",
      "{\n",
      "  \"error\": \"__init__() got an unexpected keyword argument 'language_processor'\",\n",
      "  \"success\": false\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "# Test Finnish keyword analysis\n",
    "print(\"\\nTest Finnish keyword analysis:\")\n",
    "print(\"-\" * 50)\n",
    "\n",
    "options_fi = AnalysisOptions(\n",
    "    show_confidence=True,\n",
    "    show_evidence=True,\n",
    "    debug_mode=True,\n",
    "    language=\"fi\"  # Explicitly set language\n",
    ")\n",
    "\n",
    "# Analyze Finnish text with auto-detection\n",
    "text = example_texts[\"Finnish Technical\"]\n",
    "# results_fi = await analyze_text(text, options_fi)\n",
    "keywords_fi = await analyze_keywords(text, options_fi)\n",
    "\n",
    "\n",
    "# # 4. Test batch analysis with mixed languages\n",
    "# print(\"\\nBatch Analysis with Mixed Languages:\")\n",
    "# print(\"-\" * 50)\n",
    "\n",
    "# batch_results = {}\n",
    "# for name, text in example_texts.items():\n",
    "#     print(f\"\\nAnalyzing {name}:\")\n",
    "#     results = await analyze_text(text, options_auto)\n",
    "#     batch_results[name] = results\n",
    "\n",
    "# # 5. Test Excel file processing\n",
    "# from src.nb_helpers.analyzers import analyze_excel_content\n",
    "\n",
    "# # Create a test DataFrame\n",
    "# import pandas as pd\n",
    "# df = pd.DataFrame({\n",
    "#     \"content\": example_texts.values(),\n",
    "#     \"type\": [name.split()[0] for name in example_texts.keys()],  # \"English\" or \"Finnish\"\n",
    "# })\n",
    "\n",
    "# # Save to temporary Excel file\n",
    "# temp_excel = \"temp_test_content.xlsx\"\n",
    "# df.to_excel(temp_excel, index=False)\n",
    "\n",
    "# print(\"\\nExcel File Analysis:\")\n",
    "# print(\"-\" * 50)\n",
    "\n",
    "# await analyze_excel_content(\n",
    "#     input_file=temp_excel,\n",
    "#     output_file=\"analysis_results\",\n",
    "#     content_column=\"content\",\n",
    "#     parameter_file=\"parameters_en.xlsx\",  # Use our parameter file\n",
    "#     language_column=\"type\"  # Use type column for language\n",
    "# )\n",
    "\n",
    "# # Clean up temporary file\n",
    "# os.remove(temp_excel)\n",
    "\n",
    "# # 6. Compare analysis results\n",
    "# print(\"\\nAnalysis Results Comparison:\")\n",
    "# print(\"-\" * 50)\n",
    "\n",
    "# def print_analysis_summary(results: dict, name: str):\n",
    "#     print(f\"\\n{name}:\")\n",
    "#     if \"keywords\" in results:\n",
    "#         keywords = results[\"keywords\"].get(\"keywords\", [])\n",
    "#         print(f\"Keywords found: {len(keywords)}\")\n",
    "#         for kw in keywords[:3]:  # Show top 3 keywords\n",
    "#             print(f\"- {kw.keyword}: {kw.score:.2f}\")\n",
    "    \n",
    "#     if \"themes\" in results:\n",
    "#         themes = results[\"themes\"].get(\"themes\", [])\n",
    "#         print(f\"Themes found: {len(themes)}\")\n",
    "#         for theme in themes[:2]:  # Show top 2 themes\n",
    "#             print(f\"- {theme.name}: {theme.confidence:.2f}\")\n",
    "            \n",
    "#     if \"categories\" in results:\n",
    "#         categories = results[\"categories\"].get(\"categories\", [])\n",
    "#         print(f\"Categories found: {len(categories)}\")\n",
    "#         for cat in categories[:2]:  # Show top 2 categories\n",
    "#             print(f\"- {cat.name}: {cat.confidence:.2f}\")\n",
    "\n",
    "# for name, results in batch_results.items():\n",
    "#     print_analysis_summary(results, name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run environment verification\n",
    "# from src.nb_helpers.environment import verify_environment\n",
    "# verify_environment()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-18 12:14:21,524 - src.analyzers.keyword_analyzer - DEBUG - Testing keyword analyzer logging\n"
     ]
    }
   ],
   "source": [
    "# Test logging\n",
    "logger = logging.getLogger(\"src.analyzers.keyword_analyzer\")\n",
    "logger.debug(\"Testing keyword analyzer logging\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NOTE: following are not working with the new parameter handling model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example texts in different languages\n",
    "example_texts = {\n",
    "    \"English Technical\": \"\"\"\n",
    "        The cloud migration project improved system scalability while reducing costs.\n",
    "        New DevOps practices streamlined the deployment pipeline significantly.\n",
    "    \"\"\",\n",
    "    \n",
    "    \"Finnish Technical\": \"\"\"\n",
    "        Pilvipalveluihin siirtyminen paransi järjestelmän skaalautuvuutta ja vähensi kustannuksia.\n",
    "        Uudet DevOps-käytännöt tehostivat merkittävästi käyttöönottoprosessia.\n",
    "    \"\"\"\n",
    "}\n",
    "\n",
    "# Analyze with automatic language detection\n",
    "for name, text in example_texts.items():\n",
    "    print(f\"\\nAnalyzing {name}:\")\n",
    "    results = await analyze_text(text, options)\n",
    "\n",
    "# Example with specific language and parameters\n",
    "fi_options = AnalysisOptions(\n",
    "    show_confidence=True,\n",
    "    show_evidence=True,\n",
    "    debug_mode=True,\n",
    "    language=\"fi\",\n",
    "    parameter_file=\"finnish_params.yaml\"\n",
    ")\n",
    "\n",
    "# Analyze Finnish text with specific parameters\n",
    "fi_results = await analyze_text(example_texts[\"Finnish Technical\"], fi_options)\n",
    "\n",
    "# Batch process Excel file with language detection\n",
    "await analyze_excel_content(\n",
    "    input_file=\"multilingual_texts.xlsx\",\n",
    "    output_file=\"analysis_results\",\n",
    "    content_column=\"content\",\n",
    "    parameter_file=\"analysis_params.yaml\",\n",
    "    language_column=\"language\"  # Optional column specifying language\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!-- ## Analysis Functions\n",
    "\n",
    "### Single Analysis with Debug Output\n",
    "Run detailed analysis for a single text: -->\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "example_texts = {\n",
    "    \"Business Analysis\": \"\"\"\n",
    "        Q3 revenue increased by 15% with strong growth in enterprise sales.\n",
    "        Customer retention improved while acquisition costs decreased.\n",
    "        New market expansion initiatives are showing positive early results.\n",
    "    \"\"\",\n",
    "    \n",
    "    \"Technical Content\": \"\"\"\n",
    "        The application uses microservices architecture with containerized deployments.\n",
    "        Data processing pipeline incorporates machine learning models for prediction.\n",
    "        System monitoring ensures high availability and performance metrics.\n",
    "    \"\"\",\n",
    "    \n",
    "    \"Mixed Content\": \"\"\"\n",
    "        The IT department's cloud migration project reduced infrastructure costs by 25%.\n",
    "        DevOps implementation improved deployment frequency while maintaining quality.\n",
    "        Monthly recurring revenue from SaaS products grew steadily.\n",
    "    \"\"\",\n",
    "    \"koulutus\":\n",
    "    \"\"\"\n",
    "        Verkko-oppimisalusta sisältää interaktiivisia moduuleja ja oman tahdin edistymisen seurannan. \n",
    "        Virtuaaliluokat mahdollistavat reaaliaikaisen yhteistyön opiskelijoiden ja ohjaajien välillä. \n",
    "        Digitaaliset arviointityökalut antavat välitöntä palautetta oppimistuloksista.\n",
    "    \"\"\",\n",
    "    \"tekninen\":\n",
    "    \"\"\"\n",
    "        Koneoppimismalleja koulutetaan suurilla datajoukolla tunnistamaan kaavoja. \n",
    "        Neuroverkon arkkitehtuuri sisältää useita kerroksia piirteiden erottamiseen. \n",
    "        Datan esikäsittely ja piirteiden suunnittelu ovat keskeisiä vaiheita prosessissa.\n",
    "\n",
    "    \"\"\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # New imports\n",
    "# from src.core.language_parameters import LanguageParameterManager\n",
    "\n",
    "# # Initialize parameter manager\n",
    "# param_manager = LanguageParameterManager()\n",
    "\n",
    "# # Example analysis with automatic language detection\n",
    "# text_en = \"Cloud computing enables scalable infrastructure deployment.\"\n",
    "# text_fi = \"Pilvipalvelut mahdollistavat skaalautuvan infrastruktuurin käyttöönoton.\"\n",
    "\n",
    "# # Analyze with automatic language detection and default parameters\n",
    "# async def analyze_text_with_language(text: str, parameter_file: Optional[str] = None):\n",
    "#     \"\"\"Analyze text with automatic language handling.\"\"\"\n",
    "#     # Get language-specific parameters\n",
    "#     params = param_manager.get_parameters(text, parameter_file)\n",
    "    \n",
    "#     # Create analyzers with parameters\n",
    "#     keyword_analyzer = KeywordAnalyzer(config=params.dict())\n",
    "#     theme_analyzer = ThemeAnalyzer(config=params.dict())\n",
    "#     category_analyzer = CategoryAnalyzer(config=params.dict())\n",
    "    \n",
    "#     # Run analysis\n",
    "#     results = {\n",
    "#         \"keywords\": await keyword_analyzer.analyze(text),\n",
    "#         \"themes\": await theme_analyzer.analyze(text),\n",
    "#         \"categories\": await category_analyzer.analyze(text)\n",
    "#     }\n",
    "    \n",
    "#     return results\n",
    "\n",
    "# # Example with Excel parameters\n",
    "# async def analyze_batch_with_excel_params(texts: List[str], excel_params: str):\n",
    "#     \"\"\"Analyze texts using parameters from Excel.\"\"\"\n",
    "#     # Load language-specific parameters\n",
    "#     params_by_lang = param_manager.load_excel_parameters(excel_params)\n",
    "    \n",
    "#     results = []\n",
    "#     for text in texts:\n",
    "#         # Detect language\n",
    "#         lang = param_manager.detect_language(text)\n",
    "#         # Get parameters for language\n",
    "#         params = params_by_lang.get(lang, param_manager.get_parameters(text))\n",
    "        \n",
    "#         # Create analyzer with language-specific parameters\n",
    "#         analyzer = KeywordAnalyzer(config=params.dict())\n",
    "#         result = await analyzer.analyze(text)\n",
    "#         results.append(result)\n",
    "    \n",
    "#     return results\n",
    "\n",
    "# # Example usage:\n",
    "# # With default parameters\n",
    "# results_en = await analyze_text_with_language(text_en)\n",
    "\n",
    "# # With parameter file\n",
    "# results_fi = await analyze_text_with_language(text_fi, \"finnish_params.yaml\")\n",
    "\n",
    "# # With Excel parameters\n",
    "# texts = [text_en, text_fi]\n",
    "# batch_results = await analyze_batch_with_excel_params(texts, \"analysis_params.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# text = example_texts[\"Mixed Content\"]\n",
    "# text = example_texts[\"koulutussisältö\"]\n",
    "# Debug specific analyzer\n",
    "\n",
    "# Example usage\n",
    "text = example_texts[\"Mixed Content\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'options' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[12], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mawait\u001b[39;00m analyze_keywords(text, options\u001b[38;5;241m=\u001b[39moptions)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'options' is not defined"
     ]
    }
   ],
   "source": [
    "await analyze_keywords(text, options=options)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Debug Theme Analysis\n",
      "==================================================\n",
      "\n",
      "Input Text:\n",
      "--------------------\n",
      "The IT department's cloud migration project reduced infrastructure costs by 25%.\n",
      "        DevOps implementation improved deployment frequency while maintaining quality.\n",
      "        Monthly recurring revenue from SaaS products grew steadily.\n",
      "\n",
      "Running Analysis...\n",
      "--------------------\n"
     ]
    }
   ],
   "source": [
    "await analyze_themes(text, options=options)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Debug Category Analysis\n",
      "==================================================\n",
      "\n",
      "Input Text:\n",
      "--------------------\n",
      "The IT department's cloud migration project reduced infrastructure costs by 25%.\n",
      "        DevOps implementation improved deployment frequency while maintaining quality.\n",
      "        Monthly recurring revenue from SaaS products grew steadily.\n",
      "\n",
      "Running Analysis...\n",
      "--------------------\n",
      "\n",
      "Categories Found:\n",
      "\n",
      "  • technical\n",
      "    Confidence: [█████████████████░░░] (0.85)\n",
      "    The text discusses a cloud migration project and DevOps implementation, both of which are technical processes related to software development and system management.\n",
      "    Evidence:\n",
      "      - cloud migration project\n",
      "      - DevOps implementation\n",
      "      - improved deployment frequency\n",
      "\n",
      "  • business\n",
      "    Confidence: [███████████████░░░░░] (0.75)\n",
      "    The text mentions reduced infrastructure costs and growth in monthly recurring revenue, which are key indicators of business performance and financial health.\n",
      "    Evidence:\n",
      "      - reduced infrastructure costs by 25%\n",
      "      - monthly recurring revenue from SaaS products grew steadily\n",
      "\n",
      "Debug Information:\n",
      "--------------------\n",
      "\n",
      "Confidence Statistics:\n",
      "  Average: 0.80\n",
      "  Max: 0.85\n",
      "  Min: 0.75\n",
      "\n",
      "Raw Analysis Data:\n",
      "{\n",
      "  \"language\": \"en\",\n",
      "  \"error\": null,\n",
      "  \"success\": true,\n",
      "  \"categories\": [\n",
      "    {\n",
      "      \"name\": \"technical\",\n",
      "      \"confidence\": 0.85,\n",
      "      \"explanation\": \"The text discusses a cloud migration project and DevOps implementation, both of which are technical processes related to software development and system management.\",\n",
      "      \"evidence\": [\n",
      "        \"cloud migration project\",\n",
      "        \"DevOps implementation\",\n",
      "        \"improved deployment frequency\"\n",
      "      ],\n",
      "      \"themes\": [\n",
      "        \"cloud computing\",\n",
      "        \"DevOps\",\n",
      "        \"infrastructure management\"\n",
      "      ]\n",
      "    },\n",
      "    {\n",
      "      \"name\": \"business\",\n",
      "      \"confidence\": 0.75,\n",
      "      \"explanation\": \"The text mentions reduced infrastructure costs and growth in monthly recurring revenue, which are key indicators of business performance and financial health.\",\n",
      "      \"evidence\": [\n",
      "        \"reduced infrastructure costs by 25%\",\n",
      "        \"monthly recurring revenue from SaaS products grew steadily\"\n",
      "      ],\n",
      "      \"themes\": [\n",
      "        \"cost reduction\",\n",
      "        \"revenue growth\",\n",
      "        \"SaaS business model\"\n",
      "      ]\n",
      "    }\n",
      "  ],\n",
      "  \"explanations\": {\n",
      "    \"technical\": \"The text discusses a cloud migration project and DevOps implementation, both of which are technical processes related to software development and system management.\",\n",
      "    \"business\": \"The text mentions reduced infrastructure costs and growth in monthly recurring revenue, which are key indicators of business performance and financial health.\"\n",
      "  },\n",
      "  \"evidence\": {\n",
      "    \"technical\": [\n",
      "      \"cloud migration project\",\n",
      "      \"DevOps implementation\",\n",
      "      \"improved deployment frequency\"\n",
      "    ],\n",
      "    \"business\": [\n",
      "      \"reduced infrastructure costs by 25%\",\n",
      "      \"monthly recurring revenue from SaaS products grew steadily\"\n",
      "    ]\n",
      "  }\n",
      "}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "CategoryOutput(language='en', error=None, success=True, categories=[CategoryInfo(name='technical', confidence=0.85, explanation='The text discusses a cloud migration project and DevOps implementation, both of which are technical processes related to software development and system management.', evidence=['cloud migration project', 'DevOps implementation', 'improved deployment frequency'], themes=['cloud computing', 'DevOps', 'infrastructure management']), CategoryInfo(name='business', confidence=0.75, explanation='The text mentions reduced infrastructure costs and growth in monthly recurring revenue, which are key indicators of business performance and financial health.', evidence=['reduced infrastructure costs by 25%', 'monthly recurring revenue from SaaS products grew steadily'], themes=['cost reduction', 'revenue growth', 'SaaS business model'])], explanations={'technical': 'The text discusses a cloud migration project and DevOps implementation, both of which are technical processes related to software development and system management.', 'business': 'The text mentions reduced infrastructure costs and growth in monthly recurring revenue, which are key indicators of business performance and financial health.'}, evidence={'technical': ['cloud migration project', 'DevOps implementation', 'improved deployment frequency'], 'business': ['reduced infrastructure costs by 25%', 'monthly recurring revenue from SaaS products grew steadily']})"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "await analyze_categories(text, options=options)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Or run full pipeline with debug info\n",
    "await debug_full_pipeline(text)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Batch Processing from Excel\n",
    "Process multiple texts from Excel file:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "await analyze_excel_content(\n",
    "    input_file=\"test_content.xlsx\",  # Input Excel file path\n",
    "    output_file=\"analysis_results\",  # Output filename (without extension)\n",
    "    content_column=\"content\"         # Column containing text to analyze\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parameters\n",
    "- Configure analyzers using parameter files\n",
    "- Control output detail with DebugOptions\n",
    "- Set logging level for verbosity control\n",
    "\n",
    "## Example Outputs\n",
    "The analysis provides:\n",
    "- Keywords with confidence scores\n",
    "- Theme identification and descriptions\n",
    "- Category classification with evidence\n",
    "- Confidence visualizations with Unicode bars\n",
    "\n",
    "## Notes\n",
    "- Set logging level to WARNING to minimize output\n",
    "- Use debug functions for detailed analysis inspection\n",
    "- Excel output combines all analysis types"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "semantic-analyzer",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
