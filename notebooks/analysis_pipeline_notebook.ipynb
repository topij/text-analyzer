{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Semantic Analysis Pipeline\n",
    "\n",
    "This notebook demonstrates the semantic text analysis capabilities using our custom analyzers.\n",
    "\n",
    "## Setup\n",
    "Import required packages and configure the environment:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# At start of notebook\n",
    "import sys\n",
    "from pathlib import Path\n",
    "import logging\n",
    "import os\n",
    "\n",
    "# Add project root to Python path\n",
    "project_root = str(Path().resolve().parent)\n",
    "if project_root not in sys.path:\n",
    "    sys.path.append(project_root)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-19 21:05:47,051 - src.utils.FileUtils.file_utils - DEBUG [file_utils.py:192] - Initialized FileUtils with log level: INFO\n",
      "2024-11-19 21:05:47,053 - src.utils.FileUtils.file_utils - DEBUG [file_utils.py:198] - Project root: c:\\Users\\tja\\OneDrive - Rastor-instituutti ry\\Tiedostot\\Rastor-instituutti\\kehittäminen\\analytiikka\\repos\\semantic-text-analyzer\n",
      "2024-11-19 21:05:47,062 - src.utils.FileUtils.file_utils - DEBUG [file_utils.py:192] - Initialized FileUtils with log level: INFO\n",
      "2024-11-19 21:05:47,066 - src.utils.FileUtils.file_utils - DEBUG [file_utils.py:198] - Project root: c:\\Users\\tja\\OneDrive - Rastor-instituutti ry\\Tiedostot\\Rastor-instituutti\\kehittäminen\\analytiikka\\repos\\semantic-text-analyzer\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Environment Check Results:\n",
      "==================================================\n",
      "\n",
      "Basic Setup:\n",
      "-----------\n",
      "✓ Project root in path\n",
      "✓ FileUtils initialized\n",
      "✓ .env file loaded\n",
      "\n",
      "Environment Variables:\n",
      "---------------------\n",
      "✓ OPENAI_API_KEY set\n",
      "✓ ANTHROPIC_API_KEY set\n",
      "\n",
      "Project Structure:\n",
      "-----------------\n",
      "✓ Raw data exists\n",
      "✓ Processed data exists\n",
      "✓ Configuration exists\n",
      "✓ Main config.yaml exists\n",
      "\n",
      "==================================================\n",
      "Environment Status: Ready ✓\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# import logging\n",
    "# from src.nb_helpers.logging import configure_logging\n",
    "\n",
    "# Set up environment with DEBUG level\n",
    "from src.nb_helpers.environment import setup_notebook_env, verify_environment\n",
    "setup_notebook_env(log_level=\"DEBUG\")\n",
    "\n",
    "# Any verification needed will maintain DEBUG level\n",
    "verify_environment(log_level=\"DEBUG\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary components\n",
    "from src.loaders.parameter_handler import ParameterHandler\n",
    "from src.nb_helpers.analyzers import (\n",
    "    analyze_keywords,\n",
    "    analyze_themes,\n",
    "    analyze_categories,\n",
    "    analyze_text,\n",
    "    AnalysisOptions\n",
    ")\n",
    "\n",
    "from scripts.migrate_parameters import create_example_parameters\n",
    "from src.nb_helpers.logging import configure_logging, verify_logging_setup_with_hierarchy, reset_debug_logging\n",
    "from src.loaders.parameter_handler import ParameterHandler, get_parameter_file_path, verify_parameter_file\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-19 21:05:47,162 - src.nb_helpers.logging - DEBUG - Logging configured at DEBUG level\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Logging Configuration:\n",
      "--------------------------------------------------\n",
      "\n",
      "Logger: root\n",
      "Set Level: DEBUG\n",
      "Effective Level: DEBUG\n",
      "Propagates to root: True\n",
      "Handlers:\n",
      "  Handler 1 level: DEBUG\n",
      "\n",
      "Logger: src.nb_helpers.analyzers\n",
      "Hierarchy:\n",
      "  src: NOTSET\n",
      "  src.nb_helpers: NOTSET\n",
      "  src.nb_helpers.analyzers: DEBUG\n",
      "Set Level: DEBUG\n",
      "Effective Level: DEBUG\n",
      "Propagates to root: True\n",
      "No handlers (uses root handlers)\n",
      "\n",
      "Logger: src.analyzers.keyword_analyzer\n",
      "Hierarchy:\n",
      "  src: NOTSET\n",
      "  src.analyzers: NOTSET\n",
      "  src.analyzers.keyword_analyzer: DEBUG\n",
      "Set Level: DEBUG\n",
      "Effective Level: DEBUG\n",
      "Propagates to root: True\n",
      "No handlers (uses root handlers)\n",
      "\n",
      "Logger: src.analyzers.theme_analyzer\n",
      "Hierarchy:\n",
      "  src: NOTSET\n",
      "  src.analyzers: NOTSET\n",
      "  src.analyzers.theme_analyzer: DEBUG\n",
      "Set Level: DEBUG\n",
      "Effective Level: DEBUG\n",
      "Propagates to root: True\n",
      "No handlers (uses root handlers)\n",
      "\n",
      "Logger: src.analyzers.category_analyzer\n",
      "Hierarchy:\n",
      "  src: NOTSET\n",
      "  src.analyzers: NOTSET\n",
      "  src.analyzers.category_analyzer: DEBUG\n",
      "Set Level: DEBUG\n",
      "Effective Level: DEBUG\n",
      "Propagates to root: True\n",
      "No handlers (uses root handlers)\n",
      "\n",
      "Logger: src.utils.FileUtils.file_utils\n",
      "Hierarchy:\n",
      "  src: NOTSET\n",
      "  src.utils: NOTSET\n",
      "  src.utils.FileUtils: NOTSET\n",
      "  src.utils.FileUtils.file_utils: DEBUG\n",
      "Set Level: DEBUG\n",
      "Effective Level: DEBUG\n",
      "Propagates to root: True\n",
      "No handlers (uses root handlers)\n",
      "\n",
      "Logger: httpx\n",
      "Hierarchy:\n",
      "  httpx: INFO\n",
      "Set Level: INFO\n",
      "Effective Level: INFO\n",
      "Propagates to root: True\n",
      "No handlers (uses root handlers)\n"
     ]
    }
   ],
   "source": [
    "# Set initial logging\n",
    "configure_logging(level=\"DEBUG\")\n",
    "# Keep HTTP loggers at INFO\n",
    "for name in [\"httpx\", \"httpcore\", \"openai\", \"anthropic\"]:\n",
    "    logging.getLogger(name).setLevel(logging.INFO)\n",
    "    \n",
    "verify_logging_setup_with_hierarchy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# detailed_logging_info = True\n",
    "# if detailed_logging_info:\n",
    "#     from src.nb_helpers.logging import verify_logging_setup_with_hierarchy\n",
    "#     # Configure logging\n",
    "#     # configure_logging(level=\"DEBUG\")\n",
    "#     # Verify with detailed information\n",
    "#     verify_logging_setup_with_hierarchy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example texts in different languages\n",
    "example_texts = {\n",
    "    \"English Technical\": \"\"\"\n",
    "        The cloud migration project improved system scalability while reducing costs.\n",
    "        New DevOps practices streamlined the deployment pipeline significantly.\n",
    "    \"\"\",\n",
    "    \n",
    "    \"Finnish Technical\": \"\"\"\n",
    "        Pilvipalveluihin siirtyminen paransi järjestelmän skaalautuvuutta ja vähensi kustannuksia.\n",
    "        Uudet DevOps-käytännöt tehostivat merkittävästi käyttöönottoprosessia.\n",
    "    \"\"\",\n",
    "    \n",
    "    \"English Business\": \"\"\"\n",
    "        Q3 financial results show 15% revenue growth and improved profit margins.\n",
    "        Customer acquisition costs decreased while retention rates increased.\n",
    "    \"\"\",\n",
    "    \n",
    "    \"Finnish Business\": \"\"\"\n",
    "        Q3 taloudelliset tulokset osoittavat 15% liikevaihdon kasvun ja parantuneet katteet.\n",
    "        Asiakashankinnan kustannukset laskivat ja asiakaspysyvyys parani.\n",
    "    \"\"\"\n",
    "}\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-19 21:05:47,263 - src.utils.FileUtils.file_utils - DEBUG [file_utils.py:192] - Initialized FileUtils with log level: INFO\n",
      "2024-11-19 21:05:47,263 - src.utils.FileUtils.file_utils - DEBUG - Initialized FileUtils with log level: INFO\n",
      "2024-11-19 21:05:47,266 - src.utils.FileUtils.file_utils - DEBUG [file_utils.py:198] - Project root: c:\\Users\\tja\\OneDrive - Rastor-instituutti ry\\Tiedostot\\Rastor-instituutti\\kehittäminen\\analytiikka\\repos\\semantic-text-analyzer\n",
      "2024-11-19 21:05:47,266 - src.utils.FileUtils.file_utils - DEBUG - Project root: c:\\Users\\tja\\OneDrive - Rastor-instituutti ry\\Tiedostot\\Rastor-instituutti\\kehittäminen\\analytiikka\\repos\\semantic-text-analyzer\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using existing parameter file at: c:\\Users\\tja\\OneDrive - Rastor-instituutti ry\\Tiedostot\\Rastor-instituutti\\kehittäminen\\analytiikka\\repos\\semantic-text-analyzer\\data\\parameters\\parameters_en.xlsx\n",
      "\n",
      "Parameter File Verification:\n",
      "Absolute path: C:\\Users\\tja\\OneDrive - Rastor-instituutti ry\\Tiedostot\\Rastor-instituutti\\kehittäminen\\analytiikka\\repos\\semantic-text-analyzer\\data\\parameters\\parameters_en.xlsx\n",
      "File exists: True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-19 21:05:48,319 - src.utils.FileUtils.file_utils - DEBUG [file_utils.py:192] - Initialized FileUtils with log level: INFO\n",
      "2024-11-19 21:05:48,319 - src.utils.FileUtils.file_utils - DEBUG - Initialized FileUtils with log level: INFO\n",
      "2024-11-19 21:05:48,327 - src.utils.FileUtils.file_utils - DEBUG [file_utils.py:198] - Project root: c:\\Users\\tja\\OneDrive - Rastor-instituutti ry\\Tiedostot\\Rastor-instituutti\\kehittäminen\\analytiikka\\repos\\semantic-text-analyzer\n",
      "2024-11-19 21:05:48,327 - src.utils.FileUtils.file_utils - DEBUG - Project root: c:\\Users\\tja\\OneDrive - Rastor-instituutti ry\\Tiedostot\\Rastor-instituutti\\kehittäminen\\analytiikka\\repos\\semantic-text-analyzer\n",
      "2024-11-19 21:05:48,334 - src.loaders.parameter_handler - DEBUG - Using parameter file: c:\\Users\\tja\\OneDrive - Rastor-instituutti ry\\Tiedostot\\Rastor-instituutti\\kehittäminen\\analytiikka\\repos\\semantic-text-analyzer\\data\\parameters\\parameters_en.xlsx\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Found sheets:\n",
      "\n",
      "General Parameters:\n",
      "                parameter                           value  \\\n",
      "0            max_keywords                              10   \n",
      "1                focus_on  technical and business content   \n",
      "2  column_name_to_analyze                         content   \n",
      "3      min_keyword_length                               3   \n",
      "4       include_compounds                            True   \n",
      "\n",
      "                          description  \n",
      "0  Maximum keywords to extract (1-20)  \n",
      "1                 Analysis focus area  \n",
      "2          Name of the content column  \n",
      "3              Minimum keyword length  \n",
      "4              Include compound words  \n",
      "\n",
      "Categories:\n",
      "              category                                 description  \\\n",
      "0    technical_content  Technical and software development content   \n",
      "1     business_content              Business and financial content   \n",
      "2  educational_content            Educational and training content   \n",
      "\n",
      "                                            keywords  threshold  parent  \n",
      "0  software,development,api,programming,technical...        0.6     NaN  \n",
      "1     revenue,sales,market,growth,financial,business        0.6     NaN  \n",
      "2        learning,education,training,teaching,skills        0.5     NaN  \n",
      "\n",
      "Predefined Keywords:\n",
      "            keyword  importance     domain\n",
      "0  machine learning         1.0  technical\n",
      "1   cloud computing         0.9  technical\n",
      "2    revenue growth         0.9   business\n",
      "\n",
      "Excluded Keywords:\n",
      "  keyword       reason\n",
      "0     the  Common word\n",
      "1     and  Common word\n",
      "2     for  Common word\n",
      "\n",
      "Analysis Settings:\n",
      "                         setting  value  \\\n",
      "0  theme_analysis.min_confidence    0.5   \n",
      "1            weights.statistical    0.4   \n",
      "2                    weights.llm    0.6   \n",
      "\n",
      "                              description  \n",
      "0  Minimum confidence for theme detection  \n",
      "1         Weight for statistical analysis  \n",
      "2                 Weight for LLM analysis  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-19 21:05:48,339 - src.loaders.parameter_handler - DEBUG - Loading Excel file from: c:\\Users\\tja\\OneDrive - Rastor-instituutti ry\\Tiedostot\\Rastor-instituutti\\kehittäminen\\analytiikka\\repos\\semantic-text-analyzer\\data\\parameters\\parameters_en.xlsx\n",
      "2024-11-19 21:05:48,395 - src.utils.FileUtils.file_utils - INFO [file_utils.py:1018] - Successfully loaded 5 sheets from c:\\Users\\tja\\OneDrive - Rastor-instituutti ry\\Tiedostot\\Rastor-instituutti\\kehittäminen\\analytiikka\\repos\\semantic-text-analyzer\\data\\parameters\\parameters_en.xlsx\n",
      "2024-11-19 21:05:48,395 - src.utils.FileUtils.file_utils - INFO - Successfully loaded 5 sheets from c:\\Users\\tja\\OneDrive - Rastor-instituutti ry\\Tiedostot\\Rastor-instituutti\\kehittäminen\\analytiikka\\repos\\semantic-text-analyzer\\data\\parameters\\parameters_en.xlsx\n",
      "2024-11-19 21:05:48,398 - src.loaders.parameter_handler - DEBUG - Found sheets: ['General Parameters', 'Categories', 'Predefined Keywords', 'Excluded Keywords', 'Analysis Settings']\n",
      "2024-11-19 21:05:48,400 - src.loaders.parameter_handler - DEBUG - Looking for general parameters in sheet: General Parameters\n",
      "2024-11-19 21:05:48,402 - src.loaders.parameter_handler - DEBUG - General sheet columns: ['parameter', 'value', 'description']\n",
      "2024-11-19 21:05:48,411 - src.loaders.parameter_handler - DEBUG - General sheet content:\n",
      "                parameter                           value  \\\n",
      "0            max_keywords                              10   \n",
      "1                focus_on  technical and business content   \n",
      "2  column_name_to_analyze                         content   \n",
      "3      min_keyword_length                               3   \n",
      "4       include_compounds                            True   \n",
      "5                language                              en   \n",
      "\n",
      "                          description  \n",
      "0  Maximum keywords to extract (1-20)  \n",
      "1                 Analysis focus area  \n",
      "2          Name of the content column  \n",
      "3              Minimum keyword length  \n",
      "4              Include compound words  \n",
      "5                    Content language  \n",
      "2024-11-19 21:05:48,413 - src.loaders.parameter_handler - DEBUG - Starting with default general parameters: {'max_keywords': 10, 'min_keyword_length': 3, 'language': 'en', 'focus_on': 'general content analysis', 'include_compounds': True, 'max_themes': 3, 'min_confidence': 0.3, 'column_name_to_analyze': 'text'}\n",
      "2024-11-19 21:05:48,415 - src.loaders.parameter_handler - DEBUG - Found parameter and value columns\n",
      "2024-11-19 21:05:48,423 - src.loaders.parameter_handler - DEBUG - Full dataframe:\n",
      "                parameter                           value  \\\n",
      "0            max_keywords                              10   \n",
      "1                focus_on  technical and business content   \n",
      "2  column_name_to_analyze                         content   \n",
      "3      min_keyword_length                               3   \n",
      "4       include_compounds                            True   \n",
      "5                language                              en   \n",
      "\n",
      "                          description  \n",
      "0  Maximum keywords to extract (1-20)  \n",
      "1                 Analysis focus area  \n",
      "2          Name of the content column  \n",
      "3              Minimum keyword length  \n",
      "4              Include compound words  \n",
      "5                    Content language  \n",
      "2024-11-19 21:05:48,425 - src.loaders.parameter_handler - DEBUG - Setting max_keywords = 10\n",
      "2024-11-19 21:05:48,428 - src.loaders.parameter_handler - DEBUG - Setting focus_on = technical and business content\n",
      "2024-11-19 21:05:48,430 - src.loaders.parameter_handler - DEBUG - Setting column_name_to_analyze = content\n",
      "2024-11-19 21:05:48,431 - src.loaders.parameter_handler - DEBUG - Setting min_keyword_length = 3\n",
      "2024-11-19 21:05:48,439 - src.loaders.parameter_handler - DEBUG - Setting include_compounds = True\n",
      "2024-11-19 21:05:48,444 - src.loaders.parameter_handler - DEBUG - Setting language = en\n",
      "2024-11-19 21:05:48,446 - src.loaders.parameter_handler - DEBUG - Final general parameters: {'max_keywords': 10, 'min_keyword_length': 3, 'language': 'en', 'focus_on': 'technical and business content', 'include_compounds': True, 'max_themes': 3, 'min_confidence': 0.3, 'column_name_to_analyze': 'content'}\n",
      "2024-11-19 21:05:48,448 - src.loaders.parameter_handler - DEBUG - Parsed general parameters: {'max_keywords': 10, 'min_keyword_length': 3, 'language': 'en', 'focus_on': 'technical and business content', 'include_compounds': True, 'max_themes': 3, 'min_confidence': 0.3, 'column_name_to_analyze': 'content'}\n",
      "2024-11-19 21:05:48,454 - src.loaders.parameter_handler - DEBUG - Created parameter set: {'general': {'max_keywords': 10, 'min_keyword_length': 3, 'language': 'en', 'focus_on': 'technical and business content', 'include_compounds': True, 'max_themes': 3, 'min_confidence': 0.3, 'column_name_to_analyze': 'content'}, 'categories': {'technical_content': {'description': 'Technical and software development content', 'keywords': ['software', 'development', 'api', 'programming', 'technical', 'code'], 'threshold': 0.6, 'parent': None}, 'business_content': {'description': 'Business and financial content', 'keywords': ['revenue', 'sales', 'market', 'growth', 'financial', 'business'], 'threshold': 0.6, 'parent': None}, 'educational_content': {'description': 'Educational and training content', 'keywords': ['learning', 'education', 'training', 'teaching', 'skills'], 'threshold': 0.5, 'parent': None}}, 'predefined_keywords': {'machine learning': {'importance': 1.0, 'domain': 'technical', 'compound_parts': []}, 'cloud computing': {'importance': 0.9, 'domain': 'technical', 'compound_parts': []}, 'revenue growth': {'importance': 0.9, 'domain': 'business', 'compound_parts': []}}, 'excluded_keywords': {'the', 'for', 'and'}, 'analysis_settings': {'theme_analysis': {'enabled': True, 'min_confidence': 0.5}, 'weights': {'statistical': 0.4, 'llm': 0.6}}, 'domain_context': {}}\n"
     ]
    }
   ],
   "source": [
    "# Create and load parameters\n",
    "params_file_name = \"parameters_en.xlsx\"\n",
    "\n",
    "# Get the full parameter file path\n",
    "params_file = get_parameter_file_path(params_file_name)\n",
    "\n",
    "# Create file if it doesn't exist\n",
    "if not params_file.exists():\n",
    "    params_file = create_example_parameters(params_file_name)\n",
    "    print(f\"Created parameter file at: {params_file}\")\n",
    "else:\n",
    "    print(f\"Using existing parameter file at: {params_file}\")\n",
    "\n",
    "# Verify the file\n",
    "verify_parameter_file(params_file)\n",
    "\n",
    "# Load parameters\n",
    "handler = ParameterHandler(params_file_name)  # Can now use just the file name\n",
    "params = handler.get_parameters()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Loaded parameters:\n",
      "ParameterSet(\n",
      "  general=max_keywords=10 min_keyword_length=3 language='en' focus_on='technical and business content' include_compounds=True max_themes=3 min_confidence=0.3 column_name_to_analyze='content',\n",
      "  categories=3 items,\n",
      "  predefined_keywords=3 items,\n",
      "  excluded_keywords=3 items,\n",
      "  analysis_settings=theme_analysis=ThemeAnalysisSettings(enabled=True, min_confidence=0.5) weights=AnalysisWeights(statistical=0.4, llm=0.6),\n",
      "  domain_context=0 items\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nLoaded parameters:\")\n",
    "# params.print()  # Uses the new print method\n",
    "\n",
    "# Or just\n",
    "print(params)  # Uses the new __str__ method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Not creating new example files.\n"
     ]
    }
   ],
   "source": [
    "# Create example files\n",
    "\n",
    "create_new_example_files=False\n",
    "\n",
    "if create_new_example_files:\n",
    "    en_params = create_example_parameters(\"parameters_en.xlsx\", \"en\")\n",
    "    fi_params = create_example_parameters(\"parameters_fi.xlsx\", \"fi\")\n",
    "    print(f\"Created parameter files:\\n- {en_params}\\n- {fi_params}\")\n",
    "    print(f\"Created parameter files:\\n- {en_params}\\n- {fi_params}\")\n",
    "else:\n",
    "    print(\"Not creating new example files.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter Validation:\n",
      "--------------------------------------------------\n",
      "\n",
      "Parameters validated successfully!\n"
     ]
    }
   ],
   "source": [
    "# Check parameter validation\n",
    "print(\"Parameter Validation:\")\n",
    "print(\"-\" * 50)\n",
    "is_valid, warnings, errors = handler.validate()\n",
    "if warnings:\n",
    "    print(\"\\nWarnings:\")\n",
    "    for warning in warnings:\n",
    "        print(f\"- {warning}\")\n",
    "if not is_valid:\n",
    "    print(\"\\nErrors:\")\n",
    "    for error in errors:\n",
    "        print(f\"- {error}\")\n",
    "else:\n",
    "    print(\"\\nParameters validated successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test cases\n",
    "test_texts = {\n",
    "    \"Technical Compound Terms\": \"\"\"\n",
    "        The cloud migration project improved system scalability.\n",
    "        DevOps practices streamlined the deployment pipeline.\n",
    "        Our microservices architecture enables API integrations.\n",
    "    \"\"\",\n",
    "    \n",
    "    \"Mixed Domain Content\": \"\"\"\n",
    "        The IT department's infrastructure costs decreased by 25%\n",
    "        after implementing cloud-native solutions. Monthly recurring\n",
    "        revenue from SaaS products grew steadily while deployment\n",
    "        frequency improved.\n",
    "    \"\"\",\n",
    "    \n",
    "    \"Business Focus\": \"\"\"\n",
    "        Market analysis shows 15% revenue growth in Q3.\n",
    "        Customer acquisition costs decreased while retention rates\n",
    "        increased. Strategic partnerships drove innovation.\n",
    "    \"\"\",\n",
    "    \n",
    "    \"Multiple Compounds\": \"\"\"\n",
    "        Machine learning models process real-time data streams.\n",
    "        The CI/CD pipeline integrates automated testing workflows.\n",
    "        Cloud-based infrastructure supports multi-region deployments.\n",
    "    \"\"\"\n",
    "}\n",
    "\n",
    "finnish_texts = {\n",
    "    \"technical_fi_1\":\"Pilvipalveluiden käyttöönotto tehosti järjestelmän skaalautuvuutta merkittävästi. DevOps-prosessit nopeuttivat julkaisusykliä ja automatisoivat laadunvarmistusta. Kuukausittainen tilaustuotto SaaS-ratkaisuista kasvoi 25%.\",\n",
    "    \"technical_fi_2\":\"Mikropalveluarkkitehtuuri mahdollisti järjestelmän modulaarisen kehityksen. Konttiteknologian avulla saavutettiin parempi resurssien käyttöaste ja joustavampi ylläpito. Rajapintojen dokumentointi helpotti integraatioiden toteuttamista.\",\n",
    "    \"technical_fi_3\":\"Tekoälypohjaiset ennusteet auttoivat optimoimaan kuormantasausta. Pilvinatiivi lähestymistapa vähensi infrastruktuurikustannuksia ja paransi vikasietoisuutta. Monitorointi tarjosi reaaliaikaista näkyvyyttä suorituskykyyn.\",\n",
    "    \"business_fi_1\":\"Liikevaihdon kasvu vahvistui kolmannella vuosineljänneksellä 15 prosenttiin. Asiakashankinnan kustannukset laskivat samalla kun asiakaspysyvyys parani. Markkinaosuus kasvoi erityisesti pilvipalveluiden segmentissä.\",\n",
    "    \"business_fi_2\":\"Analytiikkatyökalut paljastivat uusia käyttäytymismalleja asiakasrajapinnassa. Toistuvaislaskutuksen osuus kokonaistuotoista nousi 75 prosenttiin. Automaattinen raportointi tehosti päätöksentekoa.\",\n",
    "    \"business_fi_3\":\"Uudet tuotelanseeraukset vahvistivat kilpailuasemaa. Strategiset kumppanuudet mahdollistivat laajentumisen uusille markkina-alueille. Resurssien kohdentaminen tuotekehitykseen tuotti merkittävää kasvua.\"\n",
    "}\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Testing function\n",
    "async def test_keyword_analyzer(text: str, show_debug: bool = True, language: str = \"en\"):\n",
    "    options = AnalysisOptions(\n",
    "        show_confidence=True,\n",
    "        show_evidence=True,\n",
    "        show_keywords=True,\n",
    "        show_raw_data=show_debug,\n",
    "        debug_mode=True,\n",
    "        language=language\n",
    "    )\n",
    "    \n",
    "    results = await analyze_keywords(text, options)\n",
    "    return results\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-19 21:05:48,637 - src.nb_helpers.analyzers - DEBUG - Starting keyword analysis\n",
      "2024-11-19 21:05:48,641 - src.utils.FileUtils.file_utils - DEBUG [file_utils.py:192] - Initialized FileUtils with log level: INFO\n",
      "2024-11-19 21:05:48,641 - src.utils.FileUtils.file_utils - DEBUG - Initialized FileUtils with log level: INFO\n",
      "2024-11-19 21:05:48,644 - src.utils.FileUtils.file_utils - DEBUG [file_utils.py:198] - Project root: c:\\Users\\tja\\OneDrive - Rastor-instituutti ry\\Tiedostot\\Rastor-instituutti\\kehittäminen\\analytiikka\\repos\\semantic-text-analyzer\n",
      "2024-11-19 21:05:48,644 - src.utils.FileUtils.file_utils - DEBUG - Project root: c:\\Users\\tja\\OneDrive - Rastor-instituutti ry\\Tiedostot\\Rastor-instituutti\\kehittäminen\\analytiikka\\repos\\semantic-text-analyzer\n",
      "2024-11-19 21:05:48,651 - src.nb_helpers.analyzers - DEBUG - Initialized TextAnalyzer with options: AnalysisOptions(show_confidence=True, show_evidence=True, show_keywords=True, show_raw_data=True, debug_mode=True, language='fi', parameter_file=None)\n",
      "2024-11-19 21:05:48,653 - src.core.language_processing.factory - DEBUG - Using default configuration\n",
      "2024-11-19 21:05:48,655 - src.core.language_processing.factory - DEBUG - Creating fi processor\n",
      "2024-11-19 21:05:48,658 - src.utils.FileUtils.file_utils - DEBUG [file_utils.py:192] - Initialized FileUtils with log level: INFO\n",
      "2024-11-19 21:05:48,658 - src.utils.FileUtils.file_utils - DEBUG - Initialized FileUtils with log level: INFO\n",
      "2024-11-19 21:05:48,659 - src.utils.FileUtils.file_utils - DEBUG [file_utils.py:198] - Project root: c:\\Users\\tja\\OneDrive - Rastor-instituutti ry\\Tiedostot\\Rastor-instituutti\\kehittäminen\\analytiikka\\repos\\semantic-text-analyzer\n",
      "2024-11-19 21:05:48,659 - src.utils.FileUtils.file_utils - DEBUG - Project root: c:\\Users\\tja\\OneDrive - Rastor-instituutti ry\\Tiedostot\\Rastor-instituutti\\kehittäminen\\analytiikka\\repos\\semantic-text-analyzer\n",
      "2024-11-19 21:05:48,668 - src.core.language_processing.finnish - INFO - Loaded 747 stopwords from c:\\Users\\tja\\OneDrive - Rastor-instituutti ry\\Tiedostot\\Rastor-instituutti\\kehittäminen\\analytiikka\\repos\\semantic-text-analyzer\\data\\configurations\\stop_words\\fi.txt\n",
      "2024-11-19 21:05:48,670 - src.core.language_processing.finnish - DEBUG - Added 27 technical stopwords\n",
      "2024-11-19 21:05:48,671 - src.core.language_processing.finnish - DEBUG - Total Finnish stopwords: 774\n",
      "2024-11-19 21:05:48,673 - src.core.language_processing.finnish - INFO - Detected platform: win32\n",
      "2024-11-19 21:05:48,675 - src.core.language_processing.finnish - DEBUG - Could not initialize Voikko using system libraries: Could not find module 'libvoikko-1.dll' (or one of its dependencies). Try using the full path with constructor syntax.\n",
      "Exception ignored in: <function Voikko.__del__ at 0x0000022A78E16670>\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\tja\\AppData\\Local\\miniconda3\\envs\\semantic-analyzer\\lib\\site-packages\\libvoikko.py\", line 446, in __del__\n",
      "    self.terminate()\n",
      "  File \"c:\\Users\\tja\\AppData\\Local\\miniconda3\\envs\\semantic-analyzer\\lib\\site-packages\\libvoikko.py\", line 476, in terminate\n",
      "    if self.__handle:\n",
      "AttributeError: 'Voikko' object has no attribute '_Voikko__handle'\n",
      "2024-11-19 21:05:48,680 - src.core.language_processing.finnish - INFO - Added C:\\scripts\\Voikko to DLL search path\n",
      "2024-11-19 21:05:48,682 - src.core.language_processing.finnish - INFO - Verifying Voikko installation...\n",
      "2024-11-19 21:05:48,684 - src.core.language_processing.finnish - INFO - DLL exists: True (C:\\scripts\\Voikko\\libvoikko-1.dll)\n",
      "2024-11-19 21:05:48,685 - src.core.language_processing.finnish - INFO - Found dictionary version 5 at: C:\\scripts\\Voikko\\voikko\\5\\mor-standard\n",
      "2024-11-19 21:05:48,695 - src.core.language_processing.finnish - INFO - Successfully initialized Voikko with path: C:\\scripts\\Voikko\n",
      "2024-11-19 21:05:50,533 - src.utils.FileUtils.file_utils - DEBUG [file_utils.py:192] - Initialized FileUtils with log level: INFO\n",
      "2024-11-19 21:05:50,533 - src.utils.FileUtils.file_utils - DEBUG - Initialized FileUtils with log level: INFO\n",
      "2024-11-19 21:05:50,536 - src.utils.FileUtils.file_utils - DEBUG [file_utils.py:198] - Project root: c:\\Users\\tja\\OneDrive - Rastor-instituutti ry\\Tiedostot\\Rastor-instituutti\\kehittäminen\\analytiikka\\repos\\semantic-text-analyzer\n",
      "2024-11-19 21:05:50,536 - src.utils.FileUtils.file_utils - DEBUG - Project root: c:\\Users\\tja\\OneDrive - Rastor-instituutti ry\\Tiedostot\\Rastor-instituutti\\kehittäminen\\analytiikka\\repos\\semantic-text-analyzer\n",
      "2024-11-19 21:05:50,546 - src.nb_helpers.analyzers - DEBUG - Running keyword analysis\n",
      "2024-11-19 21:05:50,547 - src.nb_helpers.testers - DEBUG - KeywordTester starting analysis\n",
      "2024-11-19 21:05:50,548 - src.analyzers.keyword_analyzer - DEBUG - Starting keyword analysis\n",
      "2024-11-19 21:05:50,556 - src.analyzers.keyword_analyzer - DEBUG - Applied compound bonus to liikevaihto\n",
      "2024-11-19 21:05:50,559 - src.analyzers.keyword_analyzer - DEBUG - Applied compound bonus to vuosineljännes\n",
      "2024-11-19 21:05:50,562 - src.analyzers.keyword_analyzer - DEBUG - Applied compound bonus to asiakashankinta\n",
      "2024-11-19 21:05:50,564 - src.analyzers.keyword_analyzer - DEBUG - Applied compound bonus to asiakaspysyvyys\n",
      "2024-11-19 21:05:50,567 - src.analyzers.keyword_analyzer - DEBUG - Applied compound bonus to markkinaosuus\n",
      "2024-11-19 21:05:50,569 - src.analyzers.keyword_analyzer - DEBUG - Applied compound bonus to pilvipalvelu\n",
      "2024-11-19 21:05:50,615 - src.analyzers.keyword_analyzer - DEBUG - Applied compound bonus to liikevaihto\n",
      "2024-11-19 21:05:50,620 - src.analyzers.keyword_analyzer - DEBUG - Applied compound bonus to vuosineljännes\n",
      "2024-11-19 21:05:50,623 - src.analyzers.keyword_analyzer - DEBUG - Applied compound bonus to asiakashankinta\n",
      "2024-11-19 21:05:50,626 - src.analyzers.keyword_analyzer - DEBUG - Applied compound bonus to asiakaspysyvyys\n",
      "2024-11-19 21:05:50,628 - src.analyzers.keyword_analyzer - DEBUG - Applied compound bonus to markkinaosuus\n",
      "2024-11-19 21:05:50,630 - src.analyzers.keyword_analyzer - DEBUG - Applied compound bonus to pilvipalvelu\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "liikevaihto\n",
      "kasvu\n",
      "vahvistua\n",
      "vuosineljännes\n",
      "prosentti\n",
      "asiakashankinta\n",
      "kustannus\n",
      "laskea\n",
      "asiakaspysyvyys\n",
      "para\n",
      "markkinaosuus\n",
      "kasvaa\n",
      "pilvipalvelu\n",
      "segmentti\n",
      "liikevaihto\n",
      "kasvu\n",
      "vahvistua\n",
      "vuosineljännes\n",
      "prosentti\n",
      "asiakashankinta\n",
      "kustannus\n",
      "laskea\n",
      "asiakaspysyvyys\n",
      "para\n",
      "markkinaosuus\n",
      "kasvaa\n",
      "pilvipalvelu\n",
      "segmentti\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-19 21:05:56,907 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-11-19 21:05:56,943 - src.analyzers.keyword_analyzer - DEBUG - Got LLM response for keyword analysis\n",
      "2024-11-19 21:05:56,944 - src.analyzers.keyword_analyzer - DEBUG - Processed LLM keyword: liikevaihto\n",
      "2024-11-19 21:05:56,945 - src.analyzers.keyword_analyzer - DEBUG - Processed LLM keyword: kasvu\n",
      "2024-11-19 21:05:56,946 - src.analyzers.keyword_analyzer - DEBUG - Processed LLM keyword: vahvistua\n",
      "2024-11-19 21:05:56,947 - src.analyzers.keyword_analyzer - DEBUG - Processed LLM keyword: vuosineljännes\n",
      "2024-11-19 21:05:56,949 - src.analyzers.keyword_analyzer - DEBUG - Processed LLM keyword: prosentti\n",
      "2024-11-19 21:05:56,951 - src.analyzers.keyword_analyzer - DEBUG - Applied compound bonus to liikevaihto\n",
      "2024-11-19 21:05:56,953 - src.analyzers.keyword_analyzer - DEBUG - Applied compound bonus to vahvistua\n",
      "2024-11-19 21:05:56,956 - src.analyzers.keyword_analyzer - DEBUG - Applied compound bonus to vuosineljännes\n",
      "2024-11-19 21:05:56,959 - src.analyzers.keyword_analyzer - DEBUG - Applied compound bonus to asiakashankinta\n",
      "2024-11-19 21:05:56,961 - src.analyzers.keyword_analyzer - DEBUG - Applied compound bonus to asiakaspysyvyys\n",
      "2024-11-19 21:05:56,963 - src.analyzers.keyword_analyzer - DEBUG - Applied compound bonus to markkinaosuus\n",
      "2024-11-19 21:05:56,965 - src.analyzers.keyword_analyzer - DEBUG - Applied compound bonus to pilvipalvelu\n",
      "2024-11-19 21:05:56,967 - src.analyzers.keyword_analyzer - DEBUG - Applied domain boost (1.15) to liikevaihto\n",
      "2024-11-19 21:05:56,968 - src.analyzers.keyword_analyzer - DEBUG - Applied compound bonus to liikevaihto\n",
      "2024-11-19 21:05:56,972 - src.analyzers.keyword_analyzer - DEBUG - Applied compound bonus to vahvistua\n",
      "2024-11-19 21:05:56,974 - src.analyzers.keyword_analyzer - DEBUG - Applied domain boost (1.15) to vuosineljännes\n",
      "2024-11-19 21:05:56,976 - src.analyzers.keyword_analyzer - DEBUG - Applied compound bonus to vuosineljännes\n",
      "2024-11-19 21:05:57,015 - src.analyzers.keyword_analyzer - DEBUG - Applied POS penalty to laskea (VB)\n",
      "2024-11-19 21:05:57,018 - src.analyzers.keyword_analyzer - DEBUG - Applied generic penalty to kasvaa\n",
      "2024-11-19 21:05:57,020 - src.analyzers.keyword_analyzer - DEBUG - Applied POS penalty to kasvaa (VB)\n",
      "2024-11-19 21:05:57,023 - src.analyzers.keyword_analyzer - DEBUG - Analysis complete. Found 10 keywords\n",
      "2024-11-19 21:05:57,025 - src.nb_helpers.testers - DEBUG - KeywordTester analysis complete\n",
      "2024-11-19 21:05:57,026 - src.nb_helpers.analyzers - DEBUG - Keyword analysis completed\n",
      "2024-11-19 21:05:57,027 - src.nb_helpers.analyzers - DEBUG - Formatting results\n",
      "2024-11-19 21:05:57,028 - src.nb_helpers.analyzers - DEBUG - Displaying debug information\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "liikevaihto\n",
      "vuosineljännes\n",
      "liikevaihto\n",
      "vahvistua\n",
      "liikevaihto\n",
      "asiakaspysyvyys\n",
      "liikevaihto\n",
      "kasvu\n",
      "liikevaihto\n",
      "asiakashankinta\n",
      "liikevaihto\n",
      "prosentti\n",
      "liikevaihto\n",
      "markkinaosuus\n",
      "liikevaihto\n",
      "pilvipalvelu\n",
      "liikevaihto\n",
      "kustannus\n",
      "liikevaihto\n",
      "laskea\n",
      "liikevaihto\n",
      "para\n",
      "liikevaihto\n",
      "kasvaa\n",
      "liikevaihto\n",
      "segmentti\n",
      "vuosineljännes\n",
      "vahvistua\n",
      "vuosineljännes\n",
      "asiakaspysyvyys\n",
      "vuosineljännes\n",
      "kasvu\n",
      "vuosineljännes\n",
      "asiakashankinta\n",
      "vuosineljännes\n",
      "prosentti\n",
      "vuosineljännes\n",
      "markkinaosuus\n",
      "vuosineljännes\n",
      "pilvipalvelu\n",
      "vuosineljännes\n",
      "kustannus\n",
      "vuosineljännes\n",
      "laskea\n",
      "vuosineljännes\n",
      "para\n",
      "vuosineljännes\n",
      "kasvaa\n",
      "vuosineljännes\n",
      "segmentti\n",
      "vahvistua\n",
      "asiakaspysyvyys\n",
      "vahvistua\n",
      "kasvu\n",
      "vahvistua\n",
      "asiakashankinta\n",
      "vahvistua\n",
      "prosentti\n",
      "vahvistua\n",
      "markkinaosuus\n",
      "vahvistua\n",
      "pilvipalvelu\n",
      "vahvistua\n",
      "kustannus\n",
      "vahvistua\n",
      "laskea\n",
      "vahvistua\n",
      "para\n",
      "vahvistua\n",
      "kasvaa\n",
      "vahvistua\n",
      "segmentti\n",
      "asiakaspysyvyys\n",
      "kasvu\n",
      "asiakaspysyvyys\n",
      "asiakashankinta\n",
      "asiakaspysyvyys\n",
      "prosentti\n",
      "asiakaspysyvyys\n",
      "markkinaosuus\n",
      "asiakaspysyvyys\n",
      "pilvipalvelu\n",
      "asiakaspysyvyys\n",
      "kustannus\n",
      "asiakaspysyvyys\n",
      "laskea\n",
      "asiakaspysyvyys\n",
      "para\n",
      "asiakaspysyvyys\n",
      "kasvaa\n",
      "asiakaspysyvyys\n",
      "segmentti\n",
      "kasvu\n",
      "prosentti\n",
      "kasvu\n",
      "markkinaosuus\n",
      "kasvu\n",
      "pilvipalvelu\n",
      "kasvu\n",
      "kustannus\n",
      "kasvu\n",
      "laskea\n",
      "kasvu\n",
      "para\n",
      "kasvu\n",
      "kasvaa\n",
      "kasvu\n",
      "segmentti\n",
      "prosentti\n",
      "markkinaosuus\n",
      "prosentti\n",
      "pilvipalvelu\n",
      "prosentti\n",
      "kustannus\n",
      "prosentti\n",
      "laskea\n",
      "prosentti\n",
      "para\n",
      "prosentti\n",
      "kasvaa\n",
      "prosentti\n",
      "segmentti\n",
      "markkinaosuus\n",
      "pilvipalvelu\n",
      "markkinaosuus\n",
      "kustannus\n",
      "markkinaosuus\n",
      "laskea\n",
      "markkinaosuus\n",
      "para\n",
      "markkinaosuus\n",
      "kasvaa\n",
      "markkinaosuus\n",
      "segmentti\n",
      "pilvipalvelu\n",
      "kustannus\n",
      "pilvipalvelu\n",
      "laskea\n",
      "pilvipalvelu\n",
      "para\n",
      "pilvipalvelu\n",
      "kasvaa\n",
      "pilvipalvelu\n",
      "segmentti\n",
      "kustannus\n",
      "laskea\n",
      "kustannus\n",
      "para\n",
      "kustannus\n",
      "kasvaa\n",
      "kustannus\n",
      "segmentti\n",
      "laskea\n",
      "para\n",
      "laskea\n",
      "kasvaa\n",
      "laskea\n",
      "segmentti\n",
      "para\n",
      "kasvaa\n",
      "para\n",
      "segmentti\n",
      "kasvaa\n",
      "segmentti\n",
      "\n",
      "Keywords Found:\n",
      "  • liikevaihto          [████████████████████] (1.00)\n",
      "  • vuosineljännes       [████████████████████] (1.00)\n",
      "  • vahvistua            [████████████████████] (1.00)\n",
      "  • asiakaspysyvyys      [████████████████████] (1.00)\n",
      "  • asiakashankinta      [█████████████████░░░] (0.88)\n",
      "  • kasvu                [████████████████░░░░] (0.83)\n",
      "  • prosentti            [███████████████░░░░░] (0.78)\n",
      "  • markkinaosuus        [███████████████░░░░░] (0.76)\n",
      "  • pilvipalvelu         [███████████████░░░░░] (0.76)\n",
      "  • kustannus            [███████████░░░░░░░░░] (0.58)\n",
      "\n",
      "Debug Information:\n",
      "--------------------\n",
      "{\n",
      "  \"keywords\": [\n",
      "    {\n",
      "      \"keyword\": \"liikevaihto\",\n",
      "      \"score\": 1.0,\n",
      "      \"domain\": \"business\",\n",
      "      \"compound_parts\": [\n",
      "        \"liike\",\n",
      "        \"vaihto\"\n",
      "      ]\n",
      "    },\n",
      "    {\n",
      "      \"keyword\": \"vuosinelj\\u00e4nnes\",\n",
      "      \"score\": 1.0,\n",
      "      \"domain\": \"business\",\n",
      "      \"compound_parts\": [\n",
      "        \"vuosi\",\n",
      "        \"nelj\\u00e4nnes\"\n",
      "      ]\n",
      "    },\n",
      "    {\n",
      "      \"keyword\": \"vahvistua\",\n",
      "      \"score\": 1.0,\n",
      "      \"domain\": \"business\",\n",
      "      \"compound_parts\": [\n",
      "        \"vahvist\",\n",
      "        \"ua\"\n",
      "      ]\n",
      "    },\n",
      "    {\n",
      "      \"keyword\": \"asiakaspysyvyys\",\n",
      "      \"score\": 1.0,\n",
      "      \"domain\": null,\n",
      "      \"compound_parts\": [\n",
      "        \"asiakas\",\n",
      "        \"pysy\",\n",
      "        \"vy\",\n",
      "        \"ys\"\n",
      "      ]\n",
      "    },\n",
      "    {\n",
      "      \"keyword\": \"asiakashankinta\",\n",
      "      \"score\": 0.8808800000000001,\n",
      "      \"domain\": null,\n",
      "      \"compound_parts\": [\n",
      "        \"asiakas\",\n",
      "        \"hanki\",\n",
      "        \"ta\"\n",
      "      ]\n",
      "    },\n",
      "    {\n",
      "      \"keyword\": \"kasvu\",\n",
      "      \"score\": 0.82764,\n",
      "      \"domain\": \"business\",\n",
      "      \"compound_parts\": [\n",
      "        \"kasvu\"\n",
      "      ]\n",
      "    },\n",
      "    {\n",
      "      \"keyword\": \"prosentti\",\n",
      "      \"score\": 0.7840800000000002,\n",
      "      \"domain\": \"business\",\n",
      "      \"compound_parts\": [\n",
      "        \"prosentti\"\n",
      "      ]\n",
      "    },\n",
      "    {\n",
      "      \"keyword\": \"markkinaosuus\",\n",
      "      \"score\": 0.76032,\n",
      "      \"domain\": null,\n",
      "      \"compound_parts\": [\n",
      "        \"markkina\",\n",
      "        \"osuus\"\n",
      "      ]\n",
      "    },\n",
      "    {\n",
      "      \"keyword\": \"pilvipalvelu\",\n",
      "      \"score\": 0.76032,\n",
      "      \"domain\": null,\n",
      "      \"compound_parts\": [\n",
      "        \"pilvi\",\n",
      "        \"palvelu\"\n",
      "      ]\n",
      "    },\n",
      "    {\n",
      "      \"keyword\": \"kustannus\",\n",
      "      \"score\": 0.5808000000000001,\n",
      "      \"domain\": null,\n",
      "      \"compound_parts\": [\n",
      "        \"kustannus\"\n",
      "      ]\n",
      "    }\n",
      "  ],\n",
      "  \"compound_words\": [\n",
      "    \"liikevaihto\",\n",
      "    \"vuosinelj\\u00e4nnes\",\n",
      "    \"vahvistua\",\n",
      "    \"asiakaspysyvyys\",\n",
      "    \"asiakashankinta\",\n",
      "    \"kasvu\",\n",
      "    \"prosentti\",\n",
      "    \"markkinaosuus\",\n",
      "    \"pilvipalvelu\",\n",
      "    \"kustannus\"\n",
      "  ],\n",
      "  \"domain_keywords\": {\n",
      "    \"business\": [\n",
      "      \"liikevaihto\",\n",
      "      \"vuosinelj\\u00e4nnes\",\n",
      "      \"vahvistua\",\n",
      "      \"kasvu\",\n",
      "      \"prosentti\"\n",
      "    ]\n",
      "  },\n",
      "  \"language\": \"fi\",\n",
      "  \"success\": true,\n",
      "  \"error\": null\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "# test_case = \"technical_fi_1\"\n",
    "test_case = \"business_fi_1\"\n",
    "\n",
    "results = await test_keyword_analyzer(finnish_texts[test_case], language=\"fi\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-19 20:33:35,115 - src.nb_helpers.analyzers - DEBUG - Starting keyword analysis\n",
      "2024-11-19 20:33:35,119 - src.utils.FileUtils.file_utils - DEBUG [file_utils.py:192] - Initialized FileUtils with log level: INFO\n",
      "2024-11-19 20:33:35,119 - src.utils.FileUtils.file_utils - DEBUG - Initialized FileUtils with log level: INFO\n",
      "2024-11-19 20:33:35,122 - src.utils.FileUtils.file_utils - DEBUG [file_utils.py:198] - Project root: c:\\Users\\tja\\OneDrive - Rastor-instituutti ry\\Tiedostot\\Rastor-instituutti\\kehittäminen\\analytiikka\\repos\\semantic-text-analyzer\n",
      "2024-11-19 20:33:35,122 - src.utils.FileUtils.file_utils - DEBUG - Project root: c:\\Users\\tja\\OneDrive - Rastor-instituutti ry\\Tiedostot\\Rastor-instituutti\\kehittäminen\\analytiikka\\repos\\semantic-text-analyzer\n",
      "2024-11-19 20:33:35,128 - src.nb_helpers.analyzers - DEBUG - Initialized TextAnalyzer with options: AnalysisOptions(show_confidence=True, show_evidence=True, show_keywords=True, show_raw_data=True, debug_mode=True, language='en', parameter_file=None)\n",
      "2024-11-19 20:33:35,130 - src.core.language_processing.factory - DEBUG - Using default configuration\n",
      "2024-11-19 20:33:35,132 - src.core.language_processing.factory - DEBUG - Creating en processor\n",
      "2024-11-19 20:33:35,136 - src.utils.FileUtils.file_utils - DEBUG [file_utils.py:192] - Initialized FileUtils with log level: INFO\n",
      "2024-11-19 20:33:35,136 - src.utils.FileUtils.file_utils - DEBUG - Initialized FileUtils with log level: INFO\n",
      "2024-11-19 20:33:35,139 - src.utils.FileUtils.file_utils - DEBUG [file_utils.py:198] - Project root: c:\\Users\\tja\\OneDrive - Rastor-instituutti ry\\Tiedostot\\Rastor-instituutti\\kehittäminen\\analytiikka\\repos\\semantic-text-analyzer\n",
      "2024-11-19 20:33:35,139 - src.utils.FileUtils.file_utils - DEBUG - Project root: c:\\Users\\tja\\OneDrive - Rastor-instituutti ry\\Tiedostot\\Rastor-instituutti\\kehittäminen\\analytiikka\\repos\\semantic-text-analyzer\n",
      "2024-11-19 20:33:35,162 - src.core.language_processing.english - DEBUG - Loaded 179 NLTK stopwords\n",
      "2024-11-19 20:33:35,183 - src.core.language_processing.english - DEBUG - Loaded 733 additional stopwords from file\n",
      "2024-11-19 20:33:35,186 - src.core.language_processing.english - DEBUG - Total English stopwords: 831\n",
      "2024-11-19 20:33:35,187 - src.core.language_processing.english - DEBUG - Initialized English processor with 831 stopwords\n",
      "2024-11-19 20:33:36,725 - src.utils.FileUtils.file_utils - DEBUG [file_utils.py:192] - Initialized FileUtils with log level: INFO\n",
      "2024-11-19 20:33:36,725 - src.utils.FileUtils.file_utils - DEBUG - Initialized FileUtils with log level: INFO\n",
      "2024-11-19 20:33:36,727 - src.utils.FileUtils.file_utils - DEBUG [file_utils.py:198] - Project root: c:\\Users\\tja\\OneDrive - Rastor-instituutti ry\\Tiedostot\\Rastor-instituutti\\kehittäminen\\analytiikka\\repos\\semantic-text-analyzer\n",
      "2024-11-19 20:33:36,727 - src.utils.FileUtils.file_utils - DEBUG - Project root: c:\\Users\\tja\\OneDrive - Rastor-instituutti ry\\Tiedostot\\Rastor-instituutti\\kehittäminen\\analytiikka\\repos\\semantic-text-analyzer\n",
      "2024-11-19 20:33:36,739 - src.nb_helpers.analyzers - DEBUG - Running keyword analysis\n",
      "2024-11-19 20:33:36,741 - src.nb_helpers.testers - DEBUG - KeywordTester starting analysis\n",
      "2024-11-19 20:33:36,742 - src.analyzers.keyword_analyzer - DEBUG - Starting keyword analysis\n",
      "2024-11-19 20:33:44,429 - src.analyzers.keyword_analyzer - DEBUG - Applied domain boost (1.2) to infrastructure\n",
      "2024-11-19 20:33:44,431 - src.analyzers.keyword_analyzer - DEBUG - Applied domain boost (1.15) to cost\n",
      "2024-11-19 20:33:44,432 - src.analyzers.keyword_analyzer - DEBUG - Applied compound bonus to cloud-native\n",
      "2024-11-19 20:33:44,434 - src.analyzers.keyword_analyzer - DEBUG - Applied domain boost (1.15) to revenue\n",
      "2024-11-19 20:33:44,436 - src.analyzers.keyword_analyzer - DEBUG - Applied domain boost (1.2) to deployment\n",
      "2024-11-19 20:33:44,452 - src.analyzers.keyword_analyzer - DEBUG - Applied domain boost (1.2) to infrastructure\n",
      "2024-11-19 20:33:44,458 - src.analyzers.keyword_analyzer - DEBUG - Applied domain boost (1.15) to cost\n",
      "2024-11-19 20:33:44,460 - src.analyzers.keyword_analyzer - DEBUG - Applied compound bonus to cloud-native\n",
      "2024-11-19 20:33:44,462 - src.analyzers.keyword_analyzer - DEBUG - Applied domain boost (1.15) to revenue\n",
      "2024-11-19 20:33:44,463 - src.analyzers.keyword_analyzer - DEBUG - Applied domain boost (1.2) to deployment\n",
      "2024-11-19 20:33:50,080 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-11-19 20:33:50,088 - src.analyzers.keyword_analyzer - DEBUG - Got LLM response for keyword analysis\n",
      "2024-11-19 20:33:50,089 - src.analyzers.keyword_analyzer - DEBUG - Processed LLM keyword: cloud-native solutions\n",
      "2024-11-19 20:33:50,090 - src.analyzers.keyword_analyzer - DEBUG - Processed LLM keyword: monthly recurring revenue\n",
      "2024-11-19 20:33:50,091 - src.analyzers.keyword_analyzer - DEBUG - Processed LLM keyword: SaaS products\n",
      "2024-11-19 20:33:50,093 - src.analyzers.keyword_analyzer - DEBUG - Processed LLM keyword: deployment frequency\n",
      "2024-11-19 20:33:50,095 - src.analyzers.keyword_analyzer - DEBUG - Processed LLM keyword: infrastructure costs\n",
      "2024-11-19 20:33:50,096 - src.analyzers.keyword_analyzer - DEBUG - Applied domain boost (1.2) to infrastructure\n",
      "2024-11-19 20:33:50,097 - src.analyzers.keyword_analyzer - DEBUG - Applied domain boost (1.15) to cost\n",
      "2024-11-19 20:33:50,099 - src.analyzers.keyword_analyzer - DEBUG - Applied compound bonus to cloud-native\n",
      "2024-11-19 20:33:50,100 - src.analyzers.keyword_analyzer - DEBUG - Applied domain boost (1.15) to revenue\n",
      "2024-11-19 20:33:50,102 - src.analyzers.keyword_analyzer - DEBUG - Applied domain boost (1.2) to deployment\n",
      "2024-11-19 20:33:50,103 - src.analyzers.keyword_analyzer - DEBUG - Applied compound bonus to cloud-native solutions\n",
      "2024-11-19 20:33:50,105 - src.analyzers.keyword_analyzer - DEBUG - Applied compound bonus to SaaS products\n",
      "2024-11-19 20:33:50,159 - src.analyzers.keyword_analyzer - DEBUG - Applied POS penalty to monthly (RB)\n",
      "2024-11-19 20:33:50,162 - src.analyzers.keyword_analyzer - DEBUG - Applied POS penalty to steadily (RB)\n",
      "2024-11-19 20:33:50,164 - src.analyzers.keyword_analyzer - DEBUG - Applied generic penalty to improve\n",
      "2024-11-19 20:33:50,165 - src.analyzers.keyword_analyzer - DEBUG - Applied POS penalty to improve (VB)\n",
      "2024-11-19 20:33:50,167 - src.analyzers.keyword_analyzer - DEBUG - Analysis complete. Found 10 keywords\n",
      "2024-11-19 20:33:50,169 - src.nb_helpers.testers - DEBUG - KeywordTester analysis complete\n",
      "2024-11-19 20:33:50,171 - src.nb_helpers.analyzers - DEBUG - Keyword analysis completed\n",
      "2024-11-19 20:33:50,172 - src.nb_helpers.analyzers - DEBUG - Formatting results\n",
      "2024-11-19 20:33:50,173 - src.nb_helpers.analyzers - DEBUG - Displaying debug information\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Keywords Found:\n",
      "  • cloud-native solutions [████████████████████] (1.00)\n",
      "  • SaaS products        [████████████████████] (1.00)\n",
      "  • monthly recurring revenue [██████████████░░░░░░] (0.71)\n",
      "  • cloud-native         [█████████████░░░░░░░] (0.70)\n",
      "  • deployment frequency [█████████████░░░░░░░] (0.70)\n",
      "  • infrastructure costs [█████████████░░░░░░░] (0.69)\n",
      "  • infrastructure       [████████████░░░░░░░░] (0.63)\n",
      "  • deployment           [████████████░░░░░░░░] (0.63)\n",
      "  • cost                 [████████████░░░░░░░░] (0.61)\n",
      "  • revenue              [████████████░░░░░░░░] (0.61)\n",
      "\n",
      "Debug Information:\n",
      "--------------------\n",
      "{\n",
      "  \"keywords\": [\n",
      "    {\n",
      "      \"keyword\": \"cloud-native solutions\",\n",
      "      \"score\": 1.0,\n",
      "      \"domain\": \"technical\",\n",
      "      \"compound_parts\": [\n",
      "        \"cloud\",\n",
      "        \"native solutions\"\n",
      "      ]\n",
      "    },\n",
      "    {\n",
      "      \"keyword\": \"SaaS products\",\n",
      "      \"score\": 1.0,\n",
      "      \"domain\": \"technical\",\n",
      "      \"compound_parts\": [\n",
      "        \"saa\",\n",
      "        \"s products\"\n",
      "      ]\n",
      "    },\n",
      "    {\n",
      "      \"keyword\": \"monthly recurring revenue\",\n",
      "      \"score\": 0.7128000000000001,\n",
      "      \"domain\": \"business\",\n",
      "      \"compound_parts\": null\n",
      "    },\n",
      "    {\n",
      "      \"keyword\": \"cloud-native\",\n",
      "      \"score\": 0.6969600000000001,\n",
      "      \"domain\": \"technical\",\n",
      "      \"compound_parts\": [\n",
      "        \"cloud\",\n",
      "        \"native\"\n",
      "      ]\n",
      "    },\n",
      "    {\n",
      "      \"keyword\": \"deployment frequency\",\n",
      "      \"score\": 0.6969600000000001,\n",
      "      \"domain\": \"technical\",\n",
      "      \"compound_parts\": null\n",
      "    },\n",
      "    {\n",
      "      \"keyword\": \"infrastructure costs\",\n",
      "      \"score\": 0.68904,\n",
      "      \"domain\": \"business\",\n",
      "      \"compound_parts\": null\n",
      "    },\n",
      "    {\n",
      "      \"keyword\": \"infrastructure\",\n",
      "      \"score\": 0.6336,\n",
      "      \"domain\": \"technical\",\n",
      "      \"compound_parts\": null\n",
      "    },\n",
      "    {\n",
      "      \"keyword\": \"deployment\",\n",
      "      \"score\": 0.6336,\n",
      "      \"domain\": \"technical\",\n",
      "      \"compound_parts\": null\n",
      "    },\n",
      "    {\n",
      "      \"keyword\": \"cost\",\n",
      "      \"score\": 0.6072,\n",
      "      \"domain\": \"business\",\n",
      "      \"compound_parts\": null\n",
      "    },\n",
      "    {\n",
      "      \"keyword\": \"revenue\",\n",
      "      \"score\": 0.6072,\n",
      "      \"domain\": \"business\",\n",
      "      \"compound_parts\": null\n",
      "    }\n",
      "  ],\n",
      "  \"compound_words\": [\n",
      "    \"cloud-native solutions\",\n",
      "    \"SaaS products\",\n",
      "    \"cloud-native\"\n",
      "  ],\n",
      "  \"domain_keywords\": {\n",
      "    \"technical\": [\n",
      "      \"cloud-native solutions\",\n",
      "      \"SaaS products\",\n",
      "      \"cloud-native\",\n",
      "      \"deployment frequency\",\n",
      "      \"infrastructure\",\n",
      "      \"deployment\"\n",
      "    ],\n",
      "    \"business\": [\n",
      "      \"monthly recurring revenue\",\n",
      "      \"infrastructure costs\",\n",
      "      \"cost\",\n",
      "      \"revenue\"\n",
      "    ]\n",
      "  },\n",
      "  \"language\": \"en\",\n",
      "  \"success\": true,\n",
      "  \"error\": null\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "test_case = \"Mixed Domain Content\"\n",
    "results = await test_keyword_analyzer(test_texts[test_case])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-19 16:03:37,320 - src.nb_helpers.analyzers - DEBUG - Starting keyword analysis\n",
      "2024-11-19 16:03:37,324 - src.utils.FileUtils.file_utils - DEBUG [file_utils.py:192] - Initialized FileUtils with log level: INFO\n",
      "2024-11-19 16:03:37,324 - src.utils.FileUtils.file_utils - DEBUG - Initialized FileUtils with log level: INFO\n",
      "2024-11-19 16:03:37,327 - src.utils.FileUtils.file_utils - DEBUG [file_utils.py:198] - Project root: c:\\Users\\tja\\OneDrive - Rastor-instituutti ry\\Tiedostot\\Rastor-instituutti\\kehittäminen\\analytiikka\\repos\\semantic-text-analyzer\n",
      "2024-11-19 16:03:37,327 - src.utils.FileUtils.file_utils - DEBUG - Project root: c:\\Users\\tja\\OneDrive - Rastor-instituutti ry\\Tiedostot\\Rastor-instituutti\\kehittäminen\\analytiikka\\repos\\semantic-text-analyzer\n",
      "2024-11-19 16:03:37,334 - src.nb_helpers.analyzers - DEBUG - Initialized TextAnalyzer with options: AnalysisOptions(show_confidence=True, show_evidence=True, show_keywords=True, show_raw_data=True, debug_mode=True, language='en', parameter_file=None)\n",
      "2024-11-19 16:03:37,335 - src.core.language_processing.factory - DEBUG - Using default configuration\n",
      "2024-11-19 16:03:37,337 - src.core.language_processing.factory - DEBUG - Creating en processor\n",
      "2024-11-19 16:03:37,341 - src.utils.FileUtils.file_utils - DEBUG [file_utils.py:192] - Initialized FileUtils with log level: INFO\n",
      "2024-11-19 16:03:37,341 - src.utils.FileUtils.file_utils - DEBUG - Initialized FileUtils with log level: INFO\n",
      "2024-11-19 16:03:37,343 - src.utils.FileUtils.file_utils - DEBUG [file_utils.py:198] - Project root: c:\\Users\\tja\\OneDrive - Rastor-instituutti ry\\Tiedostot\\Rastor-instituutti\\kehittäminen\\analytiikka\\repos\\semantic-text-analyzer\n",
      "2024-11-19 16:03:37,343 - src.utils.FileUtils.file_utils - DEBUG - Project root: c:\\Users\\tja\\OneDrive - Rastor-instituutti ry\\Tiedostot\\Rastor-instituutti\\kehittäminen\\analytiikka\\repos\\semantic-text-analyzer\n",
      "2024-11-19 16:03:37,352 - src.core.language_processing.english - DEBUG - Loaded 179 NLTK stopwords\n",
      "2024-11-19 16:03:37,356 - src.core.language_processing.english - DEBUG - Loaded 733 additional stopwords from file\n",
      "2024-11-19 16:03:37,357 - src.core.language_processing.english - DEBUG - Total English stopwords: 831\n",
      "2024-11-19 16:03:37,358 - src.core.language_processing.english - DEBUG - Initialized English processor with 831 stopwords\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Testing: Technical Compound Terms\n",
      "==================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-19 16:03:38,675 - src.utils.FileUtils.file_utils - DEBUG [file_utils.py:192] - Initialized FileUtils with log level: INFO\n",
      "2024-11-19 16:03:38,675 - src.utils.FileUtils.file_utils - DEBUG - Initialized FileUtils with log level: INFO\n",
      "2024-11-19 16:03:38,677 - src.utils.FileUtils.file_utils - DEBUG [file_utils.py:198] - Project root: c:\\Users\\tja\\OneDrive - Rastor-instituutti ry\\Tiedostot\\Rastor-instituutti\\kehittäminen\\analytiikka\\repos\\semantic-text-analyzer\n",
      "2024-11-19 16:03:38,677 - src.utils.FileUtils.file_utils - DEBUG - Project root: c:\\Users\\tja\\OneDrive - Rastor-instituutti ry\\Tiedostot\\Rastor-instituutti\\kehittäminen\\analytiikka\\repos\\semantic-text-analyzer\n",
      "2024-11-19 16:03:38,686 - src.nb_helpers.analyzers - DEBUG - Running keyword analysis\n",
      "2024-11-19 16:03:38,675 - src.utils.FileUtils.file_utils - DEBUG - Initialized FileUtils with log level: INFO\n",
      "2024-11-19 16:03:38,677 - src.utils.FileUtils.file_utils - DEBUG [file_utils.py:198] - Project root: c:\\Users\\tja\\OneDrive - Rastor-instituutti ry\\Tiedostot\\Rastor-instituutti\\kehittäminen\\analytiikka\\repos\\semantic-text-analyzer\n",
      "2024-11-19 16:03:38,677 - src.utils.FileUtils.file_utils - DEBUG - Project root: c:\\Users\\tja\\OneDrive - Rastor-instituutti ry\\Tiedostot\\Rastor-instituutti\\kehittäminen\\analytiikka\\repos\\semantic-text-analyzer\n",
      "2024-11-19 16:03:38,686 - src.nb_helpers.analyzers - DEBUG - Running keyword analysis\n",
      "2024-11-19 16:03:38,688 - src.nb_helpers.testers - DEBUG - KeywordTester starting analysis\n",
      "2024-11-19 16:03:38,690 - src.analyzers.keyword_analyzer - DEBUG - Starting keyword analysis\n",
      "2024-11-19 16:03:38,695 - src.analyzers.keyword_analyzer - DEBUG - Applied domain boost (1.2) to cloud\n",
      "2024-11-19 16:03:38,713 - src.analyzers.keyword_analyzer - DEBUG - Applied domain boost (1.2) to devops\n",
      "2024-11-19 16:03:38,717 - src.analyzers.keyword_analyzer - DEBUG - Applied compound bonus to devops\n",
      "2024-11-19 16:03:38,723 - src.analyzers.keyword_analyzer - DEBUG - Applied compound bonus to streamline\n",
      "2024-11-19 16:03:38,728 - src.analyzers.keyword_analyzer - DEBUG - Applied domain boost (1.2) to deployment\n",
      "2024-11-19 16:03:38,737 - src.analyzers.keyword_analyzer - DEBUG - Applied domain boost (1.2) to pipeline\n",
      "2024-11-19 16:03:38,738 - src.analyzers.keyword_analyzer - DEBUG - Applied compound bonus to pipeline\n",
      "2024-11-19 16:03:38,743 - src.analyzers.keyword_analyzer - DEBUG - Applied domain boost (1.2) to microservices\n",
      "2024-11-19 16:03:38,749 - src.analyzers.keyword_analyzer - DEBUG - Applied domain boost (1.2) to architecture\n",
      "2024-11-19 16:03:38,757 - src.analyzers.keyword_analyzer - DEBUG - Applied domain boost (1.2) to api\n",
      "2024-11-19 16:03:38,761 - src.analyzers.keyword_analyzer - DEBUG - Applied domain boost (1.2) to integration\n",
      "2024-11-19 16:03:38,784 - src.analyzers.keyword_analyzer - DEBUG - Applied domain boost (1.2) to cloud\n",
      "2024-11-19 16:03:38,788 - src.analyzers.keyword_analyzer - DEBUG - Applied domain boost (1.2) to devops\n",
      "2024-11-19 16:03:38,789 - src.analyzers.keyword_analyzer - DEBUG - Applied compound bonus to devops\n",
      "2024-11-19 16:03:38,790 - src.analyzers.keyword_analyzer - DEBUG - Applied compound bonus to streamline\n",
      "2024-11-19 16:03:38,792 - src.analyzers.keyword_analyzer - DEBUG - Applied domain boost (1.2) to deployment\n",
      "2024-11-19 16:03:38,794 - src.analyzers.keyword_analyzer - DEBUG - Applied domain boost (1.2) to pipeline\n",
      "2024-11-19 16:03:38,796 - src.analyzers.keyword_analyzer - DEBUG - Applied compound bonus to pipeline\n",
      "2024-11-19 16:03:38,797 - src.analyzers.keyword_analyzer - DEBUG - Applied domain boost (1.2) to microservices\n",
      "2024-11-19 16:03:38,799 - src.analyzers.keyword_analyzer - DEBUG - Applied domain boost (1.2) to architecture\n",
      "2024-11-19 16:03:38,800 - src.analyzers.keyword_analyzer - DEBUG - Applied domain boost (1.2) to api\n",
      "2024-11-19 16:03:38,803 - src.analyzers.keyword_analyzer - DEBUG - Applied domain boost (1.2) to integration\n"
     ]
    }
   ],
   "source": [
    "# Run tests\n",
    "for case_name, text in test_texts.items():\n",
    "    print(f\"\\nTesting: {case_name}\")\n",
    "    print(\"=\" * 50)\n",
    "    results = await test_keyword_analyzer(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "previous examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "STOP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # 2. Test single language analysis\n",
    "# print(\"\\nSingle Language Analysis:\")\n",
    "# print(\"-\" * 50)\n",
    "\n",
    "# options_en = AnalysisOptions(\n",
    "#     show_confidence=True,\n",
    "#     show_evidence=True,\n",
    "#     show_keywords=True,\n",
    "#     show_raw_data=True,\n",
    "#     debug_mode=True,\n",
    "#     language=\"en\"  # Explicitly set language\n",
    "# )\n",
    "\n",
    "# # Analyze English text\n",
    "# text = example_texts[\"English Technical\"]\n",
    "# results_en = await analyze_keywords(text, options_en)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Test Finnish keyword analysis\n",
    "# print(\"\\nTest Finnish keyword analysis:\")\n",
    "# print(\"-\" * 50)\n",
    "\n",
    "# options_fi = AnalysisOptions(\n",
    "#     show_confidence=True,\n",
    "#     show_evidence=True,\n",
    "#     debug_mode=True,\n",
    "#     language=\"fi\"  # Explicitly set language\n",
    "# )\n",
    "\n",
    "# # Analyze Finnish text with auto-detection\n",
    "# text = example_texts[\"Finnish Technical\"]\n",
    "# # results_fi = await analyze_text(text, options_fi)\n",
    "# keywords_fi = await analyze_keywords(text, options_fi)\n",
    "\n",
    "\n",
    "# # # 4. Test batch analysis with mixed languages\n",
    "# # print(\"\\nBatch Analysis with Mixed Languages:\")\n",
    "# # print(\"-\" * 50)\n",
    "\n",
    "# # batch_results = {}\n",
    "# # for name, text in example_texts.items():\n",
    "# #     print(f\"\\nAnalyzing {name}:\")\n",
    "# #     results = await analyze_text(text, options_auto)\n",
    "# #     batch_results[name] = results\n",
    "\n",
    "# # # 5. Test Excel file processing\n",
    "# # from src.nb_helpers.analyzers import analyze_excel_content\n",
    "\n",
    "# # # Create a test DataFrame\n",
    "# # import pandas as pd\n",
    "# # df = pd.DataFrame({\n",
    "# #     \"content\": example_texts.values(),\n",
    "# #     \"type\": [name.split()[0] for name in example_texts.keys()],  # \"English\" or \"Finnish\"\n",
    "# # })\n",
    "\n",
    "# # # Save to temporary Excel file\n",
    "# # temp_excel = \"temp_test_content.xlsx\"\n",
    "# # df.to_excel(temp_excel, index=False)\n",
    "\n",
    "# # print(\"\\nExcel File Analysis:\")\n",
    "# # print(\"-\" * 50)\n",
    "\n",
    "# # await analyze_excel_content(\n",
    "# #     input_file=temp_excel,\n",
    "# #     output_file=\"analysis_results\",\n",
    "# #     content_column=\"content\",\n",
    "# #     parameter_file=\"parameters_en.xlsx\",  # Use our parameter file\n",
    "# #     language_column=\"type\"  # Use type column for language\n",
    "# # )\n",
    "\n",
    "# # # Clean up temporary file\n",
    "# # os.remove(temp_excel)\n",
    "\n",
    "# # # 6. Compare analysis results\n",
    "# # print(\"\\nAnalysis Results Comparison:\")\n",
    "# # print(\"-\" * 50)\n",
    "\n",
    "# # def print_analysis_summary(results: dict, name: str):\n",
    "# #     print(f\"\\n{name}:\")\n",
    "# #     if \"keywords\" in results:\n",
    "# #         keywords = results[\"keywords\"].get(\"keywords\", [])\n",
    "# #         print(f\"Keywords found: {len(keywords)}\")\n",
    "# #         for kw in keywords[:3]:  # Show top 3 keywords\n",
    "# #             print(f\"- {kw.keyword}: {kw.score:.2f}\")\n",
    "    \n",
    "# #     if \"themes\" in results:\n",
    "# #         themes = results[\"themes\"].get(\"themes\", [])\n",
    "# #         print(f\"Themes found: {len(themes)}\")\n",
    "# #         for theme in themes[:2]:  # Show top 2 themes\n",
    "# #             print(f\"- {theme.name}: {theme.confidence:.2f}\")\n",
    "            \n",
    "# #     if \"categories\" in results:\n",
    "# #         categories = results[\"categories\"].get(\"categories\", [])\n",
    "# #         print(f\"Categories found: {len(categories)}\")\n",
    "# #         for cat in categories[:2]:  # Show top 2 categories\n",
    "# #             print(f\"- {cat.name}: {cat.confidence:.2f}\")\n",
    "\n",
    "# # for name, results in batch_results.items():\n",
    "# #     print_analysis_summary(results, name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run environment verification\n",
    "# from src.nb_helpers.environment import verify_environment\n",
    "# verify_environment()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-19 17:09:13,064 - src.analyzers.keyword_analyzer - DEBUG - Testing keyword analyzer logging\n"
     ]
    }
   ],
   "source": [
    "# Test logging\n",
    "logger = logging.getLogger(\"src.analyzers.keyword_analyzer\")\n",
    "logger.debug(\"Testing keyword analyzer logging\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NOTE: following are not working with the new parameter handling model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example texts in different languages\n",
    "example_texts = {\n",
    "    \"English Technical\": \"\"\"\n",
    "        The cloud migration project improved system scalability while reducing costs.\n",
    "        New DevOps practices streamlined the deployment pipeline significantly.\n",
    "    \"\"\",\n",
    "    \n",
    "    \"Finnish Technical\": \"\"\"\n",
    "        Pilvipalveluihin siirtyminen paransi järjestelmän skaalautuvuutta ja vähensi kustannuksia.\n",
    "        Uudet DevOps-käytännöt tehostivat merkittävästi käyttöönottoprosessia.\n",
    "    \"\"\"\n",
    "}\n",
    "\n",
    "# Analyze with automatic language detection\n",
    "for name, text in example_texts.items():\n",
    "    print(f\"\\nAnalyzing {name}:\")\n",
    "    results = await analyze_text(text, options)\n",
    "\n",
    "# Example with specific language and parameters\n",
    "fi_options = AnalysisOptions(\n",
    "    show_confidence=True,\n",
    "    show_evidence=True,\n",
    "    debug_mode=True,\n",
    "    language=\"fi\",\n",
    "    parameter_file=\"finnish_params.yaml\"\n",
    ")\n",
    "\n",
    "# Analyze Finnish text with specific parameters\n",
    "fi_results = await analyze_text(example_texts[\"Finnish Technical\"], fi_options)\n",
    "\n",
    "# Batch process Excel file with language detection\n",
    "await analyze_excel_content(\n",
    "    input_file=\"multilingual_texts.xlsx\",\n",
    "    output_file=\"analysis_results\",\n",
    "    content_column=\"content\",\n",
    "    parameter_file=\"analysis_params.yaml\",\n",
    "    language_column=\"language\"  # Optional column specifying language\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!-- ## Analysis Functions\n",
    "\n",
    "### Single Analysis with Debug Output\n",
    "Run detailed analysis for a single text: -->\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "example_texts = {\n",
    "    \"Business Analysis\": \"\"\"\n",
    "        Q3 revenue increased by 15% with strong growth in enterprise sales.\n",
    "        Customer retention improved while acquisition costs decreased.\n",
    "        New market expansion initiatives are showing positive early results.\n",
    "    \"\"\",\n",
    "    \n",
    "    \"Technical Content\": \"\"\"\n",
    "        The application uses microservices architecture with containerized deployments.\n",
    "        Data processing pipeline incorporates machine learning models for prediction.\n",
    "        System monitoring ensures high availability and performance metrics.\n",
    "    \"\"\",\n",
    "    \n",
    "    \"Mixed Content\": \"\"\"\n",
    "        The IT department's cloud migration project reduced infrastructure costs by 25%.\n",
    "        DevOps implementation improved deployment frequency while maintaining quality.\n",
    "        Monthly recurring revenue from SaaS products grew steadily.\n",
    "    \"\"\",\n",
    "    \"koulutus\":\n",
    "    \"\"\"\n",
    "        Verkko-oppimisalusta sisältää interaktiivisia moduuleja ja oman tahdin edistymisen seurannan. \n",
    "        Virtuaaliluokat mahdollistavat reaaliaikaisen yhteistyön opiskelijoiden ja ohjaajien välillä. \n",
    "        Digitaaliset arviointityökalut antavat välitöntä palautetta oppimistuloksista.\n",
    "    \"\"\",\n",
    "    \"tekninen\":\n",
    "    \"\"\"\n",
    "        Koneoppimismalleja koulutetaan suurilla datajoukolla tunnistamaan kaavoja. \n",
    "        Neuroverkon arkkitehtuuri sisältää useita kerroksia piirteiden erottamiseen. \n",
    "        Datan esikäsittely ja piirteiden suunnittelu ovat keskeisiä vaiheita prosessissa.\n",
    "\n",
    "    \"\"\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # New imports\n",
    "# from src.core.language_parameters import LanguageParameterManager\n",
    "\n",
    "# # Initialize parameter manager\n",
    "# param_manager = LanguageParameterManager()\n",
    "\n",
    "# # Example analysis with automatic language detection\n",
    "# text_en = \"Cloud computing enables scalable infrastructure deployment.\"\n",
    "# text_fi = \"Pilvipalvelut mahdollistavat skaalautuvan infrastruktuurin käyttöönoton.\"\n",
    "\n",
    "# # Analyze with automatic language detection and default parameters\n",
    "# async def analyze_text_with_language(text: str, parameter_file: Optional[str] = None):\n",
    "#     \"\"\"Analyze text with automatic language handling.\"\"\"\n",
    "#     # Get language-specific parameters\n",
    "#     params = param_manager.get_parameters(text, parameter_file)\n",
    "    \n",
    "#     # Create analyzers with parameters\n",
    "#     keyword_analyzer = KeywordAnalyzer(config=params.dict())\n",
    "#     theme_analyzer = ThemeAnalyzer(config=params.dict())\n",
    "#     category_analyzer = CategoryAnalyzer(config=params.dict())\n",
    "    \n",
    "#     # Run analysis\n",
    "#     results = {\n",
    "#         \"keywords\": await keyword_analyzer.analyze(text),\n",
    "#         \"themes\": await theme_analyzer.analyze(text),\n",
    "#         \"categories\": await category_analyzer.analyze(text)\n",
    "#     }\n",
    "    \n",
    "#     return results\n",
    "\n",
    "# # Example with Excel parameters\n",
    "# async def analyze_batch_with_excel_params(texts: List[str], excel_params: str):\n",
    "#     \"\"\"Analyze texts using parameters from Excel.\"\"\"\n",
    "#     # Load language-specific parameters\n",
    "#     params_by_lang = param_manager.load_excel_parameters(excel_params)\n",
    "    \n",
    "#     results = []\n",
    "#     for text in texts:\n",
    "#         # Detect language\n",
    "#         lang = param_manager.detect_language(text)\n",
    "#         # Get parameters for language\n",
    "#         params = params_by_lang.get(lang, param_manager.get_parameters(text))\n",
    "        \n",
    "#         # Create analyzer with language-specific parameters\n",
    "#         analyzer = KeywordAnalyzer(config=params.dict())\n",
    "#         result = await analyzer.analyze(text)\n",
    "#         results.append(result)\n",
    "    \n",
    "#     return results\n",
    "\n",
    "# # Example usage:\n",
    "# # With default parameters\n",
    "# results_en = await analyze_text_with_language(text_en)\n",
    "\n",
    "# # With parameter file\n",
    "# results_fi = await analyze_text_with_language(text_fi, \"finnish_params.yaml\")\n",
    "\n",
    "# # With Excel parameters\n",
    "# texts = [text_en, text_fi]\n",
    "# batch_results = await analyze_batch_with_excel_params(texts, \"analysis_params.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# text = example_texts[\"Mixed Content\"]\n",
    "# text = example_texts[\"koulutussisältö\"]\n",
    "# Debug specific analyzer\n",
    "\n",
    "# Example usage\n",
    "text = example_texts[\"Mixed Content\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'options' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[12], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mawait\u001b[39;00m analyze_keywords(text, options\u001b[38;5;241m=\u001b[39moptions)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'options' is not defined"
     ]
    }
   ],
   "source": [
    "await analyze_keywords(text, options=options)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Debug Theme Analysis\n",
      "==================================================\n",
      "\n",
      "Input Text:\n",
      "--------------------\n",
      "The IT department's cloud migration project reduced infrastructure costs by 25%.\n",
      "        DevOps implementation improved deployment frequency while maintaining quality.\n",
      "        Monthly recurring revenue from SaaS products grew steadily.\n",
      "\n",
      "Running Analysis...\n",
      "--------------------\n"
     ]
    }
   ],
   "source": [
    "await analyze_themes(text, options=options)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Debug Category Analysis\n",
      "==================================================\n",
      "\n",
      "Input Text:\n",
      "--------------------\n",
      "The IT department's cloud migration project reduced infrastructure costs by 25%.\n",
      "        DevOps implementation improved deployment frequency while maintaining quality.\n",
      "        Monthly recurring revenue from SaaS products grew steadily.\n",
      "\n",
      "Running Analysis...\n",
      "--------------------\n",
      "\n",
      "Categories Found:\n",
      "\n",
      "  • technical\n",
      "    Confidence: [█████████████████░░░] (0.85)\n",
      "    The text discusses a cloud migration project and DevOps implementation, both of which are technical processes related to software development and system management.\n",
      "    Evidence:\n",
      "      - cloud migration project\n",
      "      - DevOps implementation\n",
      "      - improved deployment frequency\n",
      "\n",
      "  • business\n",
      "    Confidence: [███████████████░░░░░] (0.75)\n",
      "    The text mentions reduced infrastructure costs and growth in monthly recurring revenue, which are key indicators of business performance and financial health.\n",
      "    Evidence:\n",
      "      - reduced infrastructure costs by 25%\n",
      "      - monthly recurring revenue from SaaS products grew steadily\n",
      "\n",
      "Debug Information:\n",
      "--------------------\n",
      "\n",
      "Confidence Statistics:\n",
      "  Average: 0.80\n",
      "  Max: 0.85\n",
      "  Min: 0.75\n",
      "\n",
      "Raw Analysis Data:\n",
      "{\n",
      "  \"language\": \"en\",\n",
      "  \"error\": null,\n",
      "  \"success\": true,\n",
      "  \"categories\": [\n",
      "    {\n",
      "      \"name\": \"technical\",\n",
      "      \"confidence\": 0.85,\n",
      "      \"explanation\": \"The text discusses a cloud migration project and DevOps implementation, both of which are technical processes related to software development and system management.\",\n",
      "      \"evidence\": [\n",
      "        \"cloud migration project\",\n",
      "        \"DevOps implementation\",\n",
      "        \"improved deployment frequency\"\n",
      "      ],\n",
      "      \"themes\": [\n",
      "        \"cloud computing\",\n",
      "        \"DevOps\",\n",
      "        \"infrastructure management\"\n",
      "      ]\n",
      "    },\n",
      "    {\n",
      "      \"name\": \"business\",\n",
      "      \"confidence\": 0.75,\n",
      "      \"explanation\": \"The text mentions reduced infrastructure costs and growth in monthly recurring revenue, which are key indicators of business performance and financial health.\",\n",
      "      \"evidence\": [\n",
      "        \"reduced infrastructure costs by 25%\",\n",
      "        \"monthly recurring revenue from SaaS products grew steadily\"\n",
      "      ],\n",
      "      \"themes\": [\n",
      "        \"cost reduction\",\n",
      "        \"revenue growth\",\n",
      "        \"SaaS business model\"\n",
      "      ]\n",
      "    }\n",
      "  ],\n",
      "  \"explanations\": {\n",
      "    \"technical\": \"The text discusses a cloud migration project and DevOps implementation, both of which are technical processes related to software development and system management.\",\n",
      "    \"business\": \"The text mentions reduced infrastructure costs and growth in monthly recurring revenue, which are key indicators of business performance and financial health.\"\n",
      "  },\n",
      "  \"evidence\": {\n",
      "    \"technical\": [\n",
      "      \"cloud migration project\",\n",
      "      \"DevOps implementation\",\n",
      "      \"improved deployment frequency\"\n",
      "    ],\n",
      "    \"business\": [\n",
      "      \"reduced infrastructure costs by 25%\",\n",
      "      \"monthly recurring revenue from SaaS products grew steadily\"\n",
      "    ]\n",
      "  }\n",
      "}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "CategoryOutput(language='en', error=None, success=True, categories=[CategoryInfo(name='technical', confidence=0.85, explanation='The text discusses a cloud migration project and DevOps implementation, both of which are technical processes related to software development and system management.', evidence=['cloud migration project', 'DevOps implementation', 'improved deployment frequency'], themes=['cloud computing', 'DevOps', 'infrastructure management']), CategoryInfo(name='business', confidence=0.75, explanation='The text mentions reduced infrastructure costs and growth in monthly recurring revenue, which are key indicators of business performance and financial health.', evidence=['reduced infrastructure costs by 25%', 'monthly recurring revenue from SaaS products grew steadily'], themes=['cost reduction', 'revenue growth', 'SaaS business model'])], explanations={'technical': 'The text discusses a cloud migration project and DevOps implementation, both of which are technical processes related to software development and system management.', 'business': 'The text mentions reduced infrastructure costs and growth in monthly recurring revenue, which are key indicators of business performance and financial health.'}, evidence={'technical': ['cloud migration project', 'DevOps implementation', 'improved deployment frequency'], 'business': ['reduced infrastructure costs by 25%', 'monthly recurring revenue from SaaS products grew steadily']})"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "await analyze_categories(text, options=options)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Or run full pipeline with debug info\n",
    "await debug_full_pipeline(text)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Batch Processing from Excel\n",
    "Process multiple texts from Excel file:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "await analyze_excel_content(\n",
    "    input_file=\"test_content.xlsx\",  # Input Excel file path\n",
    "    output_file=\"analysis_results\",  # Output filename (without extension)\n",
    "    content_column=\"content\"         # Column containing text to analyze\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parameters\n",
    "- Configure analyzers using parameter files\n",
    "- Control output detail with DebugOptions\n",
    "- Set logging level for verbosity control\n",
    "\n",
    "## Example Outputs\n",
    "The analysis provides:\n",
    "- Keywords with confidence scores\n",
    "- Theme identification and descriptions\n",
    "- Category classification with evidence\n",
    "- Confidence visualizations with Unicode bars\n",
    "\n",
    "## Notes\n",
    "- Set logging level to WARNING to minimize output\n",
    "- Use debug functions for detailed analysis inspection\n",
    "- Excel output combines all analysis types"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "semantic-analyzer",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
