{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required modules\n",
    "import sys\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "from typing import List, Dict, Any\n",
    "import logging\n",
    "import asyncio\n",
    "import logging\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# Add project root to Python path if needed\n",
    "project_root = str(Path().resolve().parent)\n",
    "if project_root not in sys.path:\n",
    "    sys.path.append(project_root)\n",
    "\n",
    "# Import necessary components\n",
    "from src.nb_helpers.environment import setup_notebook_env, verify_environment\n",
    "from src.semantic_analyzer import SemanticAnalyzer\n",
    "from src.core.config import AnalyzerConfig\n",
    "from src.core.language_processing import create_text_processor\n",
    "from src.core.llm.factory import create_llm\n",
    "from src.utils.output_formatter import (\n",
    "    ExcelFormatter, DetailedFormatter, OutputDetail, ExcelOutputConfig, BaseColumnFormat\n",
    ")\n",
    "from FileUtils import FileUtils, OutputFileType\n",
    "\n",
    "logger = logging.getLogger(__name__)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up environment and verify\n",
    "setup_notebook_env(log_level=\"DEBUG\")\n",
    "verify_environment()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize FileUtils\n",
    "file_utils = FileUtils()\n",
    "\n",
    "# Create analyzer config with OpenAI as default\n",
    "config = AnalyzerConfig()\n",
    "config.config[\"models\"][\"default_provider\"] = \"openai\"\n",
    "config.config[\"models\"][\"default_model\"] = \"gpt-4o-mini\"\n",
    "\n",
    "# Create LLM instance\n",
    "llm = create_llm(provider=\"openai\", config=config)\n",
    "\n",
    "# Initialize language processors\n",
    "en_processor = create_text_processor(language=\"en\")\n",
    "fi_processor = create_text_processor(language=\"fi\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create analyzer with proper initialization\n",
    "analyzer = SemanticAnalyzer(\n",
    "    llm=llm,\n",
    "    file_utils=file_utils,\n",
    "    parameter_file=\"parameters_fi.xlsx\"  # Default to English parameters\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test data for demonstrations\n",
    "test_texts = {\n",
    "    \"en\": {\n",
    "        \"technical\": \"\"\"Machine learning models are trained using large datasets to recognize patterns. \n",
    "                    The neural network architecture includes multiple layers for feature extraction. \n",
    "                    Data preprocessing and feature engineering are crucial steps.\"\"\",\n",
    "        \n",
    "        \"business\": \"\"\"Q3 financial results show 15% revenue growth and improved profit margins. \n",
    "                    Customer acquisition costs decreased while retention rates increased. \n",
    "                    Market expansion strategy focuses on emerging technology sectors.\"\"\",\n",
    "        \n",
    "        \"mixed\": \"\"\"Our AI platform leverages machine learning to optimize customer engagement.\n",
    "                 The system analyzes user behavior patterns to improve conversion rates.\n",
    "                 Q2 results showed 25% improvement in customer retention metrics.\"\"\"\n",
    "    },\n",
    "    \"fi\": {\n",
    "        \"technical\": \"\"\"Koneoppimismalleja koulutetaan suurilla datajoukolla tunnistamaan kaavoja. \n",
    "                    Neuroverkon arkkitehtuuri sisältää useita kerroksia piirteiden erottamiseen. \n",
    "                    Datan esikäsittely ja piirteiden suunnittelu ovat keskeisiä vaiheita.\"\"\",\n",
    "        \n",
    "        \"business\": \"\"\"Q3 taloudelliset tulokset osoittavat 15% liikevaihdon kasvun ja parantuneet katteet. \n",
    "                    Asiakashankinnan kustannukset laskivat ja asiakaspysyvyys parani. \n",
    "                    Markkinalaajennusstrategia keskittyy nouseviin teknologiasektoreihin.\"\"\"\n",
    "    }\n",
    "}\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize formatters with different detail levels\n",
    "summary_formatter = ExcelFormatter(\n",
    "    file_utils=file_utils,\n",
    "    config=ExcelOutputConfig(detail_level=OutputDetail.SUMMARY)\n",
    ")\n",
    "\n",
    "detailed_formatter = DetailedFormatter(\n",
    "    file_utils=file_utils,\n",
    "    config=ExcelOutputConfig(detail_level=OutputDetail.DETAILED)\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Single Text Analysis with Different Detail Levels\n",
    "async def demonstrate_single_analysis(text: str, language: str = \"en\"):\n",
    "    \"\"\"Demonstrate analysis of single text with different detail levels.\"\"\"\n",
    "    print(f\"Analyzing {language.upper()} text:\")\n",
    "    print(\"-\" * 50)\n",
    "    print(text)\n",
    "    print(\"\\n\")\n",
    "\n",
    "    try:\n",
    "        # Update analyzer's language and configuration\n",
    "        analyzer.set_language(language)\n",
    "        \n",
    "        # Perform analysis\n",
    "        result = await analyzer.analyze(\n",
    "            text,\n",
    "            analysis_types=[\"keywords\", \"themes\", \"categories\"],\n",
    "            language=language  # Pass language explicitly\n",
    "        )\n",
    "\n",
    "        print(\"\\nAnalysis Results:\")\n",
    "        print(\"-\" * 50)\n",
    "        print(result)\n",
    "\n",
    "        # Show summary format\n",
    "        print(\"\\nSummary Output:\")\n",
    "        print(\"-\" * 50)\n",
    "        summary = summary_formatter.format_output(\n",
    "            results={\n",
    "                \"keywords\": result.keywords,\n",
    "                \"themes\": result.themes,\n",
    "                \"categories\": result.categories\n",
    "            },\n",
    "            analysis_types=[\"keywords\", \"themes\", \"categories\"]\n",
    "        )\n",
    "\n",
    "        logger.debug(f\"Summary formatter results: {summary}\")\n",
    "        \n",
    "        for analysis_type, output in summary.items():\n",
    "            print(f\"\\n{analysis_type.title()}:\")\n",
    "            if output:\n",
    "                items = output.split(\"; \")\n",
    "                for item in items:\n",
    "                    print(f\"  • {item}\")\n",
    "            else:\n",
    "                print(\"  No results\")\n",
    "\n",
    "        # Show detailed format\n",
    "        print(\"\\nDetailed Output:\")\n",
    "        print(\"-\" * 50)\n",
    "        detailed = detailed_formatter.format_detailed_output(\n",
    "            results={\n",
    "                \"keywords\": result.keywords,\n",
    "                \"themes\": result.themes,\n",
    "                \"categories\": result.categories\n",
    "            },\n",
    "            analysis_types=[\"keywords\", \"themes\", \"categories\"]\n",
    "        )\n",
    "        \n",
    "        for analysis_type, output in detailed.items():\n",
    "            print(f\"\\n{analysis_type.title()}:\")\n",
    "            print(\"Summary:\")\n",
    "            if output[\"summary\"]:\n",
    "                items = output[\"summary\"].split(\"; \")\n",
    "                for item in items:\n",
    "                    print(f\"  • {item}\")\n",
    "            \n",
    "            print(\"\\nDetails:\")\n",
    "            if isinstance(output[\"details\"], str):\n",
    "                # Handle string format\n",
    "                items = output[\"details\"].split(\"; \")\n",
    "                for item in items:\n",
    "                    print(f\"  • {item}\")\n",
    "            elif isinstance(output[\"details\"], dict):\n",
    "                # Handle dictionary format\n",
    "                for key, value in output[\"details\"].items():\n",
    "                    print(f\"  • {key}:\")\n",
    "                    if isinstance(value, list):\n",
    "                        for item in value:\n",
    "                            print(f\"    - {item}\")\n",
    "                    else:\n",
    "                        print(f\"    {value}\")\n",
    "\n",
    "            print(\"\\nMetadata:\")\n",
    "            for key, value in output[\"metadata\"].items():\n",
    "                print(f\"  • {key}: {value}\")\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Analysis failed: {e}\")\n",
    "        print(f\"Error: {str(e)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "async def demonstrate_excel_processing_details():\n",
    "    \"\"\"Demonstrate processing of Excel file.\"\"\"\n",
    "    input_filename = \"test_content_short.xlsx\"  # Without extension\n",
    "    output_filename = \"analysis_results\"  # Without extension\n",
    "    text_column = \"keskustelu\"\n",
    "    language_column = \"language\"  # Optional column for language detection\n",
    "\n",
    "    print(f\"Processing Excel file: {input_filename}\")\n",
    "    print(\"-\" * 50)\n",
    "\n",
    "    try:\n",
    "        # Load input file using FileUtils\n",
    "        input_df = file_utils.load_single_file(\n",
    "            file_path=input_filename,\n",
    "            input_type=\"raw\"\n",
    "        )\n",
    "\n",
    "        if text_column not in input_df.columns:\n",
    "            print(f\"Error: Column '{text_column}' not found in input file\")\n",
    "            return\n",
    "\n",
    "        # Process each row with appropriate language handling\n",
    "        results = []\n",
    "        for idx, row in input_df.iterrows():\n",
    "            try:\n",
    "                # Determine language\n",
    "                language = row[language_column] if language_column in input_df.columns else \"en\"\n",
    "                \n",
    "                # Update analyzer's language\n",
    "                analyzer.set_language(language)\n",
    "\n",
    "                # Analyze text\n",
    "                result = await analyzer.analyze(\n",
    "                    row[text_column],\n",
    "                    analysis_types=[\"keywords\", \"themes\", \"categories\"],\n",
    "                    language=language\n",
    "                )\n",
    "\n",
    "                # Format results using the formatters\n",
    "                formatted_result = {\n",
    "                    \"keywords\": summary_formatter.format_output(\n",
    "                        {\"keywords\": result.keywords},\n",
    "                        [\"keywords\"]\n",
    "                    ).get(\"keywords\", \"\"),\n",
    "                    \n",
    "                    \"themes\": summary_formatter.format_output(\n",
    "                        {\"themes\": result.themes},\n",
    "                        [\"themes\"]\n",
    "                    ).get(\"themes\", \"\"),\n",
    "                    \n",
    "                    \"categories\": summary_formatter.format_output(\n",
    "                        {\"categories\": result.categories},\n",
    "                        [\"categories\"]\n",
    "                    ).get(\"categories\", \"\"),\n",
    "                    \n",
    "                    \"language\": language\n",
    "                }\n",
    "                \n",
    "                results.append(formatted_result)\n",
    "                print(f\"Processed row {idx + 1}/{len(input_df)} ({language})\")\n",
    "\n",
    "            except Exception as e:\n",
    "                logger.error(f\"Error processing row {idx + 1}: {e}\")\n",
    "                results.append({\n",
    "                    \"keywords\": f\"Error: {str(e)}\",\n",
    "                    \"themes\": f\"Error: {str(e)}\",\n",
    "                    \"categories\": f\"Error: {str(e)}\",\n",
    "                    \"language\": language\n",
    "                })\n",
    "\n",
    "        # Create results DataFrame\n",
    "        results_df = input_df.copy()\n",
    "        for key in [\"keywords\", \"themes\", \"categories\"]:\n",
    "            results_df[key] = [r.get(key, \"\") for r in results]\n",
    "\n",
    "        # Save using FileUtils\n",
    "        saved_files, _ = file_utils.save_data_to_storage(\n",
    "            data={\"analysis_results\": results_df},\n",
    "            output_type=\"processed\",\n",
    "            file_name=output_filename,\n",
    "            output_filetype=OutputFileType.XLSX,\n",
    "            include_timestamp=True\n",
    "        )\n",
    "\n",
    "        print(\"\\nProcessing complete!\")\n",
    "        output_path = next(iter(saved_files.values()))\n",
    "        print(f\"Results saved to: {output_path}\")\n",
    "        \n",
    "        print(\"\\nFirst few rows of results:\")\n",
    "        pd.set_option('display.max_columns', None)\n",
    "        pd.set_option('display.max_colwidth', 50)\n",
    "        print(results_df.head())\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing Excel file: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "async def demonstrate_excel_processing(file_name: str = \"test_content_fi.xlsx\", \n",
    "                                       output_filename: str = \"analysis_results\", \n",
    "                                       text_column: str = \"content\", \n",
    "                                       language_column: str = \"language\"):\n",
    "    \"\"\"Demonstrate processing of Excel file with simplified output.\"\"\"\n",
    "    file_name = file_name\n",
    "    output_filename = output_filename\n",
    "    text_column = text_column\n",
    "    language_column = language_column\n",
    "\n",
    "    # Create simplified formatter configuration\n",
    "    simple_config = ExcelOutputConfig(\n",
    "        detail_level=OutputDetail.MINIMAL,  # Use minimal detail level\n",
    "        keywords_format=BaseColumnFormat(\n",
    "            column_name=\"keywords\",\n",
    "            format_template=\"{keyword}\",  # Just show keyword without score/domain\n",
    "            included_fields=[\"keyword\"],\n",
    "            max_items=5  # Limit number of keywords\n",
    "        ),\n",
    "        themes_format=BaseColumnFormat(\n",
    "            column_name=\"themes\",\n",
    "            format_template=\"{name}\",  # Just show theme name\n",
    "            included_fields=[\"name\"],\n",
    "            max_items=3  # Limit number of themes\n",
    "        ),\n",
    "        categories_format=BaseColumnFormat(\n",
    "            column_name=\"categories\",\n",
    "            format_template=\"{name}\",  # Just show category name\n",
    "            included_fields=[\"name\"],\n",
    "            max_items=2  # Limit number of categories\n",
    "        )\n",
    "    )\n",
    "\n",
    "    # Create formatter with simplified config\n",
    "    simple_formatter = ExcelFormatter(\n",
    "        file_utils=file_utils,\n",
    "        config=simple_config\n",
    "    )\n",
    "\n",
    "    try:\n",
    "        # Load and process input file\n",
    "        input_df = file_utils.load_single_file(\n",
    "            file_path=file_name,\n",
    "            input_type=\"raw\"\n",
    "        )\n",
    "\n",
    "        if text_column not in input_df.columns:\n",
    "            print(f\"Error: Column '{text_column}' not found in input file\")\n",
    "            return\n",
    "\n",
    "        results = []\n",
    "        for idx, row in input_df.iterrows():\n",
    "            try:\n",
    "                language = row[language_column] if language_column in input_df.columns else \"en\"\n",
    "                analyzer.set_language(language)\n",
    "\n",
    "                result = await analyzer.analyze(\n",
    "                    row[text_column],\n",
    "                    analysis_types=[\"keywords\", \"themes\", \"categories\"],\n",
    "                    language=language\n",
    "                )\n",
    "\n",
    "                # Format with simplified formatter\n",
    "                formatted_result = {\n",
    "                    \"keywords\": simple_formatter.format_output(\n",
    "                        {\"keywords\": result.keywords},\n",
    "                        [\"keywords\"]\n",
    "                    ).get(\"keywords\", \"\"),\n",
    "                    \n",
    "                    \"themes\": simple_formatter.format_output(\n",
    "                        {\"themes\": result.themes},\n",
    "                        [\"themes\"]\n",
    "                    ).get(\"themes\", \"\"),\n",
    "                    \n",
    "                    \"categories\": simple_formatter.format_output(\n",
    "                        {\"categories\": result.categories},\n",
    "                        [\"categories\"]\n",
    "                    ).get(\"categories\", \"\"),\n",
    "                    \n",
    "                    \"language\": language\n",
    "                }\n",
    "                results.append(formatted_result)\n",
    "\n",
    "            except Exception as e:\n",
    "                logger.error(f\"Error processing row {idx + 1}: {e}\")\n",
    "                results.append({\n",
    "                    \"keywords\": f\"Error: {str(e)}\",\n",
    "                    \"themes\": f\"Error: {str(e)}\",\n",
    "                    \"categories\": f\"Error: {str(e)}\",\n",
    "                    \"language\": language\n",
    "                })\n",
    "\n",
    "        # Create and save results\n",
    "        results_df = input_df.copy()\n",
    "        for key in [\"keywords\", \"themes\", \"categories\"]:\n",
    "            results_df[key] = [r.get(key, \"\") for r in results]\n",
    "\n",
    "        # Configure pandas display options\n",
    "        pd.set_option('display.max_columns', None)\n",
    "        pd.set_option('display.max_colwidth', 30)  # Shorter column width\n",
    "        pd.set_option('display.expand_frame_repr', False)\n",
    "\n",
    "        # Save results\n",
    "        saved_files, _ = file_utils.save_data_to_storage(\n",
    "            data={\"analysis_results\": results_df},\n",
    "            output_type=\"processed\",\n",
    "            file_name=output_filename,\n",
    "            output_filetype=OutputFileType.XLSX,\n",
    "            include_timestamp=True\n",
    "        )\n",
    "\n",
    "        print(\"\\nProcessing complete!\")\n",
    "        print(f\"Results saved to: {next(iter(saved_files.values()))}\")\n",
    "        print(\"\\nFirst few rows of results:\")\n",
    "        print(results_df.head())\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing Excel file: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "async def demonstrate_custom_format():\n",
    "    \"\"\"Demonstrate custom formatting options with language support.\"\"\"\n",
    "    # Create custom config with language-aware templates\n",
    "    custom_config = ExcelOutputConfig(\n",
    "        detail_level=OutputDetail.SUMMARY,\n",
    "        keywords_format=BaseColumnFormat(\n",
    "            column_name=\"key_terms\",\n",
    "            format_template=\"{keywords} ({domain}) [{language}]\",\n",
    "            included_fields=[\"keyword\", \"domain\", \"language\"],\n",
    "            confidence_threshold=0.5,\n",
    "            max_items=3\n",
    "        ),\n",
    "        themes_format=BaseColumnFormat(\n",
    "            column_name=\"main_themes\",\n",
    "            format_template=\"{name} ({confidence}) [{language}]\",\n",
    "            included_fields=[\"name\", \"confidence\", \"language\"],\n",
    "            confidence_threshold=0.6,\n",
    "            max_items=2\n",
    "        )\n",
    "    )\n",
    "\n",
    "    custom_formatter = ExcelFormatter(\n",
    "        file_utils=file_utils,\n",
    "        config=custom_config\n",
    "    )\n",
    "\n",
    "    # Test both languages\n",
    "    for lang, texts in test_texts.items():\n",
    "        print(f\"\\nAnalyzing {lang.upper()} text with custom format:\")\n",
    "        print(\"-\" * 50)\n",
    "        \n",
    "        # Set appropriate language processor\n",
    "        analyzer.language_processor = (\n",
    "            fi_processor if lang == \"fi\" else en_processor\n",
    "        )\n",
    "\n",
    "        # Analyze each type of text\n",
    "        for text_type, text in texts.items():\n",
    "            print(f\"\\nText type: {text_type}\")\n",
    "            \n",
    "            try:\n",
    "                result = await analyzer.analyze(\n",
    "                    text,\n",
    "                    analysis_types=[\"keywords\", \"themes\"]\n",
    "                )\n",
    "\n",
    "                custom_output = custom_formatter.format_output(\n",
    "                    results=result,\n",
    "                    analysis_types=[\"keywords\", \"themes\"]\n",
    "                )\n",
    "                \n",
    "                for analysis_type, output in custom_output.items():\n",
    "                    print(f\"\\n{analysis_type.title()}:\")\n",
    "                    print(output)\n",
    "\n",
    "            except Exception as e:\n",
    "                print(f\"Error analyzing {lang} {text_type} text: {e}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "async def run_demos():\n",
    "    \"\"\"Run all demonstrations with proper error handling.\"\"\"\n",
    "    try:\n",
    "        # 1. English text analysis\n",
    "        print(\"=== English Text Analysis Demo ===\\n\")\n",
    "        await demonstrate_single_analysis(test_texts[\"en\"][\"mixed\"], language=\"en\")\n",
    "\n",
    "        # 2. Finnish text analysis\n",
    "        print(\"\\n=== Finnish Text Analysis Demo ===\\n\")\n",
    "        await demonstrate_single_analysis(test_texts[\"fi\"][\"technical\"], language=\"fi\")\n",
    "\n",
    "        # 3. Excel processing\n",
    "        print(\"\\n=== Excel Processing Demo ===\\n\")\n",
    "        await demonstrate_excel_processing()\n",
    "\n",
    "        # 4. Custom format demo\n",
    "        print(\"\\n=== Custom Format Demo ===\\n\")\n",
    "        await demonstrate_custom_format()\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error running demonstrations: {e}\")\n",
    "        raise\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Run all demonstrations with proper error handling.\"\"\"\n",
    "# 1. English text analysis\n",
    "print(\"=== English Text Analysis Demo ===\\n\")\n",
    "await demonstrate_single_analysis(test_texts[\"en\"][\"mixed\"], language=\"en\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Finnish text analysis\n",
    "print(\"\\n=== Finnish Text Analysis Demo ===\\n\")\n",
    "await demonstrate_single_analysis(test_texts[\"fi\"][\"technical\"], language=\"fi\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. Excel processing\n",
    "print(\"\\n=== Excel Processing Demo ===\\n\")\n",
    "await demonstrate_excel_processing()\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. Custom format demo\n",
    "print(\"\\n=== Custom Format Demo ===\\n\")\n",
    "await demonstrate_custom_format()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5. Batch file analysis\n",
    "# print(\"\\n=== Batch File Analysis Demo ===\\n\")\n",
    "# await demonstrate_batch_file_analysis()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # 1. Single Text Analysis with Different Detail Levels\n",
    "# async def demonstrate_single_analysis(text: str):\n",
    "#     \"\"\"Demonstrate analysis of single text with different detail levels.\"\"\"\n",
    "#     print(\"Analyzing text:\")\n",
    "#     print(\"-\" * 50)\n",
    "#     print(text)\n",
    "#     print(\"\\n\")\n",
    "\n",
    "#     # Perform analysis\n",
    "#     result = await analyzer.analyze(\n",
    "#         text,\n",
    "#         analysis_types=[\"keywords\", \"themes\", \"categories\"]\n",
    "#     )\n",
    "\n",
    "#     # Show summary format\n",
    "#     print(\"Summary Output:\")\n",
    "#     print(\"-\" * 50)\n",
    "#     summary = summary_formatter.format_output(\n",
    "#         results=result,\n",
    "#         analysis_types=[\"keywords\", \"themes\", \"categories\"]\n",
    "#     )\n",
    "#     for analysis_type, output in summary.items():\n",
    "#         print(f\"\\n{analysis_type.title()}:\")\n",
    "#         print(output)\n",
    "\n",
    "#     # Show detailed format\n",
    "#     print(\"\\nDetailed Output:\")\n",
    "#     print(\"-\" * 50)\n",
    "#     detailed = detailed_formatter.format_detailed_output(\n",
    "#         results=result,\n",
    "#         analysis_types=[\"keywords\", \"themes\", \"categories\"]\n",
    "#     )\n",
    "#     for analysis_type, output in detailed.items():\n",
    "#         print(f\"\\n{analysis_type.title()}:\")\n",
    "#         print(\"Summary:\", output[\"summary\"])\n",
    "#         print(\"Details:\", output[\"details\"])\n",
    "#         print(\"Metadata:\", output[\"metadata\"])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For notebook execution\n",
    "# if __name__ == \"__main__\":\n",
    "    # await run_demos()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "semantic-analyzer",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
