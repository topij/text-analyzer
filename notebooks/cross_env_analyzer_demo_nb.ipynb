{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cross-Environment Semantic Analysis Demo\n",
    "\n",
    "See also separate [documentation](../docs/ANALYSIS_DEMO_DOC.md) sheet\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Environment Setup\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Import dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import asyncio\n",
    "import logging\n",
    "from pathlib import Path\n",
    "import sys\n",
    "from typing import Optional\n",
    "\n",
    "\n",
    "# Add project root to path (for local environment)\n",
    "project_root = str(Path().resolve().parent)\n",
    "if project_root not in sys.path:\n",
    "    sys.path.append(project_root)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import main interface to analyzers\n",
    "from src.semantic_analyzer import SemanticAnalyzer\n",
    "\n",
    "# import formatting\n",
    "from src.utils.formatting_config import OutputDetail, ExcelOutputConfig\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import environment setup\n",
    "from src.core.managers import EnvironmentManager, EnvironmentConfig"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set up environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-01-09 21:06:27,143 - FileUtils.core.file_utils - INFO - Project root: /Users/topi/data-science/repos/text-analyzer\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-01-09 21:06:27,143 - FileUtils.core.file_utils - INFO - Project root: /Users/topi/data-science/repos/text-analyzer\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-01-09 21:06:27,144 - FileUtils.core.file_utils - INFO - FileUtils initialized with local storage\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-01-09 21:06:27,144 - FileUtils.core.file_utils - INFO - FileUtils initialized with local storage\n",
      "2025-01-09 21:06:27,169 - src.core.managers.environment_manager - INFO - Environment initialized successfully\n"
     ]
    }
   ],
   "source": [
    "# Set environment type\n",
    "ENV_TYPE = \"local\"  # Change to \"azure\" when running in Azure ML and you want persistent blob storage\n",
    "\n",
    "# Configure environment\n",
    "env_config = EnvironmentConfig(\n",
    "    env_type=ENV_TYPE,\n",
    "    project_root=Path().resolve().parent,\n",
    "    log_level=\"INFO\" # use config.yaml or .env for now to change logging level\n",
    ")\n",
    "environment = EnvironmentManager(env_config)\n",
    "\n",
    "# Get initialized components\n",
    "components = environment.get_components()\n",
    "file_utils = components[\"file_utils\"]\n",
    "\n",
    "# Configure logging for HTTP clients\n",
    "logging.getLogger(\"httpx\").setLevel(logging.WARNING)\n",
    "logging.getLogger(\"httpcore\").setLevel(logging.WARNING)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### User defined setup\n",
    "- parameter file (how) and content file to be analyzed (what)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# parameter_file = \"parameters_en.xlsx\"\n",
    "# content_file = \"test_content_en.xlsx\"\n",
    "\n",
    "\n",
    "parameter_file = \"parameters_en.xlsx\"\n",
    "content_file = \"test_content_en.xlsx\"\n",
    "\n",
    "# Change to True if you want to use Azure OpenAI API, if not already defined in config.yaml\n",
    "azure = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Initialize Analyzer\n",
    "\n",
    "-  Initialize analyzer with formatting config\n",
    "-  Parameter file paths are handled automatically by FileUtils\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-01-09 21:08:43,634 - src.semantic_analyzer.analyzer - INFO - Verifying analyzer configuration:\n",
      "2025-01-09 21:08:43,635 - src.semantic_analyzer.analyzer - INFO - Language: en\n",
      "2025-01-09 21:08:43,635 - src.semantic_analyzer.analyzer - INFO - Categories loaded: 2\n",
      "2025-01-09 21:08:43,636 - src.semantic_analyzer.analyzer - INFO -   - technical: 4 keywords, threshold: 0.6\n",
      "2025-01-09 21:08:43,636 - src.semantic_analyzer.analyzer - INFO -   - business: 4 keywords, threshold: 0.6\n",
      "2025-01-09 21:08:43,636 - src.semantic_analyzer.analyzer - INFO - Language processor: EnglishTextProcessor\n",
      "2025-01-09 21:08:43,636 - src.semantic_analyzer.analyzer - INFO - All analyzers initialized for language: en\n",
      "2025-01-09 21:08:43,636 - src.semantic_analyzer.analyzer - INFO - Semantic Analyzer initialized successfully\n"
     ]
    }
   ],
   "source": [
    "# Example texts\n",
    "texts = {\n",
    "    \"en\": \"Machine learning models analyze data efficiently.\",\n",
    "    \"fi\": \"Koneoppimismallit analysoivat dataa tehokkaasti.\"\n",
    "}\n",
    "\n",
    "# Initialize analyzer\n",
    "analyzer = SemanticAnalyzer(\n",
    "    parameter_file=parameter_file,\n",
    "    file_utils=file_utils\n",
    ")\n",
    "\n",
    "# Helper function for text analysis\n",
    "async def analyze_text(text: str, language: str):\n",
    "    result = await analyzer.analyze(\n",
    "        text=text,\n",
    "        language=language,\n",
    "        analysis_types=[\"keywords\", \"themes\", \"categories\"]\n",
    "    )\n",
    "    \n",
    "    if result.success:\n",
    "        print(f\"\\nAnalysis results for {language}:\")\n",
    "        print(\"Keywords:\")\n",
    "        for kw in result.keywords.keywords:\n",
    "            print(f\"• {kw.keyword} (score: {kw.score:.2f})\")\n",
    "            \n",
    "        print(\"\\nThemes:\")\n",
    "        for theme in result.themes.themes:\n",
    "            print(f\"• {theme.name} ({theme.confidence:.2f})\")\n",
    "            \n",
    "        if result.categories and result.categories.categories:\n",
    "            print(\"\\nCategories:\")\n",
    "            for cat in result.categories.categories:\n",
    "                print(f\"• {cat.name} ({cat.confidence:.2f})\")\n",
    "    else:\n",
    "        print(f\"Error: {result.error}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Single text analysis\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Single Text Analysis ===\n",
      "\n",
      "Analysis results for en:\n",
      "Keywords:\n",
      "• machine learning (score: 0.90)\n",
      "• model (score: 0.80)\n",
      "• analyze (score: 0.70)\n",
      "• data (score: 0.90)\n",
      "• efficiently (score: 0.60)\n",
      "\n",
      "Themes:\n",
      "• Efficiency of Machine Learning (0.90)\n",
      "• Data Analysis (0.85)\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'CategoryAnalysisResult' object has no attribute 'categories'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[9], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m=== Single Text Analysis ===\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m lang, text \u001b[38;5;129;01min\u001b[39;00m texts\u001b[38;5;241m.\u001b[39mitems():\n\u001b[0;32m----> 3\u001b[0m     \u001b[38;5;28;01mawait\u001b[39;00m analyze_text(text, lang)\n",
      "Cell \u001b[0;32mIn[8], line 31\u001b[0m, in \u001b[0;36manalyze_text\u001b[0;34m(text, language)\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m theme \u001b[38;5;129;01min\u001b[39;00m result\u001b[38;5;241m.\u001b[39mthemes\u001b[38;5;241m.\u001b[39mthemes:\n\u001b[1;32m     29\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m• \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtheme\u001b[38;5;241m.\u001b[39mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m (\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtheme\u001b[38;5;241m.\u001b[39mconfidence\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.2f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m)\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 31\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m result\u001b[38;5;241m.\u001b[39mcategories \u001b[38;5;129;01mand\u001b[39;00m \u001b[43mresult\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcategories\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcategories\u001b[49m:\n\u001b[1;32m     32\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mCategories:\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     33\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m cat \u001b[38;5;129;01min\u001b[39;00m result\u001b[38;5;241m.\u001b[39mcategories\u001b[38;5;241m.\u001b[39mcategories:\n",
      "File \u001b[0;32m~/miniconda3/envs/semantic-analyzer/lib/python3.9/site-packages/pydantic/main.py:892\u001b[0m, in \u001b[0;36mBaseModel.__getattr__\u001b[0;34m(self, item)\u001b[0m\n\u001b[1;32m    889\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__getattribute__\u001b[39m(item)  \u001b[38;5;66;03m# Raises AttributeError if appropriate\u001b[39;00m\n\u001b[1;32m    890\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    891\u001b[0m     \u001b[38;5;66;03m# this is the current error\u001b[39;00m\n\u001b[0;32m--> 892\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(\u001b[38;5;28mself\u001b[39m)\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m!r}\u001b[39;00m\u001b[38;5;124m object has no attribute \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mitem\u001b[38;5;132;01m!r}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'CategoryAnalysisResult' object has no attribute 'categories'"
     ]
    }
   ],
   "source": [
    "print(\"\\n=== Single Text Analysis ===\")\n",
    "for lang, text in texts.items():\n",
    "    await analyze_text(text, lang)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Excel processing\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "analyze_excel() missing 1 required positional argument: 'content_file'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[11], line 9\u001b[0m\n\u001b[1;32m      2\u001b[0m output_config \u001b[38;5;241m=\u001b[39m ExcelOutputConfig(\n\u001b[1;32m      3\u001b[0m     output_detail\u001b[38;5;241m=\u001b[39mOutputDetail\u001b[38;5;241m.\u001b[39mMINIMAL,\n\u001b[1;32m      4\u001b[0m     include_metadata\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[1;32m      5\u001b[0m     include_confidence_scores\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m      6\u001b[0m )\n\u001b[1;32m      8\u001b[0m \u001b[38;5;66;03m# Analyze Excel file\u001b[39;00m\n\u001b[0;32m----> 9\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mawait\u001b[39;00m analyzer\u001b[38;5;241m.\u001b[39manalyze_excel(\n\u001b[1;32m     10\u001b[0m     excel_file\u001b[38;5;241m=\u001b[39mcontent_file,\n\u001b[1;32m     11\u001b[0m     analysis_types\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mkeywords\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mthemes\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcategories\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[1;32m     12\u001b[0m     save_results\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[1;32m     13\u001b[0m     output_file\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mresults.xlsx\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     14\u001b[0m     output_config\u001b[38;5;241m=\u001b[39moutput_config\n\u001b[1;32m     15\u001b[0m )\n\u001b[1;32m     17\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m result\u001b[38;5;241m.\u001b[39msuccess:\n\u001b[1;32m     18\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mExcel analysis completed successfully\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mTypeError\u001b[0m: analyze_excel() missing 1 required positional argument: 'content_file'"
     ]
    }
   ],
   "source": [
    "# Configure output formatting\n",
    "output_config = ExcelOutputConfig(\n",
    "    output_detail=OutputDetail.MINIMAL,\n",
    "    include_metadata=True,\n",
    "    include_confidence_scores=True\n",
    ")\n",
    "\n",
    "# Analyze Excel file\n",
    "result = await analyzer.analyze_excel(\n",
    "    excel_file=content_file,\n",
    "    analysis_types=[\"keywords\", \"themes\", \"categories\"],\n",
    "    save_results=True,\n",
    "    output_file=\"results.xlsx\",\n",
    "    output_config=output_config\n",
    ")\n",
    "\n",
    "if result.success:\n",
    "    print(\"\\nExcel analysis completed successfully\")\n",
    "    print(f\"Results saved to: {result.output_file}\")\n",
    "else:\n",
    "    print(f\"Error: {result.error}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernel_info": {
   "name": "semantic-analyzer"
  },
  "kernelspec": {
   "display_name": "semantic-analyzer",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
