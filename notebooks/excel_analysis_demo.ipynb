{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import asyncio\n",
    "from pathlib import Path\n",
    "import logging\n",
    "import sys\n",
    "from typing import List, Optional\n",
    "\n",
    "# Add project root to Python path if needed\n",
    "project_root = str(Path().resolve().parent)\n",
    "if project_root not in sys.path:\n",
    "    sys.path.append(project_root)\n",
    "\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "from FileUtils import FileUtils, OutputFileType\n",
    "\n",
    "from src.semantic_analyzer import SemanticAnalyzer\n",
    "\n",
    "# Configure logging\n",
    "# logging.basicConfig(\n",
    "#     level=logging.INFO,\n",
    "#     format=\"%(asctime)s - %(name)s - %(levelname)s - %(message)s\",\n",
    "# )\n",
    "# logger = logging.getLogger(__name__)\n",
    "from src.nb_helpers.environment import setup_notebook_env, verify_environment\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-12-12 18:54:36,486 - FileUtils.core.file_utils - INFO - Project root: c:\\Users\\tja\\OneDrive - Rastor-instituutti ry\\Tiedostot\\Rastor-instituutti\\kehittäminen\\analytiikka\\repos\\semantic-text-analyzer\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-12-12 18:54:36,486 - FileUtils.core.file_utils - INFO - Project root: c:\\Users\\tja\\OneDrive - Rastor-instituutti ry\\Tiedostot\\Rastor-instituutti\\kehittäminen\\analytiikka\\repos\\semantic-text-analyzer\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-12-12 18:54:36,497 - FileUtils.core.file_utils - INFO - FileUtils initialized with local storage\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-12-12 18:54:36,497 - FileUtils.core.file_utils - INFO - FileUtils initialized with local storage\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-12-12 18:54:36,551 - FileUtils.core.file_utils - INFO - Project root: c:\\Users\\tja\\OneDrive - Rastor-instituutti ry\\Tiedostot\\Rastor-instituutti\\kehittäminen\\analytiikka\\repos\\semantic-text-analyzer\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-12-12 18:54:36,551 - FileUtils.core.file_utils - INFO - Project root: c:\\Users\\tja\\OneDrive - Rastor-instituutti ry\\Tiedostot\\Rastor-instituutti\\kehittäminen\\analytiikka\\repos\\semantic-text-analyzer\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-12-12 18:54:36,558 - FileUtils.core.file_utils - INFO - FileUtils initialized with local storage\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-12-12 18:54:36,558 - FileUtils.core.file_utils - INFO - FileUtils initialized with local storage\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Environment Check Results:\n",
      "==================================================\n",
      "\n",
      "Basic Setup:\n",
      "-----------\n",
      "✓ Project root in path\n",
      "✓ FileUtils initialized\n",
      "✓ .env file loaded\n",
      "\n",
      "Environment Variables:\n",
      "---------------------\n",
      "✓ OPENAI_API_KEY set\n",
      "✓ ANTHROPIC_API_KEY set\n",
      "\n",
      "Project Structure:\n",
      "-----------------\n",
      "✓ Raw data exists\n",
      "✓ Processed data exists\n",
      "✓ Configuration exists\n",
      "✓ Main config.yaml exists\n",
      "\n",
      "==================================================\n",
      "Environment Status: Ready ✓\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Set up environment and verify\n",
    "setup_notebook_env(log_level=\"WARNING\")\n",
    "verify_environment()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_analysis_summary(results: pd.DataFrame) -> None:\n",
    "    \"\"\"Display formatted analysis summary.\"\"\"\n",
    "    print(\"\\nAnalysis Results Summary\")\n",
    "    print(\"=\" * 50)\n",
    "\n",
    "    # Basic stats\n",
    "    print(f\"Total rows processed: {len(results)}\")\n",
    "    if \"language\" in results.columns:\n",
    "        print(f\"Language: {results['language'].iloc[0]}\")\n",
    "    if \"processing_time\" in results.columns:\n",
    "        print(\n",
    "            f\"Average processing time: {results['processing_time'].mean():.2f}s\"\n",
    "        )\n",
    "\n",
    "    # Results by type\n",
    "    result_sections = {\n",
    "        \"Keywords\": [\n",
    "            col for col in results.columns if col.startswith(\"keywords_\")\n",
    "        ],\n",
    "        \"Themes\": [col for col in results.columns if col.startswith(\"themes_\")],\n",
    "        \"Categories\": [\n",
    "            col for col in results.columns if col.startswith(\"categories_\")\n",
    "        ],\n",
    "    }\n",
    "\n",
    "    for section_name, columns in result_sections.items():\n",
    "        if columns:\n",
    "            print(f\"\\n{section_name} Results\")\n",
    "            print(\"-\" * 50)\n",
    "\n",
    "            # Display first 3 rows for each result type\n",
    "            sample_results = results[columns].head(3)\n",
    "\n",
    "            # Format each cell for display\n",
    "            for idx, row in sample_results.iterrows():\n",
    "                print(f\"\\nRow {idx + 1}:\")\n",
    "                for col in columns:\n",
    "                    value = row[col]\n",
    "                    if pd.notna(value):\n",
    "                        print(f\"  {col.split('_', 1)[1]}: {value}\")\n",
    "\n",
    "\n",
    "async def analyze_excel_content(\n",
    "    content_file: str = \"test_content_en.xlsx\",\n",
    "    parameter_file: str = \"parameters_en.xlsx\",\n",
    "    content_column: str = \"content\",\n",
    "    analysis_types: Optional[List[str]] = None,\n",
    "    batch_size: int = 10,\n",
    ") -> None:\n",
    "    \"\"\"Run Excel-based analysis with progress reporting.\"\"\"\n",
    "    try:\n",
    "        # Initialize FileUtils\n",
    "        file_utils = FileUtils()\n",
    "\n",
    "        # Verify paths with progress\n",
    "        with tqdm(total=2, desc=\"Checking files\") as pbar:\n",
    "            content_path = file_utils.get_data_path(\"raw\") / content_file\n",
    "            pbar.update(1)\n",
    "\n",
    "            param_path = file_utils.get_data_path(\"parameters\") / parameter_file\n",
    "            pbar.update(1)\n",
    "\n",
    "            if not content_path.exists():\n",
    "                raise FileNotFoundError(\n",
    "                    f\"Content file not found: {content_path}\"\n",
    "                )\n",
    "            if not param_path.exists():\n",
    "                raise FileNotFoundError(\n",
    "                    f\"Parameter file not found: {param_path}\"\n",
    "                )\n",
    "\n",
    "        print(\"\\nStarting analysis:\")\n",
    "        print(f\"Content file: {content_path}\")\n",
    "        print(f\"Parameter file: {param_path}\")\n",
    "        print(f\"Analysis types: {analysis_types or 'all'}\")\n",
    "\n",
    "        # Create and run analyzer\n",
    "        analyzer = SemanticAnalyzer.from_excel(\n",
    "            content_file=content_file,\n",
    "            parameter_file=parameter_file,\n",
    "            content_column=content_column,\n",
    "            file_utils=file_utils,\n",
    "        )\n",
    "\n",
    "        # Run analysis with progress\n",
    "        results = await analyzer.analyze_excel(\n",
    "            analysis_types=analysis_types,\n",
    "            batch_size=batch_size,\n",
    "            save_results=True,\n",
    "            output_file=\"analysis_results\",\n",
    "            show_progress=True,\n",
    "        )\n",
    "\n",
    "        # Display formatted results\n",
    "        display_analysis_summary(results)\n",
    "\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Analysis failed: {e}\", exc_info=True)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running Excel-based analysis...\n",
      "2024-12-12 18:54:36,696 - FileUtils.core.file_utils - INFO - Project root: c:\\Users\\tja\\OneDrive - Rastor-instituutti ry\\Tiedostot\\Rastor-instituutti\\kehittäminen\\analytiikka\\repos\\semantic-text-analyzer\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-12-12 18:54:36,696 - FileUtils.core.file_utils - INFO - Project root: c:\\Users\\tja\\OneDrive - Rastor-instituutti ry\\Tiedostot\\Rastor-instituutti\\kehittäminen\\analytiikka\\repos\\semantic-text-analyzer\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-12-12 18:54:36,703 - FileUtils.core.file_utils - INFO - FileUtils initialized with local storage\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-12-12 18:54:36,703 - FileUtils.core.file_utils - INFO - FileUtils initialized with local storage\n",
      "Checking files: 100%|██████████| 2/2 [00:00<00:00, 2000.14it/s]\n",
      "2024-12-12 18:54:36,712 - src.semantic_analyzer.analyzer - INFO - Initializing Excel Semantic Analyzer...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Starting analysis:\n",
      "Content file: c:\\Users\\tja\\OneDrive - Rastor-instituutti ry\\Tiedostot\\Rastor-instituutti\\kehittäminen\\analytiikka\\repos\\semantic-text-analyzer\\data\\raw\\test_content_en.xlsx\n",
      "Parameter file: c:\\Users\\tja\\OneDrive - Rastor-instituutti ry\\Tiedostot\\Rastor-instituutti\\kehittäminen\\analytiikka\\repos\\semantic-text-analyzer\\data\\parameters\\parameters_en.xlsx\n",
      "Analysis types: ['keywords', 'themes']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-12-12 18:54:37,568 - src.excel_analysis.base - INFO - Successfully loaded content file with 9 rows\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-12-12 18:54:37,615 - FileUtils.core.file_utils - INFO - Project root: c:\\Users\\tja\\OneDrive - Rastor-instituutti ry\\Tiedostot\\Rastor-instituutti\\kehittäminen\\analytiikka\\repos\\semantic-text-analyzer\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-12-12 18:54:37,615 - FileUtils.core.file_utils - INFO - Project root: c:\\Users\\tja\\OneDrive - Rastor-instituutti ry\\Tiedostot\\Rastor-instituutti\\kehittäminen\\analytiikka\\repos\\semantic-text-analyzer\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-12-12 18:54:37,624 - FileUtils.core.file_utils - INFO - FileUtils initialized with local storage\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-12-12 18:54:37,624 - FileUtils.core.file_utils - INFO - FileUtils initialized with local storage\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-12-12 18:54:37,750 - FileUtils.core.file_utils - INFO - Project root: c:\\Users\\tja\\OneDrive - Rastor-instituutti ry\\Tiedostot\\Rastor-instituutti\\kehittäminen\\analytiikka\\repos\\semantic-text-analyzer\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-12-12 18:54:37,750 - FileUtils.core.file_utils - INFO - Project root: c:\\Users\\tja\\OneDrive - Rastor-instituutti ry\\Tiedostot\\Rastor-instituutti\\kehittäminen\\analytiikka\\repos\\semantic-text-analyzer\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-12-12 18:54:37,759 - FileUtils.core.file_utils - INFO - FileUtils initialized with local storage\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-12-12 18:54:37,759 - FileUtils.core.file_utils - INFO - FileUtils initialized with local storage\n",
      "2024-12-12 18:54:39,399 - src.semantic_analyzer.analyzer - INFO - Initializing analyzers for language: en\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-12-12 18:54:39,437 - FileUtils.core.file_utils - INFO - Project root: c:\\Users\\tja\\OneDrive - Rastor-instituutti ry\\Tiedostot\\Rastor-instituutti\\kehittäminen\\analytiikka\\repos\\semantic-text-analyzer\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-12-12 18:54:39,437 - FileUtils.core.file_utils - INFO - Project root: c:\\Users\\tja\\OneDrive - Rastor-instituutti ry\\Tiedostot\\Rastor-instituutti\\kehittäminen\\analytiikka\\repos\\semantic-text-analyzer\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-12-12 18:54:39,445 - FileUtils.core.file_utils - INFO - FileUtils initialized with local storage\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-12-12 18:54:39,445 - FileUtils.core.file_utils - INFO - FileUtils initialized with local storage\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-12-12 18:54:47,708 - FileUtils.core.file_utils - INFO - Project root: c:\\Users\\tja\\OneDrive - Rastor-instituutti ry\\Tiedostot\\Rastor-instituutti\\kehittäminen\\analytiikka\\repos\\semantic-text-analyzer\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-12-12 18:54:47,708 - FileUtils.core.file_utils - INFO - Project root: c:\\Users\\tja\\OneDrive - Rastor-instituutti ry\\Tiedostot\\Rastor-instituutti\\kehittäminen\\analytiikka\\repos\\semantic-text-analyzer\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-12-12 18:54:47,718 - FileUtils.core.file_utils - INFO - FileUtils initialized with local storage\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-12-12 18:54:47,718 - FileUtils.core.file_utils - INFO - FileUtils initialized with local storage\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-12-12 18:54:47,799 - FileUtils.core.file_utils - INFO - Project root: c:\\Users\\tja\\OneDrive - Rastor-instituutti ry\\Tiedostot\\Rastor-instituutti\\kehittäminen\\analytiikka\\repos\\semantic-text-analyzer\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-12-12 18:54:47,799 - FileUtils.core.file_utils - INFO - Project root: c:\\Users\\tja\\OneDrive - Rastor-instituutti ry\\Tiedostot\\Rastor-instituutti\\kehittäminen\\analytiikka\\repos\\semantic-text-analyzer\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-12-12 18:54:47,807 - FileUtils.core.file_utils - INFO - FileUtils initialized with local storage\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-12-12 18:54:47,807 - FileUtils.core.file_utils - INFO - FileUtils initialized with local storage\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-12-12 18:54:47,920 - FileUtils.core.file_utils - INFO - Project root: c:\\Users\\tja\\OneDrive - Rastor-instituutti ry\\Tiedostot\\Rastor-instituutti\\kehittäminen\\analytiikka\\repos\\semantic-text-analyzer\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-12-12 18:54:47,920 - FileUtils.core.file_utils - INFO - Project root: c:\\Users\\tja\\OneDrive - Rastor-instituutti ry\\Tiedostot\\Rastor-instituutti\\kehittäminen\\analytiikka\\repos\\semantic-text-analyzer\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-12-12 18:54:47,928 - FileUtils.core.file_utils - INFO - FileUtils initialized with local storage\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-12-12 18:54:47,928 - FileUtils.core.file_utils - INFO - FileUtils initialized with local storage\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-12-12 18:54:47,982 - FileUtils.core.file_utils - INFO - Project root: c:\\Users\\tja\\OneDrive - Rastor-instituutti ry\\Tiedostot\\Rastor-instituutti\\kehittäminen\\analytiikka\\repos\\semantic-text-analyzer\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-12-12 18:54:47,982 - FileUtils.core.file_utils - INFO - Project root: c:\\Users\\tja\\OneDrive - Rastor-instituutti ry\\Tiedostot\\Rastor-instituutti\\kehittäminen\\analytiikka\\repos\\semantic-text-analyzer\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-12-12 18:54:47,991 - FileUtils.core.file_utils - INFO - FileUtils initialized with local storage\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-12-12 18:54:47,991 - FileUtils.core.file_utils - INFO - FileUtils initialized with local storage\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-12-12 18:54:48,184 - FileUtils.core.file_utils - INFO - Project root: c:\\Users\\tja\\OneDrive - Rastor-instituutti ry\\Tiedostot\\Rastor-instituutti\\kehittäminen\\analytiikka\\repos\\semantic-text-analyzer\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-12-12 18:54:48,184 - FileUtils.core.file_utils - INFO - Project root: c:\\Users\\tja\\OneDrive - Rastor-instituutti ry\\Tiedostot\\Rastor-instituutti\\kehittäminen\\analytiikka\\repos\\semantic-text-analyzer\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-12-12 18:54:48,214 - FileUtils.core.file_utils - INFO - FileUtils initialized with local storage\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-12-12 18:54:48,214 - FileUtils.core.file_utils - INFO - FileUtils initialized with local storage\n",
      "2024-12-12 18:54:48,224 - src.semantic_analyzer.analyzer - INFO - Successfully initialized all analyzers\n",
      "2024-12-12 18:54:48,226 - src.semantic_analyzer.analyzer - INFO - Running analysis types: ['keywords', 'themes']\n",
      "Analysis Progress:   0%|          | 0/2 [00:00<?, ?it/s]2024-12-12 18:54:48,231 - src.semantic_analyzer.analyzer - INFO - Running keywords analysis...\n",
      "Analysis Progress:   0%|          | 0/2 [00:00<?, ?it/s]2024-12-12 18:54:48,237 - src.analyzers.excel_support - INFO - Starting keyword analysis on 9 rows\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing Keywords...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-12-12 18:54:55,931 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-12-12 18:54:56,352 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-12-12 18:54:56,463 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-12-12 18:54:56,941 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-12-12 18:54:57,023 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-12-12 18:54:57,860 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-12-12 18:54:57,973 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-12-12 18:54:58,144 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-12-12 18:54:59,021 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-12-12 18:54:59,033 - src.analyzers.excel_support - INFO - Keyword analysis complete\n",
      "Analysis Progress:  50%|█████     | 1/2 [00:10<00:10, 10.81s/it]2024-12-12 18:54:59,042 - src.semantic_analyzer.analyzer - INFO - Running themes analysis...\n",
      "Analysis Progress:  50%|█████     | 1/2 [00:10<00:10, 10.81s/it]2024-12-12 18:54:59,049 - src.analyzers.excel_support - INFO - Starting theme analysis on 9 rows\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Completed keywords analysis\n",
      "\n",
      "Processing Themes...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-12-12 18:55:03,494 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Raw LLM response: {'themes': [{'name': 'Interactive Learning Environment', 'description': 'The online learning platform provides an engaging and interactive environment through modules and virtual classrooms, enhancing student collaboration and learning.', 'confidence': 0.95, 'keywords': ['interactive', 'virtual', 'collaboration'], 'domain': 'technical', 'parent_theme': None}, {'name': 'Self-Paced Learning', 'description': 'The platform allows students to progress at their own pace, enabling personalized learning experiences and accommodating different learning styles.', 'confidence': 0.9, 'keywords': ['self-paced', 'progress', 'learn'], 'domain': 'business', 'parent_theme': None}, {'name': 'Digital Assessment and Feedback', 'description': 'Digital tools provide immediate feedback on assessments, allowing students to understand their learning outcomes and areas for improvement.', 'confidence': 0.85, 'keywords': ['digital', 'assessment', 'feedback'], 'domain': 'technical', 'parent_theme': None}], 'evidence': {'Interactive Learning Environment': [{'text': 'The online learning platform features interactive modules and virtual classrooms enable real-time collaboration between students and instructors.', 'relevance': 0.9, 'keywords': ['interactive', 'virtual', 'collaboration']}], 'Self-Paced Learning': [{'text': 'self-paced progress tracking', 'relevance': 0.85, 'keywords': ['self-paced', 'progress', 'learn']}], 'Digital Assessment and Feedback': [{'text': 'Digital assessment tools provide immediate feedback on learning outcomes.', 'relevance': 0.9, 'keywords': ['digital', 'assessment', 'feedback']}]}, 'relationships': {'Interactive Learning Environment': ['Self-Paced Learning', 'Digital Assessment and Feedback'], 'Self-Paced Learning': ['Interactive Learning Environment'], 'Digital Assessment and Feedback': ['Interactive Learning Environment']}}\n",
      "\n",
      "Processed LLM response: {'themes': [{'name': 'Interactive Learning Environment', 'description': 'The online learning platform provides an engaging and interactive environment through modules and virtual classrooms, enhancing student collaboration and learning.', 'confidence': 0.95, 'keywords': ['interactive', 'virtual', 'collaboration'], 'domain': 'technical', 'parent_theme': None}, {'name': 'Self-Paced Learning', 'description': 'The platform allows students to progress at their own pace, enabling personalized learning experiences and accommodating different learning styles.', 'confidence': 0.9, 'keywords': ['self-paced', 'progress', 'learn'], 'domain': 'business', 'parent_theme': None}, {'name': 'Digital Assessment and Feedback', 'description': 'Digital tools provide immediate feedback on assessments, allowing students to understand their learning outcomes and areas for improvement.', 'confidence': 0.85, 'keywords': ['digital', 'assessment', 'feedback'], 'domain': 'technical', 'parent_theme': None}], 'evidence': {'Interactive Learning Environment': [{'text': 'The online learning platform features interactive modules and virtual classrooms enable real-time collaboration between students and instructors.', 'relevance': 0.9, 'keywords': ['interactive', 'virtual', 'collaboration']}], 'Self-Paced Learning': [{'text': 'self-paced progress tracking', 'relevance': 0.85, 'keywords': ['self-paced', 'progress', 'learn']}], 'Digital Assessment and Feedback': [{'text': 'Digital assessment tools provide immediate feedback on learning outcomes.', 'relevance': 0.9, 'keywords': ['digital', 'assessment', 'feedback']}]}, 'relationships': {'Interactive Learning Environment': ['Self-Paced Learning', 'Digital Assessment and Feedback'], 'Self-Paced Learning': ['Interactive Learning Environment'], 'Digital Assessment and Feedback': ['Interactive Learning Environment']}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-12-12 18:55:05,924 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Raw LLM response: {'themes': [{'name': 'Financial Performance', 'description': 'The analysis of financial results indicating revenue growth and profit margins.', 'confidence': 0.95, 'keywords': ['revenue', 'profit', 'growth', 'margins'], 'domain': 'business', 'parent_theme': None}, {'name': 'Customer Dynamics', 'description': 'Trends in customer acquisition costs and retention rates reflecting customer relationship management.', 'confidence': 0.9, 'keywords': ['customer', 'acquisition', 'retention', 'cost'], 'domain': 'business', 'parent_theme': None}, {'name': 'Market Strategy', 'description': 'The approach to market expansion focusing on emerging technology sectors.', 'confidence': 0.85, 'keywords': ['market', 'expansion', 'strategy', 'technology'], 'domain': 'business', 'parent_theme': None}], 'evidence': {'Financial Performance': [{'text': 'Q3 financial results show 15% revenue growth and improved profit margins.', 'relevance': 0.9, 'keywords': ['financial', 'revenue', 'growth', 'margin']}], 'Customer Dynamics': [{'text': 'Customer acquisition costs decreased while retention rates increased.', 'relevance': 0.9, 'keywords': ['customer', 'acquisition', 'retention', 'cost']}], 'Market Strategy': [{'text': 'Market expansion strategy focuses on emerging technology sectors.', 'relevance': 0.85, 'keywords': ['market', 'expansion', 'strategy', 'technology']}]}, 'relationships': {'Financial Performance': ['Customer Dynamics', 'Market Strategy'], 'Customer Dynamics': ['Financial Performance'], 'Market Strategy': ['Financial Performance']}}\n",
      "\n",
      "Processed LLM response: {'themes': [{'name': 'Financial Performance', 'description': 'The analysis of financial results indicating revenue growth and profit margins.', 'confidence': 0.95, 'keywords': ['revenue', 'profit', 'growth', 'margins'], 'domain': 'business', 'parent_theme': None}, {'name': 'Customer Dynamics', 'description': 'Trends in customer acquisition costs and retention rates reflecting customer relationship management.', 'confidence': 0.9, 'keywords': ['customer', 'acquisition', 'retention', 'cost'], 'domain': 'business', 'parent_theme': None}, {'name': 'Market Strategy', 'description': 'The approach to market expansion focusing on emerging technology sectors.', 'confidence': 0.85, 'keywords': ['market', 'expansion', 'strategy', 'technology'], 'domain': 'business', 'parent_theme': None}], 'evidence': {'Financial Performance': [{'text': 'Q3 financial results show 15% revenue growth and improved profit margins.', 'relevance': 0.9, 'keywords': ['financial', 'revenue', 'growth', 'margin']}], 'Customer Dynamics': [{'text': 'Customer acquisition costs decreased while retention rates increased.', 'relevance': 0.9, 'keywords': ['customer', 'acquisition', 'retention', 'cost']}], 'Market Strategy': [{'text': 'Market expansion strategy focuses on emerging technology sectors.', 'relevance': 0.85, 'keywords': ['market', 'expansion', 'strategy', 'technology']}]}, 'relationships': {'Financial Performance': ['Customer Dynamics', 'Market Strategy'], 'Customer Dynamics': ['Financial Performance'], 'Market Strategy': ['Financial Performance']}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-12-12 18:55:06,448 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Raw LLM response: {'themes': [{'name': 'Version Control Systems', 'description': 'Version control systems are essential tools for tracking changes in source code repositories, allowing teams to manage code revisions effectively.', 'confidence': 0.95, 'keywords': ['version', 'control', 'repository', 'track', 'code'], 'domain': 'technical', 'parent_theme': None}, {'name': 'Continuous Integration', 'description': 'Continuous integration is a development practice that ensures code quality through automated testing and integration of code changes.', 'confidence': 0.95, 'keywords': ['continuous', 'integration', 'quality', 'automate', 'test'], 'domain': 'technical', 'parent_theme': None}, {'name': 'Documentation', 'description': 'Documentation is crucial for providing detailed information on API usage and system architecture, facilitating better understanding and maintenance of software systems.', 'confidence': 0.9, 'keywords': ['documentation', 'API', 'usage', 'architecture', 'detail'], 'domain': 'technical', 'parent_theme': None}], 'evidence': {'Version Control Systems': [{'text': 'Version control systems track changes in source code repositories.', 'relevance': 0.9, 'keywords': ['version', 'control', 'repository', 'track', 'code']}], 'Continuous Integration': [{'text': 'Continuous integration ensures code quality and automated testing.', 'relevance': 0.9, 'keywords': ['continuous', 'integration', 'quality', 'automate', 'test']}], 'Documentation': [{'text': 'Documentation covers API usage and system architecture details.', 'relevance': 0.9, 'keywords': ['documentation', 'API', 'usage', 'architecture', 'detail']}]}, 'relationships': {'Version Control Systems': ['Continuous Integration', 'Documentation'], 'Continuous Integration': ['Version Control Systems', 'Documentation'], 'Documentation': ['Version Control Systems', 'Continuous Integration']}}\n",
      "\n",
      "Processed LLM response: {'themes': [{'name': 'Version Control Systems', 'description': 'Version control systems are essential tools for tracking changes in source code repositories, allowing teams to manage code revisions effectively.', 'confidence': 0.95, 'keywords': ['version', 'control', 'repository', 'track', 'code'], 'domain': 'technical', 'parent_theme': None}, {'name': 'Continuous Integration', 'description': 'Continuous integration is a development practice that ensures code quality through automated testing and integration of code changes.', 'confidence': 0.95, 'keywords': ['continuous', 'integration', 'quality', 'automate', 'test'], 'domain': 'technical', 'parent_theme': None}, {'name': 'Documentation', 'description': 'Documentation is crucial for providing detailed information on API usage and system architecture, facilitating better understanding and maintenance of software systems.', 'confidence': 0.9, 'keywords': ['documentation', 'API', 'usage', 'architecture', 'detail'], 'domain': 'technical', 'parent_theme': None}], 'evidence': {'Version Control Systems': [{'text': 'Version control systems track changes in source code repositories.', 'relevance': 0.9, 'keywords': ['version', 'control', 'repository', 'track', 'code']}], 'Continuous Integration': [{'text': 'Continuous integration ensures code quality and automated testing.', 'relevance': 0.9, 'keywords': ['continuous', 'integration', 'quality', 'automate', 'test']}], 'Documentation': [{'text': 'Documentation covers API usage and system architecture details.', 'relevance': 0.9, 'keywords': ['documentation', 'API', 'usage', 'architecture', 'detail']}]}, 'relationships': {'Version Control Systems': ['Continuous Integration', 'Documentation'], 'Continuous Integration': ['Version Control Systems', 'Documentation'], 'Documentation': ['Version Control Systems', 'Continuous Integration']}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-12-12 18:55:06,879 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-12-12 18:55:06,893 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-12-12 18:55:06,957 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Raw LLM response: {'themes': [{'name': 'Strategic Partnerships', 'description': 'The role of strategic partnerships in fostering innovation and enhancing market presence.', 'confidence': 0.95, 'keywords': ['partnership', 'strategic', 'drive', 'innovation'], 'domain': 'business', 'parent_theme': None}, {'name': 'Product Development and Launch', 'description': 'The impact of investment in research and development on new product launches.', 'confidence': 0.9, 'keywords': ['investment', 'R&D', 'product', 'launch'], 'domain': 'business', 'parent_theme': None}, {'name': 'Sales Performance', 'description': 'The achievement of sales targets and performance in key market segments.', 'confidence': 0.85, 'keywords': ['sales', 'performance', 'exceed', 'target', 'segment'], 'domain': 'business', 'parent_theme': None}], 'evidence': {'Strategic Partnerships': [{'text': 'Strategic partnerships drive innovation and market penetration.', 'relevance': 0.9, 'keywords': ['partnership', 'drive', 'innovation', 'penetration']}], 'Product Development and Launch': [{'text': 'Investment in R&D resulted in three new product launches.', 'relevance': 0.9, 'keywords': ['investment', 'R&D', 'product', 'launch']}], 'Sales Performance': [{'text': 'Sales performance exceeded targets in key market segments.', 'relevance': 0.9, 'keywords': ['sales', 'performance', 'exceed', 'target', 'segment']}]}, 'relationships': {'Strategic Partnerships': ['Product Development and Launch', 'Sales Performance'], 'Product Development and Launch': ['Sales Performance'], 'Sales Performance': ['Strategic Partnerships']}}\n",
      "\n",
      "Processed LLM response: {'themes': [{'name': 'Strategic Partnerships', 'description': 'The role of strategic partnerships in fostering innovation and enhancing market presence.', 'confidence': 0.95, 'keywords': ['partnership', 'strategic', 'drive', 'innovation'], 'domain': 'business', 'parent_theme': None}, {'name': 'Product Development and Launch', 'description': 'The impact of investment in research and development on new product launches.', 'confidence': 0.9, 'keywords': ['investment', 'R&D', 'product', 'launch'], 'domain': 'business', 'parent_theme': None}, {'name': 'Sales Performance', 'description': 'The achievement of sales targets and performance in key market segments.', 'confidence': 0.85, 'keywords': ['sales', 'performance', 'exceed', 'target', 'segment'], 'domain': 'business', 'parent_theme': None}], 'evidence': {'Strategic Partnerships': [{'text': 'Strategic partnerships drive innovation and market penetration.', 'relevance': 0.9, 'keywords': ['partnership', 'drive', 'innovation', 'penetration']}], 'Product Development and Launch': [{'text': 'Investment in R&D resulted in three new product launches.', 'relevance': 0.9, 'keywords': ['investment', 'R&D', 'product', 'launch']}], 'Sales Performance': [{'text': 'Sales performance exceeded targets in key market segments.', 'relevance': 0.9, 'keywords': ['sales', 'performance', 'exceed', 'target', 'segment']}]}, 'relationships': {'Strategic Partnerships': ['Product Development and Launch', 'Sales Performance'], 'Product Development and Launch': ['Sales Performance'], 'Sales Performance': ['Strategic Partnerships']}}\n",
      "\n",
      "Raw LLM response: {'themes': [{'name': 'Professional Development', 'description': 'Programs designed to enhance skills and competencies relevant to the industry, focusing on career advancement.', 'confidence': 0.95, 'keywords': ['professional', 'development', 'program', 'industry-relevant'], 'domain': 'business', 'parent_theme': None}, {'name': 'Mentoring and Guidance', 'description': 'The role of mentoring sessions in providing support and guidance for individuals seeking career advancement.', 'confidence': 0.9, 'keywords': ['mentoring', 'guidance', 'career', 'advancement'], 'domain': 'business', 'parent_theme': 'Professional Development'}, {'name': 'Competency Assessment', 'description': 'The process of tracking progress towards learning goals through competency assessments.', 'confidence': 0.85, 'keywords': ['competency', 'assessment', 'progress', 'goal'], 'domain': 'technical', 'parent_theme': 'Professional Development'}], 'evidence': {'Professional Development': [{'text': 'Professional development programs focus on industry-relevant skills.', 'relevance': 0.9, 'keywords': ['professional', 'development', 'industry-relevant', 'skills']}], 'Mentoring and Guidance': [{'text': 'Mentoring sessions provide guidance for career advancement.', 'relevance': 0.9, 'keywords': ['mentoring', 'guidance', 'career', 'advancement']}], 'Competency Assessment': [{'text': 'Competency assessments track progress towards learning goals.', 'relevance': 0.9, 'keywords': ['competency', 'assessment', 'track', 'progress', 'goal']}]}, 'relationships': {'Professional Development': ['Mentoring and Guidance', 'Competency Assessment'], 'Mentoring and Guidance': [], 'Competency Assessment': []}}\n",
      "\n",
      "Processed LLM response: {'themes': [{'name': 'Professional Development', 'description': 'Programs designed to enhance skills and competencies relevant to the industry, focusing on career advancement.', 'confidence': 0.95, 'keywords': ['professional', 'development', 'program', 'industry-relevant'], 'domain': 'business', 'parent_theme': None}, {'name': 'Mentoring and Guidance', 'description': 'The role of mentoring sessions in providing support and guidance for individuals seeking career advancement.', 'confidence': 0.9, 'keywords': ['mentoring', 'guidance', 'career', 'advancement'], 'domain': 'business', 'parent_theme': 'Professional Development'}, {'name': 'Competency Assessment', 'description': 'The process of tracking progress towards learning goals through competency assessments.', 'confidence': 0.85, 'keywords': ['competency', 'assessment', 'progress', 'goal'], 'domain': 'technical', 'parent_theme': 'Professional Development'}], 'evidence': {'Professional Development': [{'text': 'Professional development programs focus on industry-relevant skills.', 'relevance': 0.9, 'keywords': ['professional', 'development', 'industry-relevant', 'skills']}], 'Mentoring and Guidance': [{'text': 'Mentoring sessions provide guidance for career advancement.', 'relevance': 0.9, 'keywords': ['mentoring', 'guidance', 'career', 'advancement']}], 'Competency Assessment': [{'text': 'Competency assessments track progress towards learning goals.', 'relevance': 0.9, 'keywords': ['competency', 'assessment', 'track', 'progress', 'goal']}]}, 'relationships': {'Professional Development': ['Mentoring and Guidance', 'Competency Assessment'], 'Mentoring and Guidance': [], 'Competency Assessment': []}}\n",
      "\n",
      "Raw LLM response: {'themes': [{'name': 'Operational Efficiency', 'description': 'The theme focuses on the improvements in operational processes through automation, leading to enhanced productivity and effectiveness.', 'confidence': 0.95, 'keywords': ['operational', 'efficiency', 'automation', 'process'], 'domain': 'business', 'parent_theme': None}, {'name': 'Customer Satisfaction', 'description': 'This theme highlights the positive trends in customer satisfaction metrics, indicating an improvement in customer experience and service delivery.', 'confidence': 0.9, 'keywords': ['customer', 'satisfaction', 'metric', 'positive', 'trend'], 'domain': 'business', 'parent_theme': None}, {'name': 'Cost Optimization', 'description': 'The theme revolves around initiatives aimed at reducing costs, exemplified by the reported savings achieved in a specific quarter.', 'confidence': 0.85, 'keywords': ['cost', 'optimization', 'saving', 'initiative'], 'domain': 'business', 'parent_theme': None}], 'evidence': {'Operational Efficiency': [{'text': 'Operational efficiency improved through process automation.', 'relevance': 0.9, 'keywords': ['operational', 'efficiency', 'automation']}], 'Customer Satisfaction': [{'text': 'Customer satisfaction metrics show positive trend year-over-year.', 'relevance': 0.9, 'keywords': ['customer', 'satisfaction', 'metric', 'positive', 'trend']}], 'Cost Optimization': [{'text': 'Cost optimization initiatives delivered 12% savings in Q4.', 'relevance': 0.9, 'keywords': ['cost', 'optimization', 'saving', 'initiative']}]}, 'relationships': {'Operational Efficiency': ['Customer Satisfaction', 'Cost Optimization'], 'Customer Satisfaction': ['Operational Efficiency'], 'Cost Optimization': ['Operational Efficiency']}}\n",
      "\n",
      "Processed LLM response: {'themes': [{'name': 'Operational Efficiency', 'description': 'The theme focuses on the improvements in operational processes through automation, leading to enhanced productivity and effectiveness.', 'confidence': 0.95, 'keywords': ['operational', 'efficiency', 'automation', 'process'], 'domain': 'business', 'parent_theme': None}, {'name': 'Customer Satisfaction', 'description': 'This theme highlights the positive trends in customer satisfaction metrics, indicating an improvement in customer experience and service delivery.', 'confidence': 0.9, 'keywords': ['customer', 'satisfaction', 'metric', 'positive', 'trend'], 'domain': 'business', 'parent_theme': None}, {'name': 'Cost Optimization', 'description': 'The theme revolves around initiatives aimed at reducing costs, exemplified by the reported savings achieved in a specific quarter.', 'confidence': 0.85, 'keywords': ['cost', 'optimization', 'saving', 'initiative'], 'domain': 'business', 'parent_theme': None}], 'evidence': {'Operational Efficiency': [{'text': 'Operational efficiency improved through process automation.', 'relevance': 0.9, 'keywords': ['operational', 'efficiency', 'automation']}], 'Customer Satisfaction': [{'text': 'Customer satisfaction metrics show positive trend year-over-year.', 'relevance': 0.9, 'keywords': ['customer', 'satisfaction', 'metric', 'positive', 'trend']}], 'Cost Optimization': [{'text': 'Cost optimization initiatives delivered 12% savings in Q4.', 'relevance': 0.9, 'keywords': ['cost', 'optimization', 'saving', 'initiative']}]}, 'relationships': {'Operational Efficiency': ['Customer Satisfaction', 'Cost Optimization'], 'Customer Satisfaction': ['Operational Efficiency'], 'Cost Optimization': ['Operational Efficiency']}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-12-12 18:55:07,538 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Raw LLM response: {'themes': [{'name': 'Cloud Computing Services', 'description': 'The provision of scalable infrastructure that supports various deployments in a cloud environment.', 'confidence': 0.95, 'keywords': ['cloud', 'computing', 'scalable', 'infrastructure', 'deployment'], 'domain': 'technical/business'}, {'name': 'Microservices Architecture', 'description': 'A design approach that promotes modularity and maintainability in system development, allowing for independent deployment of services.', 'confidence': 0.9, 'keywords': ['microservices', 'architecture', 'modular', 'maintainable', 'system', 'design'], 'domain': 'technical/business'}, {'name': 'API Management', 'description': 'The handling of authentication and data validation through API endpoints, ensuring secure and reliable communication between services.', 'confidence': 0.85, 'keywords': ['API', 'endpoints', 'authentication', 'data', 'validation', 'requirements'], 'domain': 'technical/business'}], 'evidence': {'Cloud Computing Services': [{'text': 'Cloud computing services provide scalable infrastructure for deployments.', 'relevance': 0.9, 'keywords': ['cloud', 'computing', 'scalable', 'infrastructure', 'deployment']}], 'Microservices Architecture': [{'text': 'Microservices architecture enables modular and maintainable system design.', 'relevance': 0.9, 'keywords': ['microservices', 'architecture', 'modular', 'maintainable', 'system', 'design']}], 'API Management': [{'text': 'API endpoints handle authentication and data validation requirements.', 'relevance': 0.9, 'keywords': ['API', 'endpoints', 'authentication', 'data', 'validation', 'requirements']}]}, 'relationships': {'Cloud Computing Services': ['Microservices Architecture', 'API Management'], 'Microservices Architecture': ['Cloud Computing Services', 'API Management'], 'API Management': ['Cloud Computing Services', 'Microservices Architecture']}}\n",
      "\n",
      "Processed LLM response: {'themes': [{'name': 'Cloud Computing Services', 'description': 'The provision of scalable infrastructure that supports various deployments in a cloud environment.', 'confidence': 0.95, 'keywords': ['cloud', 'computing', 'scalable', 'infrastructure', 'deployment'], 'domain': 'technical/business'}, {'name': 'Microservices Architecture', 'description': 'A design approach that promotes modularity and maintainability in system development, allowing for independent deployment of services.', 'confidence': 0.9, 'keywords': ['microservices', 'architecture', 'modular', 'maintainable', 'system', 'design'], 'domain': 'technical/business'}, {'name': 'API Management', 'description': 'The handling of authentication and data validation through API endpoints, ensuring secure and reliable communication between services.', 'confidence': 0.85, 'keywords': ['API', 'endpoints', 'authentication', 'data', 'validation', 'requirements'], 'domain': 'technical/business'}], 'evidence': {'Cloud Computing Services': [{'text': 'Cloud computing services provide scalable infrastructure for deployments.', 'relevance': 0.9, 'keywords': ['cloud', 'computing', 'scalable', 'infrastructure', 'deployment']}], 'Microservices Architecture': [{'text': 'Microservices architecture enables modular and maintainable system design.', 'relevance': 0.9, 'keywords': ['microservices', 'architecture', 'modular', 'maintainable', 'system', 'design']}], 'API Management': [{'text': 'API endpoints handle authentication and data validation requirements.', 'relevance': 0.9, 'keywords': ['API', 'endpoints', 'authentication', 'data', 'validation', 'requirements']}]}, 'relationships': {'Cloud Computing Services': ['Microservices Architecture', 'API Management'], 'Microservices Architecture': ['Cloud Computing Services', 'API Management'], 'API Management': ['Cloud Computing Services', 'Microservices Architecture']}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-12-12 18:55:08,472 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-12-12 18:55:08,476 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-12-12 18:55:08,491 - src.analyzers.excel_support - INFO - Theme analysis complete\n",
      "Analysis Progress: 100%|██████████| 2/2 [00:20<00:00, 10.13s/it]\n",
      "2024-12-12 18:55:08,499 - src.semantic_analyzer.analyzer - INFO - Combining results...\n",
      "2024-12-12 18:55:08,512 - src.semantic_analyzer.analyzer - INFO - Saving results...\n",
      "2024-12-12 18:55:08,586 - LocalStorage - INFO - Saved Excel file with sheets: ['Analysis Results']\n",
      "2024-12-12 18:55:08,586 - LocalStorage - INFO - Saved Excel file with sheets: ['Analysis Results']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Raw LLM response: {'themes': [{'name': 'Integration of Theory and Practice', 'description': 'The theme emphasizes the combination of theoretical concepts with practical exercises in classroom workshops, highlighting the importance of applying knowledge in real-world scenarios.', 'confidence': 0.95, 'keywords': ['theoretical', 'exercise', 'combine', 'hands-on', 'workshop'], 'domain': 'technical/business', 'parent_theme': None}, {'name': 'Peer Learning and Collaboration', 'description': 'This theme focuses on the role of small group activities in promoting peer learning and knowledge sharing among participants, fostering a collaborative learning environment.', 'confidence': 0.9, 'keywords': ['peer', 'group', 'activity', 'share', 'knowledge'], 'domain': 'technical/business', 'parent_theme': None}, {'name': 'Reinforcement of Learning Objectives', 'description': 'The theme highlights the importance of practice sessions in reinforcing key learning objectives, ensuring that participants effectively grasp and retain the material.', 'confidence': 0.85, 'keywords': ['reinforce', 'key', 'learning', 'objective', 'practice'], 'domain': 'technical/business', 'parent_theme': None}], 'evidence': {'Integration of Theory and Practice': [{'text': 'Classroom workshops combine theoretical concepts with hands-on exercises.', 'relevance': 0.9, 'keywords': ['theoretical', 'combine', 'hands-on', 'workshop']}], 'Peer Learning and Collaboration': [{'text': 'Small group activities promote peer learning and knowledge sharing.', 'relevance': 0.9, 'keywords': ['peer', 'group', 'activity', 'share', 'knowledge']}], 'Reinforcement of Learning Objectives': [{'text': 'Practice sessions reinforce key learning objectives.', 'relevance': 0.9, 'keywords': ['reinforce', 'key', 'learning', 'objective', 'practice']}]}, 'relationships': {'Integration of Theory and Practice': ['Peer Learning and Collaboration', 'Reinforcement of Learning Objectives'], 'Peer Learning and Collaboration': ['Integration of Theory and Practice', 'Reinforcement of Learning Objectives'], 'Reinforcement of Learning Objectives': ['Integration of Theory and Practice', 'Peer Learning and Collaboration']}}\n",
      "\n",
      "Processed LLM response: {'themes': [{'name': 'Integration of Theory and Practice', 'description': 'The theme emphasizes the combination of theoretical concepts with practical exercises in classroom workshops, highlighting the importance of applying knowledge in real-world scenarios.', 'confidence': 0.95, 'keywords': ['theoretical', 'exercise', 'combine', 'hands-on', 'workshop'], 'domain': 'technical/business', 'parent_theme': None}, {'name': 'Peer Learning and Collaboration', 'description': 'This theme focuses on the role of small group activities in promoting peer learning and knowledge sharing among participants, fostering a collaborative learning environment.', 'confidence': 0.9, 'keywords': ['peer', 'group', 'activity', 'share', 'knowledge'], 'domain': 'technical/business', 'parent_theme': None}, {'name': 'Reinforcement of Learning Objectives', 'description': 'The theme highlights the importance of practice sessions in reinforcing key learning objectives, ensuring that participants effectively grasp and retain the material.', 'confidence': 0.85, 'keywords': ['reinforce', 'key', 'learning', 'objective', 'practice'], 'domain': 'technical/business', 'parent_theme': None}], 'evidence': {'Integration of Theory and Practice': [{'text': 'Classroom workshops combine theoretical concepts with hands-on exercises.', 'relevance': 0.9, 'keywords': ['theoretical', 'combine', 'hands-on', 'workshop']}], 'Peer Learning and Collaboration': [{'text': 'Small group activities promote peer learning and knowledge sharing.', 'relevance': 0.9, 'keywords': ['peer', 'group', 'activity', 'share', 'knowledge']}], 'Reinforcement of Learning Objectives': [{'text': 'Practice sessions reinforce key learning objectives.', 'relevance': 0.9, 'keywords': ['reinforce', 'key', 'learning', 'objective', 'practice']}]}, 'relationships': {'Integration of Theory and Practice': ['Peer Learning and Collaboration', 'Reinforcement of Learning Objectives'], 'Peer Learning and Collaboration': ['Integration of Theory and Practice', 'Reinforcement of Learning Objectives'], 'Reinforcement of Learning Objectives': ['Integration of Theory and Practice', 'Peer Learning and Collaboration']}}\n",
      "\n",
      "Raw LLM response: {'themes': [{'name': 'Machine Learning Process', 'description': 'The systematic approach to training machine learning models using large datasets, emphasizing the importance of data preprocessing and feature engineering.', 'confidence': 0.95, 'keywords': ['machine learning', 'training', 'datasets', 'preprocessing', 'feature engineering'], 'domain': 'technical', 'parent_theme': None}, {'name': 'Neural Network Architecture', 'description': 'The structure of neural networks, which includes multiple layers designed for effective feature extraction and pattern recognition.', 'confidence': 0.9, 'keywords': ['neural network', 'architecture', 'layers', 'feature extraction', 'pattern recognition'], 'domain': 'technical', 'parent_theme': 'Machine Learning Process'}, {'name': 'Data Handling Techniques', 'description': 'The essential techniques involved in preparing and managing data for machine learning, including data preprocessing and the significance of feature engineering.', 'confidence': 0.85, 'keywords': ['data handling', 'preprocessing', 'feature engineering', 'pipeline'], 'domain': 'technical', 'parent_theme': 'Machine Learning Process'}], 'evidence': {'Machine Learning Process': [{'text': 'Machine learning models are trained using large datasets to recognize patterns.', 'relevance': 0.9, 'keywords': ['machine learning', 'trained', 'large datasets', 'recognize patterns']}, {'text': 'Data preprocessing and feature engineering are crucial steps in the pipeline.', 'relevance': 0.9, 'keywords': ['data preprocessing', 'feature engineering', 'crucial steps', 'pipeline']}], 'Neural Network Architecture': [{'text': 'The neural network architecture includes multiple layers for feature extraction.', 'relevance': 0.9, 'keywords': ['neural network architecture', 'multiple layers', 'feature extraction']}], 'Data Handling Techniques': [{'text': 'Data preprocessing and feature engineering are crucial steps in the pipeline.', 'relevance': 0.85, 'keywords': ['data preprocessing', 'feature engineering', 'pipeline']}]}, 'relationships': {'Machine Learning Process': ['Neural Network Architecture', 'Data Handling Techniques'], 'Neural Network Architecture': [], 'Data Handling Techniques': []}}\n",
      "\n",
      "Processed LLM response: {'themes': [{'name': 'Machine Learning Process', 'description': 'The systematic approach to training machine learning models using large datasets, emphasizing the importance of data preprocessing and feature engineering.', 'confidence': 0.95, 'keywords': ['machine learning', 'training', 'datasets', 'preprocessing', 'feature engineering'], 'domain': 'technical', 'parent_theme': None}, {'name': 'Neural Network Architecture', 'description': 'The structure of neural networks, which includes multiple layers designed for effective feature extraction and pattern recognition.', 'confidence': 0.9, 'keywords': ['neural network', 'architecture', 'layers', 'feature extraction', 'pattern recognition'], 'domain': 'technical', 'parent_theme': 'Machine Learning Process'}, {'name': 'Data Handling Techniques', 'description': 'The essential techniques involved in preparing and managing data for machine learning, including data preprocessing and the significance of feature engineering.', 'confidence': 0.85, 'keywords': ['data handling', 'preprocessing', 'feature engineering', 'pipeline'], 'domain': 'technical', 'parent_theme': 'Machine Learning Process'}], 'evidence': {'Machine Learning Process': [{'text': 'Machine learning models are trained using large datasets to recognize patterns.', 'relevance': 0.9, 'keywords': ['machine learning', 'trained', 'large datasets', 'recognize patterns']}, {'text': 'Data preprocessing and feature engineering are crucial steps in the pipeline.', 'relevance': 0.9, 'keywords': ['data preprocessing', 'feature engineering', 'crucial steps', 'pipeline']}], 'Neural Network Architecture': [{'text': 'The neural network architecture includes multiple layers for feature extraction.', 'relevance': 0.9, 'keywords': ['neural network architecture', 'multiple layers', 'feature extraction']}], 'Data Handling Techniques': [{'text': 'Data preprocessing and feature engineering are crucial steps in the pipeline.', 'relevance': 0.85, 'keywords': ['data preprocessing', 'feature engineering', 'pipeline']}]}, 'relationships': {'Machine Learning Process': ['Neural Network Architecture', 'Data Handling Techniques'], 'Neural Network Architecture': [], 'Data Handling Techniques': []}}\n",
      "✓ Completed themes analysis\n",
      "2024-12-12 18:55:08,589 - FileUtils.core.file_utils - INFO - Data saved successfully: {'analysis_results_20241212_185508': 'c:\\\\Users\\\\tja\\\\OneDrive - Rastor-instituutti ry\\\\Tiedostot\\\\Rastor-instituutti\\\\kehittäminen\\\\analytiikka\\\\repos\\\\semantic-text-analyzer\\\\data\\\\processed\\\\analysis_results_20241212_185508.xlsx'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-12-12 18:55:08,589 - FileUtils.core.file_utils - INFO - Data saved successfully: {'analysis_results_20241212_185508': 'c:\\\\Users\\\\tja\\\\OneDrive - Rastor-instituutti ry\\\\Tiedostot\\\\Rastor-instituutti\\\\kehittäminen\\\\analytiikka\\\\repos\\\\semantic-text-analyzer\\\\data\\\\processed\\\\analysis_results_20241212_185508.xlsx'}\n",
      "2024-12-12 18:55:08,592 - src.semantic_analyzer.analyzer - INFO - Saved results to: c:\\Users\\tja\\OneDrive - Rastor-instituutti ry\\Tiedostot\\Rastor-instituutti\\kehittäminen\\analytiikka\\repos\\semantic-text-analyzer\\data\\processed\\analysis_results_20241212_185508.xlsx\n",
      "2024-12-12 18:55:08,595 - src.semantic_analyzer.analyzer - INFO - Results saved to: c:\\Users\\tja\\OneDrive - Rastor-instituutti ry\\Tiedostot\\Rastor-instituutti\\kehittäminen\\analytiikka\\repos\\semantic-text-analyzer\\data\\processed\\analysis_results_20241212_185508.xlsx\n",
      "2024-12-12 18:55:08,596 - src.semantic_analyzer.analyzer - INFO - Analysis completed in 20.37 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Analysis Results Summary\n",
      "==================================================\n",
      "Total rows processed: 9\n",
      "Language: en\n",
      "Average processing time: 20.29s\n",
      "\n",
      "Keywords Results\n",
      "--------------------------------------------------\n",
      "\n",
      "Row 1:\n",
      "  id: technical_1\n",
      "  type: technical\n",
      "  language: en\n",
      "  keyword_scores: 0.95, 0.95, 0.90, 0.90, 0.90, 0.85, 0.85, 0.80\n",
      "  keyword_domains: technical, technical, technical, technical, technical, technical, technical, technical\n",
      "\n",
      "Row 2:\n",
      "  id: technical_2\n",
      "  type: technical\n",
      "  language: en\n",
      "  keyword_scores: 0.95, 0.95, 0.95, 0.90\n",
      "  keyword_domains: technical, technical, technical, technical\n",
      "\n",
      "Row 3:\n",
      "  id: technical_3\n",
      "  type: technical\n",
      "  language: en\n",
      "  keyword_scores: 0.95, 0.95, 0.90, 0.90, 0.90, 0.90\n",
      "  keyword_domains: technical, technical, technical, technical, technical, technical\n",
      "\n",
      "Themes Results\n",
      "--------------------------------------------------\n",
      "\n",
      "Row 1:\n",
      "  id: technical_1\n",
      "  type: technical\n",
      "  language: en\n",
      "  theme_descriptions: The systematic approach to training machine learning models using large datasets, emphasizing the importance of data preprocessing and feature engineering.; The structure of neural networks, which includes multiple layers designed for effective feature extraction and pattern recognition.; The essential techniques involved in preparing and managing data for machine learning, including data preprocessing and the significance of feature engineering.\n",
      "  theme_confidence: 0.95, 0.90, 0.85\n",
      "\n",
      "Row 2:\n",
      "  id: technical_2\n",
      "  type: technical\n",
      "  language: en\n",
      "  theme_descriptions: The provision of scalable infrastructure that supports various deployments in a cloud environment.; A design approach that promotes modularity and maintainability in system development, allowing for independent deployment of services.; The handling of authentication and data validation through API endpoints, ensuring secure and reliable communication between services.\n",
      "  theme_confidence: 0.95, 0.90, 0.85\n",
      "\n",
      "Row 3:\n",
      "  id: technical_3\n",
      "  type: technical\n",
      "  language: en\n",
      "  theme_descriptions: Version control systems are essential tools for tracking changes in source code repositories, allowing teams to manage code revisions effectively.; Continuous integration is a development practice that ensures code quality through automated testing and integration of code changes.; Documentation is crucial for providing detailed information on API usage and system architecture, facilitating better understanding and maintenance of software systems.\n",
      "  theme_confidence: 0.95, 0.95, 0.90\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    print(\"Running Excel-based analysis...\")\n",
    "\n",
    "    # await run(\n",
    "    await analyze_excel_content(\n",
    "        content_file=\"test_content_fi.xlsx\",\n",
    "        parameter_file=\"parameters_fi.xlsx\",\n",
    "        analysis_types=[\"keywords\", \"themes\"],\n",
    "    )\n",
    "    # )\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "semantic-analyzer",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
