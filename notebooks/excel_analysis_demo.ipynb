{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import asyncio\n",
    "from pathlib import Path\n",
    "import logging\n",
    "import sys\n",
    "from typing import List, Optional\n",
    "\n",
    "# Add project root to Python path if needed\n",
    "project_root = str(Path().resolve().parent)\n",
    "if project_root not in sys.path:\n",
    "    sys.path.append(project_root)\n",
    "\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "from FileUtils import FileUtils, OutputFileType\n",
    "\n",
    "from src.semantic_analyzer import SemanticAnalyzer\n",
    "\n",
    "# Configure logging\n",
    "# logging.basicConfig(\n",
    "#     level=logging.INFO,\n",
    "#     format=\"%(asctime)s - %(name)s - %(levelname)s - %(message)s\",\n",
    "# )\n",
    "# logger = logging.getLogger(__name__)\n",
    "from src.nb_helpers.environment import setup_notebook_env, verify_environment\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-12-12 18:59:26,565 - FileUtils.core.file_utils - INFO - Project root: c:\\Users\\tja\\OneDrive - Rastor-instituutti ry\\Tiedostot\\Rastor-instituutti\\kehittäminen\\analytiikka\\repos\\semantic-text-analyzer\n",
      "2024-12-12 18:59:26,572 - FileUtils.core.file_utils - INFO - FileUtils initialized with local storage\n",
      "Environment Check Results:\n",
      "==================================================\n",
      "\n",
      "Basic Setup:\n",
      "-----------\n",
      "✓ Project root in path\n",
      "✓ FileUtils initialized\n",
      "✓ .env file loaded\n",
      "\n",
      "Environment Variables:\n",
      "---------------------\n",
      "✓ OPENAI_API_KEY set\n",
      "✓ ANTHROPIC_API_KEY set\n",
      "\n",
      "Project Structure:\n",
      "-----------------\n",
      "✓ Raw data exists\n",
      "✓ Processed data exists\n",
      "✓ Configuration exists\n",
      "✓ Main config.yaml exists\n",
      "\n",
      "==================================================\n",
      "Environment Status: Ready ✓\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Set up environment and verify\n",
    "setup_notebook_env(log_level=\"WARNING\")\n",
    "verify_environment()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_analysis_summary(results: pd.DataFrame) -> None:\n",
    "    \"\"\"Display formatted analysis summary.\"\"\"\n",
    "    print(\"\\nAnalysis Results Summary\")\n",
    "    print(\"=\" * 50)\n",
    "\n",
    "    # Basic stats\n",
    "    print(f\"Total rows processed: {len(results)}\")\n",
    "    if \"language\" in results.columns:\n",
    "        print(f\"Language: {results['language'].iloc[0]}\")\n",
    "    if \"processing_time\" in results.columns:\n",
    "        print(\n",
    "            f\"Average processing time: {results['processing_time'].mean():.2f}s\"\n",
    "        )\n",
    "\n",
    "    # Results by type\n",
    "    result_sections = {\n",
    "        \"Keywords\": [\n",
    "            col for col in results.columns if col.startswith(\"keywords_\")\n",
    "        ],\n",
    "        \"Themes\": [col for col in results.columns if col.startswith(\"themes_\")],\n",
    "        \"Categories\": [\n",
    "            col for col in results.columns if col.startswith(\"categories_\")\n",
    "        ],\n",
    "    }\n",
    "\n",
    "    for section_name, columns in result_sections.items():\n",
    "        if columns:\n",
    "            print(f\"\\n{section_name} Results\")\n",
    "            print(\"-\" * 50)\n",
    "\n",
    "            # Display first 3 rows for each result type\n",
    "            sample_results = results[columns].head(3)\n",
    "\n",
    "            # Format each cell for display\n",
    "            for idx, row in sample_results.iterrows():\n",
    "                print(f\"\\nRow {idx + 1}:\")\n",
    "                for col in columns:\n",
    "                    value = row[col]\n",
    "                    if pd.notna(value):\n",
    "                        print(f\"  {col.split('_', 1)[1]}: {value}\")\n",
    "\n",
    "\n",
    "async def analyze_excel_content(\n",
    "    content_file: str = \"test_content_en.xlsx\",\n",
    "    parameter_file: str = \"parameters_en.xlsx\",\n",
    "    content_column: str = \"content\",\n",
    "    analysis_types: Optional[List[str]] = None,\n",
    "    batch_size: int = 10,\n",
    ") -> None:\n",
    "    \"\"\"Run Excel-based analysis with progress reporting.\"\"\"\n",
    "    try:\n",
    "        # Initialize FileUtils\n",
    "        file_utils = FileUtils()\n",
    "\n",
    "        # Verify paths with progress\n",
    "        with tqdm(total=2, desc=\"Checking files\") as pbar:\n",
    "            content_path = file_utils.get_data_path(\"raw\") / content_file\n",
    "            pbar.update(1)\n",
    "\n",
    "            param_path = file_utils.get_data_path(\"parameters\") / parameter_file\n",
    "            pbar.update(1)\n",
    "\n",
    "            if not content_path.exists():\n",
    "                raise FileNotFoundError(\n",
    "                    f\"Content file not found: {content_path}\"\n",
    "                )\n",
    "            if not param_path.exists():\n",
    "                raise FileNotFoundError(\n",
    "                    f\"Parameter file not found: {param_path}\"\n",
    "                )\n",
    "\n",
    "        print(\"\\nStarting analysis:\")\n",
    "        print(f\"Content file: {content_path}\")\n",
    "        print(f\"Parameter file: {param_path}\")\n",
    "        print(f\"Analysis types: {analysis_types or 'all'}\")\n",
    "\n",
    "        # Create and run analyzer\n",
    "        analyzer = SemanticAnalyzer.from_excel(\n",
    "            content_file=content_file,\n",
    "            parameter_file=parameter_file,\n",
    "            content_column=content_column,\n",
    "            file_utils=file_utils,\n",
    "        )\n",
    "\n",
    "        # Run analysis with progress\n",
    "        results = await analyzer.analyze_excel(\n",
    "            analysis_types=analysis_types,\n",
    "            batch_size=batch_size,\n",
    "            save_results=True,\n",
    "            output_file=\"analysis_results\",\n",
    "            show_progress=True,\n",
    "        )\n",
    "\n",
    "        # Display formatted results\n",
    "        display_analysis_summary(results)\n",
    "\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Analysis failed: {e}\", exc_info=True)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running Excel-based analysis...\n",
      "2024-12-12 18:59:26,782 - FileUtils.core.file_utils - INFO - Project root: c:\\Users\\tja\\OneDrive - Rastor-instituutti ry\\Tiedostot\\Rastor-instituutti\\kehittäminen\\analytiikka\\repos\\semantic-text-analyzer\n",
      "2024-12-12 18:59:26,791 - FileUtils.core.file_utils - INFO - FileUtils initialized with local storage\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Checking files: 100%|██████████| 2/2 [00:00<00:00, 1000.19it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Starting analysis:\n",
      "Content file: c:\\Users\\tja\\OneDrive - Rastor-instituutti ry\\Tiedostot\\Rastor-instituutti\\kehittäminen\\analytiikka\\repos\\semantic-text-analyzer\\data\\raw\\test_content_fi.xlsx\n",
      "Parameter file: c:\\Users\\tja\\OneDrive - Rastor-instituutti ry\\Tiedostot\\Rastor-instituutti\\kehittäminen\\analytiikka\\repos\\semantic-text-analyzer\\data\\parameters\\parameters_fi.xlsx\n",
      "Analysis types: ['keywords', 'themes']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-12-12 18:59:27,579 - FileUtils.core.file_utils - INFO - Project root: c:\\Users\\tja\\OneDrive - Rastor-instituutti ry\\Tiedostot\\Rastor-instituutti\\kehittäminen\\analytiikka\\repos\\semantic-text-analyzer\n",
      "2024-12-12 18:59:27,585 - FileUtils.core.file_utils - INFO - FileUtils initialized with local storage\n",
      "2024-12-12 18:59:27,681 - FileUtils.core.file_utils - INFO - Project root: c:\\Users\\tja\\OneDrive - Rastor-instituutti ry\\Tiedostot\\Rastor-instituutti\\kehittäminen\\analytiikka\\repos\\semantic-text-analyzer\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO: Project root: c:\\Users\\tja\\OneDrive - Rastor-instituutti ry\\Tiedostot\\Rastor-instituutti\\kehittäminen\\analytiikka\\repos\\semantic-text-analyzer\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-12-12 18:59:27,690 - FileUtils.core.file_utils - INFO - FileUtils initialized with local storage\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO: FileUtils initialized with local storage\n",
      "INFO: Initializing analyzers for language: fi\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-12-12 18:59:29,089 - FileUtils.core.file_utils - INFO - Project root: c:\\Users\\tja\\OneDrive - Rastor-instituutti ry\\Tiedostot\\Rastor-instituutti\\kehittäminen\\analytiikka\\repos\\semantic-text-analyzer\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO: Project root: c:\\Users\\tja\\OneDrive - Rastor-instituutti ry\\Tiedostot\\Rastor-instituutti\\kehittäminen\\analytiikka\\repos\\semantic-text-analyzer\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-12-12 18:59:29,096 - FileUtils.core.file_utils - INFO - FileUtils initialized with local storage\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO: FileUtils initialized with local storage\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-12-12 18:59:29,167 - FileUtils.core.file_utils - INFO - Project root: c:\\Users\\tja\\OneDrive - Rastor-instituutti ry\\Tiedostot\\Rastor-instituutti\\kehittäminen\\analytiikka\\repos\\semantic-text-analyzer\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO: Project root: c:\\Users\\tja\\OneDrive - Rastor-instituutti ry\\Tiedostot\\Rastor-instituutti\\kehittäminen\\analytiikka\\repos\\semantic-text-analyzer\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-12-12 18:59:29,174 - FileUtils.core.file_utils - INFO - FileUtils initialized with local storage\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO: FileUtils initialized with local storage\n",
      "INFO: Loaded 747 stopwords from c:\\Users\\tja\\OneDrive - Rastor-instituutti ry\\Tiedostot\\Rastor-instituutti\\kehittäminen\\analytiikka\\repos\\semantic-text-analyzer\\data\\configurations\\stop_words\\fi.txt\n",
      "DEBUG: Initialized with config: {'language': 'fi', 'min_confidence': 0.3, 'focus_on': 'business and technical content analysis', 'max_keywords': 8, 'min_keyword_length': 3, 'include_compounds': True, 'weights': {'statistical': 0.4, 'llm': 0.6}}\n",
      "DEBUG: Trying library paths: ['C:\\\\scripts\\\\Voikko\\\\libvoikko-1.dll', 'C:\\\\Program Files\\\\Voikko\\\\libvoikko-1.dll', 'C:\\\\Voikko\\\\libvoikko-1.dll']\n",
      "DEBUG: Trying dictionary paths: ['C:\\\\scripts\\\\Voikko', 'C:\\\\Program Files\\\\Voikko', 'C:\\\\Voikko']\n",
      "DEBUG: Added C:\\scripts\\Voikko to DLL search path\n",
      "INFO: Successfully initialized Voikko with path: C:\\scripts\\Voikko\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-12-12 18:59:29,807 - FileUtils.core.file_utils - INFO - Project root: c:\\Users\\tja\\OneDrive - Rastor-instituutti ry\\Tiedostot\\Rastor-instituutti\\kehittäminen\\analytiikka\\repos\\semantic-text-analyzer\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO: Project root: c:\\Users\\tja\\OneDrive - Rastor-instituutti ry\\Tiedostot\\Rastor-instituutti\\kehittäminen\\analytiikka\\repos\\semantic-text-analyzer\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-12-12 18:59:29,814 - FileUtils.core.file_utils - INFO - FileUtils initialized with local storage\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO: FileUtils initialized with local storage\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-12-12 18:59:29,893 - FileUtils.core.file_utils - INFO - Project root: c:\\Users\\tja\\OneDrive - Rastor-instituutti ry\\Tiedostot\\Rastor-instituutti\\kehittäminen\\analytiikka\\repos\\semantic-text-analyzer\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO: Project root: c:\\Users\\tja\\OneDrive - Rastor-instituutti ry\\Tiedostot\\Rastor-instituutti\\kehittäminen\\analytiikka\\repos\\semantic-text-analyzer\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-12-12 18:59:29,900 - FileUtils.core.file_utils - INFO - FileUtils initialized with local storage\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO: FileUtils initialized with local storage\n",
      "INFO: Loaded 747 stopwords from c:\\Users\\tja\\OneDrive - Rastor-instituutti ry\\Tiedostot\\Rastor-instituutti\\kehittäminen\\analytiikka\\repos\\semantic-text-analyzer\\data\\configurations\\stop_words\\fi.txt\n",
      "DEBUG: Initialized with config: {'language': 'fi', 'min_confidence': 0.3, 'focus_on': 'business and technical content analysis', 'max_themes': 3, 'theme_analysis': {'enabled': True, 'min_confidence': 0.5}}\n",
      "DEBUG: Trying library paths: ['C:\\\\scripts\\\\Voikko\\\\libvoikko-1.dll', 'C:\\\\Program Files\\\\Voikko\\\\libvoikko-1.dll', 'C:\\\\Voikko\\\\libvoikko-1.dll']\n",
      "DEBUG: Trying dictionary paths: ['C:\\\\scripts\\\\Voikko', 'C:\\\\Program Files\\\\Voikko', 'C:\\\\Voikko']\n",
      "DEBUG: Added C:\\scripts\\Voikko to DLL search path\n",
      "INFO: Successfully initialized Voikko with path: C:\\scripts\\Voikko\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-12-12 18:59:29,952 - FileUtils.core.file_utils - INFO - Project root: c:\\Users\\tja\\OneDrive - Rastor-instituutti ry\\Tiedostot\\Rastor-instituutti\\kehittäminen\\analytiikka\\repos\\semantic-text-analyzer\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO: Project root: c:\\Users\\tja\\OneDrive - Rastor-instituutti ry\\Tiedostot\\Rastor-instituutti\\kehittäminen\\analytiikka\\repos\\semantic-text-analyzer\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-12-12 18:59:29,960 - FileUtils.core.file_utils - INFO - FileUtils initialized with local storage\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO: FileUtils initialized with local storage\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-12-12 18:59:30,037 - FileUtils.core.file_utils - INFO - Project root: c:\\Users\\tja\\OneDrive - Rastor-instituutti ry\\Tiedostot\\Rastor-instituutti\\kehittäminen\\analytiikka\\repos\\semantic-text-analyzer\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO: Project root: c:\\Users\\tja\\OneDrive - Rastor-instituutti ry\\Tiedostot\\Rastor-instituutti\\kehittäminen\\analytiikka\\repos\\semantic-text-analyzer\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-12-12 18:59:30,044 - FileUtils.core.file_utils - INFO - FileUtils initialized with local storage\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO: FileUtils initialized with local storage\n",
      "INFO: Loaded 747 stopwords from c:\\Users\\tja\\OneDrive - Rastor-instituutti ry\\Tiedostot\\Rastor-instituutti\\kehittäminen\\analytiikka\\repos\\semantic-text-analyzer\\data\\configurations\\stop_words\\fi.txt\n",
      "DEBUG: Initialized with config: {'language': 'fi', 'min_confidence': 0.3, 'focus_on': 'business and technical content analysis', 'categories': {}}\n",
      "DEBUG: Trying library paths: ['C:\\\\scripts\\\\Voikko\\\\libvoikko-1.dll', 'C:\\\\Program Files\\\\Voikko\\\\libvoikko-1.dll', 'C:\\\\Voikko\\\\libvoikko-1.dll']\n",
      "DEBUG: Trying dictionary paths: ['C:\\\\scripts\\\\Voikko', 'C:\\\\Program Files\\\\Voikko', 'C:\\\\Voikko']\n",
      "DEBUG: Added C:\\scripts\\Voikko to DLL search path\n",
      "INFO: Successfully initialized Voikko with path: C:\\scripts\\Voikko\n",
      "INFO: Successfully initialized all analyzers\n",
      "INFO: Running analysis types: ['keywords', 'themes']\n",
      "Analysis Progress:   0%|          | 0/2 [00:00<?, ?it/s]INFO: Running keywords analysis...\n",
      "Analysis Progress:   0%|          | 0/2 [00:00<?, ?it/s]INFO: Starting keyword analysis on 6 rows\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing Keywords...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO: HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO: HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO: HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO: HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO: HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO: HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO: Keyword analysis complete\n",
      "Analysis Progress:  50%|█████     | 1/2 [00:07<00:07,  7.49s/it]INFO: Running themes analysis...\n",
      "Analysis Progress:  50%|█████     | 1/2 [00:07<00:07,  7.49s/it]INFO: Starting theme analysis on 6 rows\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Completed keywords analysis\n",
      "\n",
      "Processing Themes...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO: HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Raw LLM response: {'themes': [{'name': 'Versionhallintajärjestelmät', 'description': 'Versionhallintajärjestelmät ovat työkaluja, jotka seuraavat ja hallitsevat lähdekoodin muutoksia, mahdollistaen tehokkaan kehitystyön.', 'confidence': 0.95, 'keywords': ['versionhallintajärjestelmä', 'lähdekoodi'], 'domain': 'technical', 'parent_theme': None}, {'name': 'Jatkuva integraatio', 'description': 'Jatkuva integraatio on prosessi, joka varmistaa koodin laadun ja mahdollistaa automaattitestauksen, mikä parantaa ohjelmistokehityksen tehokkuutta.', 'confidence': 0.9, 'keywords': ['jatkuva', 'integraatio', 'koodi'], 'domain': 'technical', 'parent_theme': 'Versionhallintajärjestelmät'}], 'evidence': {'Versionhallintajärjestelmät': [{'text': 'Versionhallintajärjestelmät seuraavat lähdekoodin muutoksia.', 'relevance': 0.9, 'keywords': ['versionhallintajärjestelmä', 'lähdekoodi']}], 'Jatkuva integraatio': [{'text': 'Jatkuva integraatio varmistaa koodin laadun ja automaattitestauksen.', 'relevance': 0.9, 'keywords': ['jatkuva', 'integraatio', 'koodi']}]}, 'relationships': {'Versionhallintajärjestelmät': ['Jatkuva integraatio']}}\n",
      "\n",
      "Processed LLM response: {'themes': [{'name': 'Versionhallintajärjestelmät', 'description': 'Versionhallintajärjestelmät ovat työkaluja, jotka seuraavat ja hallitsevat lähdekoodin muutoksia, mahdollistaen tehokkaan kehitystyön.', 'confidence': 0.95, 'keywords': ['versionhallintajärjestelmä', 'lähdekoodi'], 'domain': 'technical', 'parent_theme': None}, {'name': 'Jatkuva integraatio', 'description': 'Jatkuva integraatio on prosessi, joka varmistaa koodin laadun ja mahdollistaa automaattitestauksen, mikä parantaa ohjelmistokehityksen tehokkuutta.', 'confidence': 0.9, 'keywords': ['jatkuva', 'integraatio', 'koodi'], 'domain': 'technical', 'parent_theme': 'Versionhallintajärjestelmät'}], 'evidence': {'Versionhallintajärjestelmät': [{'text': 'Versionhallintajärjestelmät seuraavat lähdekoodin muutoksia.', 'relevance': 0.9, 'keywords': ['versionhallintajärjestelmä', 'lähdekoodi']}], 'Jatkuva integraatio': [{'text': 'Jatkuva integraatio varmistaa koodin laadun ja automaattitestauksen.', 'relevance': 0.9, 'keywords': ['jatkuva', 'integraatio', 'koodi']}]}, 'relationships': {'Versionhallintajärjestelmät': ['Jatkuva integraatio']}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO: HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Raw LLM response: {'themes': [{'name': 'Strategic Partnerships', 'description': 'The role of strategic partnerships in fostering innovation and market penetration.', 'confidence': 0.95, 'keywords': ['kumppanuus', 'strateginen'], 'domain': 'business', 'parent_theme': None}, {'name': 'Innovation and Product Launches', 'description': 'The impact of R&D investments on new product launches and innovation.', 'confidence': 0.9, 'keywords': ['innovaatiota', 'tuotelanseeraukseen'], 'domain': 'technical', 'parent_theme': None}, {'name': 'Market Penetration', 'description': 'The significance of market penetration as a goal for businesses, supported by strategic partnerships.', 'confidence': 0.85, 'keywords': ['markkinapenetraatio'], 'domain': 'business', 'parent_theme': 'Strategic Partnerships'}], 'evidence': {'Strategic Partnerships': [{'text': 'Strategiset kumppanuudet edistävät innovaatiota ja markkinapenetraatiota.', 'relevance': 0.9, 'keywords': ['kumppanuus', 'strateginen']}], 'Innovation and Product Launches': [{'text': 'T&K-investoinnit johtivat kolmeen uuteen tuotelanseeraukseen.', 'relevance': 0.9, 'keywords': ['innovaatiota', 'tuotelanseeraukseen']}], 'Market Penetration': [{'text': 'Strategiset kumppanuudet edistävät innovaatiota ja markkinapenetraatiota.', 'relevance': 0.85, 'keywords': ['markkinapenetraatio']}]}, 'relationships': {'Strategic Partnerships': ['Market Penetration'], 'Innovation and Product Launches': [], 'Market Penetration': []}}\n",
      "\n",
      "Processed LLM response: {'themes': [{'name': 'Strategic Partnerships', 'description': 'The role of strategic partnerships in fostering innovation and market penetration.', 'confidence': 0.95, 'keywords': ['kumppanuus', 'strateginen'], 'domain': 'business', 'parent_theme': None}, {'name': 'Innovation and Product Launches', 'description': 'The impact of R&D investments on new product launches and innovation.', 'confidence': 0.9, 'keywords': ['innovaatiota', 'tuotelanseeraukseen'], 'domain': 'technical', 'parent_theme': None}, {'name': 'Market Penetration', 'description': 'The significance of market penetration as a goal for businesses, supported by strategic partnerships.', 'confidence': 0.85, 'keywords': ['markkinapenetraatio'], 'domain': 'business', 'parent_theme': 'Strategic Partnerships'}], 'evidence': {'Strategic Partnerships': [{'text': 'Strategiset kumppanuudet edistävät innovaatiota ja markkinapenetraatiota.', 'relevance': 0.9, 'keywords': ['kumppanuus', 'strateginen']}], 'Innovation and Product Launches': [{'text': 'T&K-investoinnit johtivat kolmeen uuteen tuotelanseeraukseen.', 'relevance': 0.9, 'keywords': ['innovaatiota', 'tuotelanseeraukseen']}], 'Market Penetration': [{'text': 'Strategiset kumppanuudet edistävät innovaatiota ja markkinapenetraatiota.', 'relevance': 0.85, 'keywords': ['markkinapenetraatio']}]}, 'relationships': {'Strategic Partnerships': ['Market Penetration'], 'Innovation and Product Launches': [], 'Market Penetration': []}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO: HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Raw LLM response: {'themes': [{'name': 'Taloudellinen kasvu', 'description': 'Q3 taloudelliset tulokset osoittavat merkittävää liikevaihdon kasvua, mikä viittaa yrityksen taloudelliseen menestykseen.', 'confidence': 0.95, 'keywords': ['kasvu', 'liikevaihto', 'taloudellinen'], 'domain': 'business', 'parent_theme': None}, {'name': 'Parantuneet katteet', 'description': 'Katteiden parantuminen osoittaa tehokkuuden ja kannattavuuden kasvua yrityksessä.', 'confidence': 0.9, 'keywords': ['parantunut', 'kate', 'kannattavuus'], 'domain': 'business', 'parent_theme': 'Taloudellinen kasvu'}, {'name': 'Asiakashankinnan tehokkuus', 'description': 'Asiakashankinnan kustannusten lasku ja asiakaspysyvyyden parantuminen viittaavat tehokkaampiin markkinointistrategioihin.', 'confidence': 0.85, 'keywords': ['asiakashankinta', 'kustannukset', 'asiakaspysyvyys'], 'domain': 'business', 'parent_theme': None}], 'evidence': {'Taloudellinen kasvu': [{'text': 'Q3 taloudelliset tulokset osoittavat 15% liikevaihdon kasvun', 'relevance': 0.9, 'keywords': ['kasvu', 'liikevaihto']}], 'Parantuneet katteet': [{'text': 'ja parantuneet katteet', 'relevance': 0.85, 'keywords': ['parantunut', 'kate']}], 'Asiakashankinnan tehokkuus': [{'text': 'Asiakashankinnan kustannukset laskivat ja asiakaspysyvyys parani', 'relevance': 0.9, 'keywords': ['asiakashankinta', 'kustannukset', 'asiakaspysyvyys']}]}, 'relationships': {'Taloudellinen kasvu': ['Parantuneet katteet', 'Asiakashankinnan tehokkuus'], 'Parantuneet katteet': [], 'Asiakashankinnan tehokkuus': []}}\n",
      "\n",
      "Processed LLM response: {'themes': [{'name': 'Taloudellinen kasvu', 'description': 'Q3 taloudelliset tulokset osoittavat merkittävää liikevaihdon kasvua, mikä viittaa yrityksen taloudelliseen menestykseen.', 'confidence': 0.95, 'keywords': ['kasvu', 'liikevaihto', 'taloudellinen'], 'domain': 'business', 'parent_theme': None}, {'name': 'Parantuneet katteet', 'description': 'Katteiden parantuminen osoittaa tehokkuuden ja kannattavuuden kasvua yrityksessä.', 'confidence': 0.9, 'keywords': ['parantunut', 'kate', 'kannattavuus'], 'domain': 'business', 'parent_theme': 'Taloudellinen kasvu'}, {'name': 'Asiakashankinnan tehokkuus', 'description': 'Asiakashankinnan kustannusten lasku ja asiakaspysyvyyden parantuminen viittaavat tehokkaampiin markkinointistrategioihin.', 'confidence': 0.85, 'keywords': ['asiakashankinta', 'kustannukset', 'asiakaspysyvyys'], 'domain': 'business', 'parent_theme': None}], 'evidence': {'Taloudellinen kasvu': [{'text': 'Q3 taloudelliset tulokset osoittavat 15% liikevaihdon kasvun', 'relevance': 0.9, 'keywords': ['kasvu', 'liikevaihto']}], 'Parantuneet katteet': [{'text': 'ja parantuneet katteet', 'relevance': 0.85, 'keywords': ['parantunut', 'kate']}], 'Asiakashankinnan tehokkuus': [{'text': 'Asiakashankinnan kustannukset laskivat ja asiakaspysyvyys parani', 'relevance': 0.9, 'keywords': ['asiakashankinta', 'kustannukset', 'asiakaspysyvyys']}]}, 'relationships': {'Taloudellinen kasvu': ['Parantuneet katteet', 'Asiakashankinnan tehokkuus'], 'Parantuneet katteet': [], 'Asiakashankinnan tehokkuus': []}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO: HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Raw LLM response: {'themes': [{'name': 'Koneoppimismallien koulutus', 'description': 'Koneoppimismallien koulutus suurilla datajoukolla on keskeinen prosessi, joka mahdollistaa kaavojen tunnistamisen ja analysoinnin.', 'confidence': 0.95, 'keywords': ['koneoppimismalli', 'datajoukko', 'kaava'], 'domain': 'technical', 'parent_theme': None}, {'name': 'Neuroverkon arkkitehtuuri', 'description': 'Neuroverkon arkkitehtuuri, joka koostuu useista kerroksista, on tärkeä tekijä piirteiden erottamisessa ja analysoinnissa.', 'confidence': 0.9, 'keywords': ['neuroverkko', 'arkkitehtuuri', 'kerros'], 'domain': 'technical', 'parent_theme': None}, {'name': 'Piirteiden erottaminen', 'description': 'Piirteiden erottaminen on prosessi, jossa neuroverkon kerrokset auttavat tunnistamaan ja analysoimaan datasta löytyviä kaavoja.', 'confidence': 0.85, 'keywords': ['erottaa', 'piirre', 'kaava'], 'domain': 'technical', 'parent_theme': 'Koneoppimismallien koulutus'}], 'evidence': {'Koneoppimismallien koulutus': [{'text': 'Koneoppimismalleja koulutetaan suurilla datajoukolla tunnistamaan kaavoja.', 'relevance': 0.9, 'keywords': ['koneoppimismalli', 'datajoukko', 'kaava']}], 'Neuroverkon arkkitehtuuri': [{'text': 'Neuroverkon arkkitehtuuri sisältää useita kerroksia piirteiden erottamiseen.', 'relevance': 0.9, 'keywords': ['neuroverkko', 'arkkitehtuuri', 'kerros']}], 'Piirteiden erottaminen': [{'text': 'Neuroverkon arkkitehtuuri sisältää useita kerroksia piirteiden erottamiseen.', 'relevance': 0.85, 'keywords': ['erottaa', 'piirre', 'kaava']}]}, 'relationships': {'Koneoppimismallien koulutus': ['Neuroverkon arkkitehtuuri'], 'Neuroverkon arkkitehtuuri': ['Piirteiden erottaminen'], 'Piirteiden erottaminen': []}}\n",
      "\n",
      "Processed LLM response: {'themes': [{'name': 'Koneoppimismallien koulutus', 'description': 'Koneoppimismallien koulutus suurilla datajoukolla on keskeinen prosessi, joka mahdollistaa kaavojen tunnistamisen ja analysoinnin.', 'confidence': 0.95, 'keywords': ['koneoppimismalli', 'datajoukko', 'kaava'], 'domain': 'technical', 'parent_theme': None}, {'name': 'Neuroverkon arkkitehtuuri', 'description': 'Neuroverkon arkkitehtuuri, joka koostuu useista kerroksista, on tärkeä tekijä piirteiden erottamisessa ja analysoinnissa.', 'confidence': 0.9, 'keywords': ['neuroverkko', 'arkkitehtuuri', 'kerros'], 'domain': 'technical', 'parent_theme': None}, {'name': 'Piirteiden erottaminen', 'description': 'Piirteiden erottaminen on prosessi, jossa neuroverkon kerrokset auttavat tunnistamaan ja analysoimaan datasta löytyviä kaavoja.', 'confidence': 0.85, 'keywords': ['erottaa', 'piirre', 'kaava'], 'domain': 'technical', 'parent_theme': 'Koneoppimismallien koulutus'}], 'evidence': {'Koneoppimismallien koulutus': [{'text': 'Koneoppimismalleja koulutetaan suurilla datajoukolla tunnistamaan kaavoja.', 'relevance': 0.9, 'keywords': ['koneoppimismalli', 'datajoukko', 'kaava']}], 'Neuroverkon arkkitehtuuri': [{'text': 'Neuroverkon arkkitehtuuri sisältää useita kerroksia piirteiden erottamiseen.', 'relevance': 0.9, 'keywords': ['neuroverkko', 'arkkitehtuuri', 'kerros']}], 'Piirteiden erottaminen': [{'text': 'Neuroverkon arkkitehtuuri sisältää useita kerroksia piirteiden erottamiseen.', 'relevance': 0.85, 'keywords': ['erottaa', 'piirre', 'kaava']}]}, 'relationships': {'Koneoppimismallien koulutus': ['Neuroverkon arkkitehtuuri'], 'Neuroverkon arkkitehtuuri': ['Piirteiden erottaminen'], 'Piirteiden erottaminen': []}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO: HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Raw LLM response: {'themes': [{'name': 'Tehokkuus', 'description': 'Tehokkuuden parantaminen prosessiautomaation avulla, mikä viittaa liiketoiminnan ja teknologian yhdistämiseen.', 'confidence': 0.95, 'keywords': ['tehokkuus', 'prosessiautomaatio'], 'domain': 'business/technical', 'parent_theme': None}, {'name': 'Asiakastyytyväisyys', 'description': 'Asiakastyytyväisyyden mittaaminen ja sen positiivinen kehitys, mikä osoittaa asiakaspalvelun parantumista.', 'confidence': 0.9, 'keywords': ['asiakastyytyväisyys', 'kehitys'], 'domain': 'business/technical', 'parent_theme': None}], 'evidence': {'Tehokkuus': [{'text': 'Toiminnan tehokkuus parani prosessiautomaation avulla.', 'relevance': 0.9, 'keywords': ['tehokkuus', 'prosessiautomaatio']}], 'Asiakastyytyväisyys': [{'text': 'Asiakastyytyväisyysmittarit osoittavat positiivista kehitystä.', 'relevance': 0.9, 'keywords': ['asiakastyytyväisyys', 'kehitys']}]}, 'relationships': {'Tehokkuus': ['Asiakastyytyväisyys'], 'Asiakastyytyväisyys': ['Tehokkuus']}}\n",
      "\n",
      "Processed LLM response: {'themes': [{'name': 'Tehokkuus', 'description': 'Tehokkuuden parantaminen prosessiautomaation avulla, mikä viittaa liiketoiminnan ja teknologian yhdistämiseen.', 'confidence': 0.95, 'keywords': ['tehokkuus', 'prosessiautomaatio'], 'domain': 'business/technical', 'parent_theme': None}, {'name': 'Asiakastyytyväisyys', 'description': 'Asiakastyytyväisyyden mittaaminen ja sen positiivinen kehitys, mikä osoittaa asiakaspalvelun parantumista.', 'confidence': 0.9, 'keywords': ['asiakastyytyväisyys', 'kehitys'], 'domain': 'business/technical', 'parent_theme': None}], 'evidence': {'Tehokkuus': [{'text': 'Toiminnan tehokkuus parani prosessiautomaation avulla.', 'relevance': 0.9, 'keywords': ['tehokkuus', 'prosessiautomaatio']}], 'Asiakastyytyväisyys': [{'text': 'Asiakastyytyväisyysmittarit osoittavat positiivista kehitystä.', 'relevance': 0.9, 'keywords': ['asiakastyytyväisyys', 'kehitys']}]}, 'relationships': {'Tehokkuus': ['Asiakastyytyväisyys'], 'Asiakastyytyväisyys': ['Tehokkuus']}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO: HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO: Theme analysis complete\n",
      "Analysis Progress: 100%|██████████| 2/2 [00:24<00:00, 12.09s/it]\n",
      "INFO: Combining results...\n",
      "INFO: Saving results...\n",
      "2024-12-12 18:59:54,315 - LocalStorage - INFO - Saved Excel file with sheets: ['Analysis Results']\n",
      "INFO: Saved Excel file with sheets: ['Analysis Results']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Raw LLM response: {'themes': [{'name': 'Pilvipalvelut', 'description': 'Pilvipalvelut tarjoavat skaalautuvan infrastruktuurin, joka mahdollistaa joustavan ja tehokkaan resurssien hallinnan.', 'confidence': 0.95, 'keywords': ['pilvipalvelu', 'skaalautuva', 'infrastruktuuri'], 'domain': 'technical/business'}, {'name': 'Mikropalveluarkkitehtuuri', 'description': 'Mikropalveluarkkitehtuuri mahdollistaa modulaarisen järjestelmäsuunnittelun, mikä parantaa kehityksen joustavuutta ja ylläpidettävyyttä.', 'confidence': 0.9, 'keywords': ['mikropalveluarkkitehtuuri', 'modulaarinen', 'järjestelmäsuunnittelu'], 'domain': 'technical/business'}, {'name': 'Käyttöönotto', 'description': 'Käyttöönotto viittaa prosessiin, jossa pilvipalvelut ja mikropalveluarkkitehtuuri otetaan käyttöön organisaatiossa.', 'confidence': 0.85, 'keywords': ['käyttöönotto', 'infrastruktuuri', 'skaalautuva'], 'domain': 'technical/business', 'parent_theme': 'Pilvipalvelut'}], 'evidence': {'Pilvipalvelut': [{'text': 'Pilvipalvelut tarjoavat skaalautuvan infrastruktuurin.', 'relevance': 0.9, 'keywords': ['pilvipalvelu', 'skaalautuva', 'infrastruktuuri']}], 'Mikropalveluarkkitehtuuri': [{'text': 'Mikropalveluarkkitehtuuri mahdollistaa modulaarisen järjestelmäsuunnittelun.', 'relevance': 0.9, 'keywords': ['mikropalveluarkkitehtuuri', 'modulaarinen', 'järjestelmäsuunnittelu']}], 'Käyttöönotto': [{'text': 'Käyttöönotto viittaa prosessiin, jossa pilvipalvelut ja mikropalveluarkkitehtuuri otetaan käyttöön.', 'relevance': 0.85, 'keywords': ['käyttöönotto', 'infrastruktuuri', 'skaalautuva']}]}, 'relationships': {'Pilvipalvelut': ['Mikropalveluarkkitehtuuri', 'Käyttöönotto'], 'Mikropalveluarkkitehtuuri': ['Käyttöönotto']}}\n",
      "\n",
      "Processed LLM response: {'themes': [{'name': 'Pilvipalvelut', 'description': 'Pilvipalvelut tarjoavat skaalautuvan infrastruktuurin, joka mahdollistaa joustavan ja tehokkaan resurssien hallinnan.', 'confidence': 0.95, 'keywords': ['pilvipalvelu', 'skaalautuva', 'infrastruktuuri'], 'domain': 'technical/business'}, {'name': 'Mikropalveluarkkitehtuuri', 'description': 'Mikropalveluarkkitehtuuri mahdollistaa modulaarisen järjestelmäsuunnittelun, mikä parantaa kehityksen joustavuutta ja ylläpidettävyyttä.', 'confidence': 0.9, 'keywords': ['mikropalveluarkkitehtuuri', 'modulaarinen', 'järjestelmäsuunnittelu'], 'domain': 'technical/business'}, {'name': 'Käyttöönotto', 'description': 'Käyttöönotto viittaa prosessiin, jossa pilvipalvelut ja mikropalveluarkkitehtuuri otetaan käyttöön organisaatiossa.', 'confidence': 0.85, 'keywords': ['käyttöönotto', 'infrastruktuuri', 'skaalautuva'], 'domain': 'technical/business', 'parent_theme': 'Pilvipalvelut'}], 'evidence': {'Pilvipalvelut': [{'text': 'Pilvipalvelut tarjoavat skaalautuvan infrastruktuurin.', 'relevance': 0.9, 'keywords': ['pilvipalvelu', 'skaalautuva', 'infrastruktuuri']}], 'Mikropalveluarkkitehtuuri': [{'text': 'Mikropalveluarkkitehtuuri mahdollistaa modulaarisen järjestelmäsuunnittelun.', 'relevance': 0.9, 'keywords': ['mikropalveluarkkitehtuuri', 'modulaarinen', 'järjestelmäsuunnittelu']}], 'Käyttöönotto': [{'text': 'Käyttöönotto viittaa prosessiin, jossa pilvipalvelut ja mikropalveluarkkitehtuuri otetaan käyttöön.', 'relevance': 0.85, 'keywords': ['käyttöönotto', 'infrastruktuuri', 'skaalautuva']}]}, 'relationships': {'Pilvipalvelut': ['Mikropalveluarkkitehtuuri', 'Käyttöönotto'], 'Mikropalveluarkkitehtuuri': ['Käyttöönotto']}}\n",
      "✓ Completed themes analysis\n",
      "2024-12-12 18:59:54,318 - FileUtils.core.file_utils - INFO - Data saved successfully: {'analysis_results_20241212_185954': 'c:\\\\Users\\\\tja\\\\OneDrive - Rastor-instituutti ry\\\\Tiedostot\\\\Rastor-instituutti\\\\kehittäminen\\\\analytiikka\\\\repos\\\\semantic-text-analyzer\\\\data\\\\processed\\\\analysis_results_20241212_185954.xlsx'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO: Data saved successfully: {'analysis_results_20241212_185954': 'c:\\\\Users\\\\tja\\\\OneDrive - Rastor-instituutti ry\\\\Tiedostot\\\\Rastor-instituutti\\\\kehittäminen\\\\analytiikka\\\\repos\\\\semantic-text-analyzer\\\\data\\\\processed\\\\analysis_results_20241212_185954.xlsx'}\n",
      "INFO: Saved results to: c:\\Users\\tja\\OneDrive - Rastor-instituutti ry\\Tiedostot\\Rastor-instituutti\\kehittäminen\\analytiikka\\repos\\semantic-text-analyzer\\data\\processed\\analysis_results_20241212_185954.xlsx\n",
      "INFO: Results saved to: c:\\Users\\tja\\OneDrive - Rastor-instituutti ry\\Tiedostot\\Rastor-instituutti\\kehittäminen\\analytiikka\\repos\\semantic-text-analyzer\\data\\processed\\analysis_results_20241212_185954.xlsx\n",
      "INFO: Analysis completed in 24.26 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Analysis Results Summary\n",
      "==================================================\n",
      "Total rows processed: 6\n",
      "Language: fi\n",
      "Average processing time: 24.19s\n",
      "\n",
      "Keywords Results\n",
      "--------------------------------------------------\n",
      "\n",
      "Row 1:\n",
      "  id: technical_1\n",
      "  type: technical\n",
      "  language: fi\n",
      "  keyword_scores: 0.95, 0.90, 0.85, 0.80\n",
      "  keyword_domains: technical, technical, technical, technical\n",
      "\n",
      "Row 2:\n",
      "  id: technical_2\n",
      "  type: technical\n",
      "  language: fi\n",
      "  keyword_scores: 0.95, 0.90, 0.90, 0.85\n",
      "  keyword_domains: technical, technical, technical, technical\n",
      "\n",
      "Row 3:\n",
      "  id: technical_3\n",
      "  type: technical\n",
      "  language: fi\n",
      "  keyword_scores: 0.95, 0.90, 0.85, 0.92, 0.88, 0.87\n",
      "  keyword_domains: technical, technical, technical, technical, technical, technical\n",
      "\n",
      "Themes Results\n",
      "--------------------------------------------------\n",
      "\n",
      "Row 1:\n",
      "  id: technical_1\n",
      "  type: technical\n",
      "  language: fi\n",
      "  theme_descriptions: Koneoppimismallien koulutus suurilla datajoukolla on keskeinen prosessi, joka mahdollistaa kaavojen tunnistamisen ja analysoinnin.; Neuroverkon arkkitehtuuri, joka koostuu useista kerroksista, on tärkeä tekijä piirteiden erottamisessa ja analysoinnissa.; Piirteiden erottaminen on prosessi, jossa neuroverkon kerrokset auttavat tunnistamaan ja analysoimaan datasta löytyviä kaavoja.\n",
      "  theme_confidence: 0.95, 0.90, 0.85\n",
      "\n",
      "Row 2:\n",
      "  id: technical_2\n",
      "  type: technical\n",
      "  language: fi\n",
      "  theme_descriptions: Pilvipalvelut tarjoavat skaalautuvan infrastruktuurin, joka mahdollistaa joustavan ja tehokkaan resurssien hallinnan.; Mikropalveluarkkitehtuuri mahdollistaa modulaarisen järjestelmäsuunnittelun, mikä parantaa kehityksen joustavuutta ja ylläpidettävyyttä.; Käyttöönotto viittaa prosessiin, jossa pilvipalvelut ja mikropalveluarkkitehtuuri otetaan käyttöön organisaatiossa.\n",
      "  theme_confidence: 0.95, 0.90, 0.85\n",
      "\n",
      "Row 3:\n",
      "  id: technical_3\n",
      "  type: technical\n",
      "  language: fi\n",
      "  theme_descriptions: Versionhallintajärjestelmät ovat työkaluja, jotka seuraavat ja hallitsevat lähdekoodin muutoksia, mahdollistaen tehokkaan kehitystyön.; Jatkuva integraatio on prosessi, joka varmistaa koodin laadun ja mahdollistaa automaattitestauksen, mikä parantaa ohjelmistokehityksen tehokkuutta.\n",
      "  theme_confidence: 0.95, 0.90\n"
     ]
    }
   ],
   "source": [
    "# if __name__ == \"__main__\":\n",
    "print(\"Running Excel-based analysis...\")\n",
    "\n",
    "# await run(\n",
    "await analyze_excel_content(\n",
    "    content_file=\"test_content_fi.xlsx\",\n",
    "    parameter_file=\"parameters_fi.xlsx\",\n",
    "    analysis_types=[\"keywords\", \"themes\"],\n",
    ")\n",
    "    # )\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "semantic-analyzer",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
